link,content
https://github.com/hviovn/new-vocabulary/commit/268b562063bbfd31add802a8495ca9f534c6f565,the dates were all wrong
https://github.com/hviovn/new-vocabulary/commit/7325b9519280b7699d59a04db2b0b2bbd0565cf3,Merge pull request #2 from hviovn/feature/clickable-thumbnails-844169335408701926
https://github.com/hviovn/new-vocabulary/commit/73c94681760209bfee2ffd1a8d1875d38332f50e,Parse first example.
https://github.com/hviovn/new-vocabulary/commit/b8ac453d7d12dae0d535e194a24d5a40571324e1,match image names to content
https://github.com/hviovn/new-vocabulary/commit/e318d008f88480964c47b170e9b32d819181fb59,cleanup
https://github.com/hviovn/new-vocabulary/commit/a66224d926a4058edf83b8b2be5c55cf120e8b85,import picture sources
https://github.com/hviovn/new-vocabulary/commit/ef0bda50caa96e1b11d44679661cf6cfbecd089f,Add .DS_Store to .gitignore for Synology Diskstation
https://github.com/hviovn/diary-statistic/commit/a7eaf53fc644c7b5d3a38ae901036485e5459ab6,Merge pull request #9 from hviovn/fix-jekyll-error-and-split-output-15352974587547767671
https://github.com/hviovn/diary-statistic/commit/1e4ed8aff877707087715ef491a471690f85386b,Update README for clarity and grammar
https://github.com/kreier/quartz/commit/252c674695144c355f7a5e30b602a02ef5211b41,"fix typos, more benchmark from penta server"
https://github.com/kreier/quartz/commit/5d5046355d432bfa5f97f270b17cca832d0e3d83,fixed server error message
https://github.com/kreier/quartz/commit/b3b0fe97ad2e29dec8bb9aff92509ff4b93a4fa3,Hardware collection and other history artifacts
https://github.com/kreier/quartz/commit/1e023eaa9ff97a0adceec3fa727a99e2346f0f44,Tschechientour update
https://github.com/kreier/quartz/commit/ce28da3789bd2b4f7fa91ac247fb5e9a16fec577,"Quartz sync: Feb 25, 2026, 4:29 PM"
https://github.com/kreier/obsidian/commit/ab4f8f561c1cfdd1fbcd4fbe9fa93398f9e2b594,step two in automated syncing
https://github.com/kreier/obsidian/commit/ea79d2272f9f4f165bcf6aabd3d6151f1c878768,sync: update vault/saiht from quartz/content (2026-02-25)
https://github.com/kreier/obsidian/commit/056f5502203d8c7ab35981a4c1102242830434d2,start automated workflow
https://github.com/kreier/obsidian/commit/27fe2ef6a506a3084f8779452177888a65e04c77,Add 'vault/saiht/' from commit '8facfbedf07014a37b4cc6c6ef7a1756492e5795'
https://github.com/kreier/obsidian/commit/13fd581c7b7e6cd7ca54f70e149025d80fb23dc7,Move saiht to saiht_old to clear path for subtree
https://github.com/kreier/obsidian/commit/8facfbedf07014a37b4cc6c6ef7a1756492e5795,branch for Obsidian content
https://github.com/kreier/obsidian/commit/eb49403b0fd6801a178747670cb6d51cff8bc91b,prepare complete history import
https://github.com/kreier/homelab/commit/6e8ac409c1eb36ba6a74723c08eb89388ac9dd54,fix idle shutdown
https://github.com/kreier/quartz/commit/edd894aff027adbea5caa74e22940db0d74edec8,some llama.cpp tests
https://github.com/kreier/obsidian/commit/69e14bef4a86c7571565216612fef7117265b8a9,some llama.cpp tests
https://github.com/kreier/llama.cpp-jetson/commit/cba793e345442fc9f542f3418ae4b0070bd37b06,Add LFM2.5-1.2B-Thinking section to README
https://github.com/kreier/llama.cpp-jetson/commit/15ba3a7a08957049eb06cb91c75b0d46c9f519a9,Can we compile for Liquid?
https://github.com/kreier/homelab/commit/9880d0fde596bebb18c3b2090a4d8913640e123d,first iteration - some crashes
https://github.com/kreier/wob/commit/b2064a5a0505b0d9af7a5e029d5f4cee9a2be8b8,"code examples, cleanup"
https://github.com/kreier/wob/commit/ce19b314caa3c0ddc9cf1bb69ddd62d5456e67c8,cleanup
https://github.com/kreier/wob/commit/e02f339e893183b54d790e5996d3116b943debc5,Enhance README with project details and examples
https://github.com/kreier/wob/commit/f0c80636686206cd228274a8980c9a318ba0c444,rough outline
https://github.com/kreier/wob/commit/b8573052fb4ad89a96049cd58520c4b1fc8da3ba,Add wake_penta.py to wake Penta-GPU server
https://github.com/kreier/wob/commit/6cc2fba011fa39ff3b1b2c103fb64d7ce0954c89,starting outline
https://github.com/kreier/wob/commit/f7a7f6cab2d38d47b00cdb8a74287c65a1a4d746,Update .gitignore to include .DS_Store
https://github.com/kreier/wob/commit/85c5f11dbeeca8cecd992d2fd3e90bb3bb10c71d,Initial commit
https://github.com/kreier/quartz/commit/2b386e7836ea2c99e2983b3cb9b9d62f29311693,include some hiking experience
https://github.com/kreier/obsidian/commit/eb32b620c60e7f7744f70fab264d36b1360f1d6b,include some hiking experience
https://github.com/kreier/quartz/commit/ea65c769a316c765de8d8c465884846e8fbc44f8,include Black Virgin Mountain
https://github.com/kreier/obsidian/commit/1a08ff84daa51602cbd1481b2b789bd819b52fb2,include Black Virgin Mountain
https://github.com/kreier/T100/commit/27c4c1da00a1d7529810fa39416a9e558667d80d,Add BLE project details and Bluetooth module history
https://github.com/kreier/quartz/commit/aac21671276305370fa75788509711a6b73a37d0,document ar65view and related events
https://github.com/kreier/obsidian/commit/263368b3b544998193998a4c2d582bf283e127f1,document ar65view and related events
https://github.com/kreier/ar65view-svn/commit/5d0def8d78d9f57abeea03aad15182f679d8ae97,Initialize README.md with project information
https://github.com/kreier/ar65view-svn/commit/b296a1efee3d027c3c9a1464fca6e7654fb3a081,Add .DS_Store to .gitignore for Synology Diskstation
https://github.com/kreier/ar65view-svn/commit/ad6cdbcdb8d9f8a046d0eb41e6cf536e55b91b32,Add GNU General Public License v2
https://github.com/kreier/ar65view/commit/96585b5aa1e8ceb6b3508467ba4ab75958f0afef,Update build status badge in README.md
https://github.com/kreier/ar65view/commit/dde31eb19ce598a1f8a9f80ceca13e01e5a314b2,Remove HitCount badge from README
https://github.com/kreier/quartz/commit/7eb48e4011f5eefece9bd0fbf56c6c9e212df31e,expand on Penta-GPU server
https://github.com/kreier/obsidian/commit/4404c54574d9e73d76623d347c25213674c096ec,expand on Penta-GPU server
https://github.com/kreier/homelab/commit/9d76bdf990320fa87307ef635dc227eed0ff6c60,Merge branch 'main' of https://github.com/kreier/homelab
https://github.com/kreier/homelab/commit/5ea573abdcd860e86afaef4ff793beebff8bfb03,progress on Tuya integration
https://github.com/kreier/homelab/commit/070e74306f5fecec4522ec68f165aaf428c9552b,Rename repository and update README content
https://github.com/kreier/benchmark/commit/8a9ac10ccbd51652bd9f4c34227f692144df13d3,updated benchmark results 1 year later
https://github.com/kreier/homelab/commit/f3dcb6cf0956057c742232201c7df632eb4bfedc,Add mkdocs-glightbox to installation dependencies
https://github.com/kreier/homelab/commit/32efc0c25de465d0c18ce07cc255a674f816ccef,Updated structure
https://github.com/kreier/quartz/commit/1cb95a0a612b98bff0d3d6a44ce5d0014f204b03,Laptops 2020 and Penta-GPU server
https://github.com/kreier/obsidian/commit/a42b109d9aba9eb8703f564827bfe523915f833d,Laptops 2020 and Penta-GPU server
https://github.com/kreier/benchmark/commit/aaecfcde9613db993ee2dc0a76cf20624a8f50fa,expand on 64 bit
https://github.com/kreier/benchmark/commit/b217d89dc2b0b22daef118234c9a46e415b711f7,updated benchmarks with new P104-100 GPU and different slots in Z170 mainboard
https://github.com/kreier/quartz/commit/ebb1cb19f5db97ad57058614cdad8bdd8392ca9e,Penta-GPU server is running
https://github.com/kreier/obsidian/commit/c0c7bb0802059e7342385d0a55b17c4a10ea9290,Penta-GPU server is running
https://github.com/kreier/quartz/commit/3d48c6ed1be790f74cd5536fc21bb884c090c392,hardware update documentation
https://github.com/kreier/obsidian/commit/8521fb2c2854335d5099bb6ff13d1c171025304c,hardware update documentation
https://github.com/kreier/benchmark/commit/6ac58321a211879100b2a67e3efbaaef754bc9ea,Update GPU performance metrics in README
https://github.com/kreier/benchmark/commit/303ee0b7ff5f7ab3345aea36ab2b7b956f21eeb1,got a new P104-100 to benchmark
https://github.com/kreier/quartz/commit/5bfea3f5516531b44d8d0603b4e3c65fe87facfb,Document both Raspberrys Pi3 and Pi4
https://github.com/kreier/obsidian/commit/797c7b617b0eafbabcd3c273b6109617dd1d934e,Document both Raspberrys Pi3 and Pi4
https://github.com/kreier/timeline/commit/adab2d8eb7dbe5239b7f360b5f4538ea1909d074,Merge pull request #82 from kreier/6.02
https://github.com/timeline24/timeline24.github.io/commit/3d9c41e59e414e7115dee4d968fb07a78c4bc4e0,version 6.02 from 2026-02-12
https://github.com/kreier/timeline/commit/aff4a62e1090927b69379d95e7369fa150162c07,"batch processed PDF generation, 5 new languages"
https://github.com/timeline24/timeline24.github.io/commit/4595f121bd10272ec9304a372465cb046b63f9b6,Revise language versions and print links
https://github.com/kreier/timeline/commit/20f931c8d291df35fa7fb44033695cfb321ccbb6,converted from float year values to YYYY-MM-DD
https://github.com/kreier/timeline/commit/80f2028eac220ccbed728e312bf9b96a25c13c73,replaced 21 locations where color was *256 since no longer needed
https://github.com/kreier/timeline/commit/3adb282fbb45eaa06f78f977645ccb071c69e662,"move daniel2_shift to deprecated, include wikipedia link"
https://github.com/kreier/timeline/commit/0a9885e76a3559d40c64d382c884557ac9c3d4f0,"update Korean, visualize editor"
https://github.com/kreier/timeline/commit/ca987e5cf6467e2a532fc7299aff5633cc77794a,"Updated editor, Check with Korean"
https://github.com/kreier/timeline/commit/c65950e677d0ff9363c0f8ea0740367b4ec62a35,Merge pull request #81 from kreier/6.02
https://github.com/kreier/timeline/commit/67e69c6d7d8aa0143307654bf0133191e4d46652,include image shift and scale for Daniel 2 image
https://github.com/kreier/timeline/commit/b10c0d967f5202845544eed3e6ce7c6dbdedc09e,updated web editor
https://github.com/kreier/timeline/commit/cd0318951d6628121b3aed133c1181f75997702e,include first edition of web edit for dictionary
https://github.com/kreier/timeline/commit/254dc489f59cf9c0ac3af68c352ca72545a9ef51,align 42 translations of 571 entries
https://github.com/kreier/timeline/commit/20e5d82a76fab9b663d699bbc28d8ef439a146a1,include 6.01 translations
https://github.com/kreier/timeline/commit/8115f6b52ed175391fc6fcdaf190c766398e79df,updated translation for 6.02
https://github.com/kreier/timeline/commit/454da40dd3202c5d2145593c464b4f7fd9d5a841,updated run of auto-translate.py
https://github.com/kreier/timeline/commit/4a3af9ababa569c7d8376ee5f4fe5c67d1b5df4f,Update for new dictionary setup in Google Sheets
https://github.com/kreier/timeline/commit/bd0657b07df42a0aae80b3614e3b66132d48b2d9,Merge pull request #80 from kreier/6.02
https://github.com/kreier/timeline/commit/e939993b49a8cc20c5373f49a1950ee9f019b1f8,document current state with Google Apps Script
https://github.com/kreier/timeline/commit/af64b00ef9f471397318f03ed913d160ad063bcc,cleanup and organize some clutter after 2.5 years
https://github.com/kreier/timeline/commit/bd868cc32d626727f3728060b6df1e211ce9e4d6,small fix for digital edition printout
https://github.com/kreier/timeline/commit/f39d08e4108e85dc761422715be2d1fba54e6e93,realign with CSV export pattern of Pandas
https://github.com/kreier/quartz/commit/9b0baa73eb2be5cf8bc9ab5f41a1667fbd5b9330,Include mining and the Triple GPU server
https://github.com/kreier/obsidian/commit/86226fa28b1751ce94a240c0c2f45a2b8822f56a,Include mining and the Triple GPU server
https://github.com/kreier/impact/commit/bfa93181b978821645280cfe5fd96e4f8b387421,Merge pull request #3 from kreier/dependabot/pip/nbconvert-7.17.0
https://github.com/kreier/python2018/commit/12f7a8b6dc18a83d1dd259dc74627ba7aec04151,Merge pull request #42 from kreier/dependabot/pip/distributed-2026.1.1
https://github.com/kreier/python2018/commit/08e35f65d98a3be584c9a0b54fc306d8db30e750,Merge pull request #43 from kreier/dependabot/pip/nbconvert-7.17.0
https://github.com/kreier/quartz/commit/0cac00af3075f78dc59876432f9438051fea679e,Update quartz landing page
https://github.com/kreier/obsidian/commit/078af7156ca04f6c9e47aec6a5ac823655bf809e,Update quartz landing page
https://github.com/kreier/quartz/commit/15946ddfae49bc484705f057782a863b5a7ece8f,document 3 PCs and one M590 mouse fix
https://github.com/kreier/obsidian/commit/48928d483c16b9eda71ac1d033cd9ded6e00948d,document 3 PCs and one M590 mouse fix
https://github.com/kreier/quartz/commit/5950441a7e72e62731ed1a1abeaef0a00d00845f,more history of Vietnam 2024-12-26
https://github.com/kreier/obsidian/commit/e5ce44163edea529275a12b1a3044426457940cc,more history of Vietnam 2024-12-26
https://github.com/kreier/timeline/commit/1081f3f43e8e43cb55a7db971c9b648cdeded747,minor updates in preparation for 6.02
https://github.com/kreier/bilder/commit/f45ded15dec45f98f6a7a6925001069058b24e7a,create summary and details for target location
https://github.com/kreier/prime/commit/00ead6097651e5a30270e5cded98093ee290b7aa,finished benchmarks after 2 days
https://github.com/kreier/quartz/commit/a1e167afd8b011d414ebf2c5d9827afd96047407,"Quartz sync: Feb 9, 2026, 1:15 AM"
https://github.com/kreier/obsidian/commit/c8ab443a094650ef9b238c4c5702684b6ec07d3e,"Quartz sync: Feb 9, 2026, 1:15 AM"
https://github.com/kreier/quartz/commit/3aaf3c918241e0564fc962755f63c6d9bd9d8fa8,Merge branch 'v4' of https://github.com/jackyzha0/quartz into v4
https://github.com/ssis-aa/collaborative-code/commit/1052bc9b64de5fc78b7941ee11d4588990298321,Update README with p5.js version details
https://github.com/hviovn/hello-world/commit/1d196a920c19cf602377a2f6a7900721622a6809,"Add hello.c to print 'Hello, World!'"
https://github.com/hviovn/hello-world/commit/ddb801b88ba31cd1792ebcefbb574f177c858d34,"cleanup, include Java"
https://github.com/kreier/homelab/commit/54f8c05d048b5716a3ff3e47baffed9f990c78f3,updated WOL problem
https://github.com/kreier/homelab/commit/487d92bf283bdbe07f6fab75c709608e3c226d65,updated Tuya network
https://github.com/kreier/prime/commit/9f562553cc253dd7a63692e15c8f2fabdf92d6c4,v5.6.2026 with fixed time measurement
https://github.com/kreier/prime/commit/cf17386725b7747045ef474ff655966878ecb95a,preliminary results for 32bit
https://github.com/kreier/quartz/commit/0de8d39f703b1024ced659e9881235b8605da4f6,some homelab updates
https://github.com/kreier/obsidian/commit/1a5045e8a8b023dc549727c25550ee70edb28de6,some homelab updates
https://github.com/kreier/prime/commit/b4f0c1f2333f69aa4bfc1d384e9192207756be18,results from May 2025
https://github.com/kreier/homelab/commit/d92258a3dcc152653ac402cbed77579e232a3722,fix typos in setup
https://github.com/kreier/homelab/commit/ae693205d779a2ec9a56720c816c4ea0f9ea56a8,glightbox was not used regardless
https://github.com/kreier/homelab/commit/d6469b395de7870cf902c2b0437a7f2a9447f177,update navigation
https://github.com/kreier/homelab/commit/f0363b2f474005214bbe54129f15553224378f48,updated navigation
https://github.com/kreier/homelab/commit/1b11472462eeca35161d424143be2139ad171381,Refactor image paths in README.md
https://github.com/kreier/homelab/commit/ccd48da011460510c6524bfd621c7e988f51b699,Merge pull request #2 from kreier/kreier-patch-1
https://github.com/kreier/homelab/commit/e7b3abaad7a2176eb4cc495f0de818ea348be895,Enhance documentation formatting for homelab setup
https://github.com/kreier/homelab/commit/dcb4e45333b5f17841366a747bdb5849ee798698,toggle dark/light mode
https://github.com/kreier/homelab/commit/8a77f90b93a959faf9168e893a681a03435e9273,suggestions from Gemini
https://github.com/kreier/homelab/commit/66d972ad6d463d4227e9d96281f54f7c89f5678b,fixed name of project
https://github.com/kreier/homelab/commit/c687c1bccf76406e5e9407a76a95736542fd815c,Update CI workflow for GitHub Pages deployment
https://github.com/kreier/homelab/commit/edfb0e6e6b110f969fc6f3fcda03f6c9a7e2db7d,Add CI workflow for deploying documentation
https://github.com/kreier/homelab/commit/f3a0301a7bb1b4f3188b95d3b534563fd3296ed1,outline mkdocs
https://github.com/kreier/homelab/commit/8fe8533fed18375f9787dfb2895a1d1a241bdeb7,Merge branch 'main' of https://github.com/kreier/homeserver
https://github.com/kreier/homelab/commit/1e899952ec27c88160c89747afe475c730be15a4,prepare for MkDocs
https://github.com/kreier/location24/commit/fdaeb5bcf6455e319f0b25a14c7f3b0e612814ad,Implement geolocation fetching from API
https://github.com/kreier/location24/commit/ec0d2beb2dd58127ea2eddc239f33f83e2d9f3d9,Create Cargo.toml with package and dependencies
https://github.com/kreier/homelab/commit/85bd678bf7091b31ade575064bce455984ce6312,Fix formatting and headings in README.md
https://github.com/kreier/homelab/commit/90a51e3440e09cfb4fe5fdb70e0fda28355284c1,added details of the setup
https://github.com/kreier/hv.io.vn/commit/cafb117ce697c186fb0b2447f2880fda389beee9,Enhance documentation with badges and server details
https://github.com/kreier/hv.io.vn/commit/9e8d95fd29ef721e987e08ef1908cd4f2861b5e7,include visual of nvtop
https://github.com/kreier/hv.io.vn/commit/e0036df8bd9ae0f1a0d3456df66831ceda092787,"nicer layout, setup"
https://github.com/kreier/hv.io.vn/commit/7daa6471c4bf07ea83e51f409c4e83ae00130236,Merge branch 'main' of https://github.com/kreier/hv.io.vn
https://github.com/kreier/hv.io.vn/commit/a4fd601a6382c015124297ad6d6b71275c8cf721,switch to mkdocs
https://github.com/kreier/hv.io.vn/commit/2adce5cb411c0ab2d3baa66885d1ec3790f3f35a,Fix href attributes in certificate links
https://github.com/kreier/hv.io.vn/commit/93c3eb17e6053684ba4e319924d0285c09ee43bf,Add hyperlinks for certificates and new links
https://github.com/kreier/hv.io.vn/commit/2c3b9e4d97c01c25fa2a7018814f428b238c6c29,Create CNAME
https://github.com/kreier/hv.io.vn/commit/f6f6c3795ffcdcbff9d167c5c8e39d8ebac54dda,Delete CNAME
https://github.com/kreier/hv.io.vn/commit/df329306d49f2d27e80a0b0ce078880f0d1a56df,Create CNAME
https://github.com/kreier/hv.io.vn/commit/2c9e5d912c2622a9ae1349c896602d7222e5feaa,Delete CNAME
https://github.com/kreier/hv.io.vn/commit/349ac7b102d454a245fd0ac37927ecc12e572378,Create CNAME
https://github.com/kreier/hv.io.vn/commit/43c82be00500bbc42cf6a1bc834505aea8ad9527,Delete CNAME
https://github.com/kreier/hv.io.vn/commit/aa9afcf3d499e454aeb75de031cd08e3bfaad964,Create CNAME
https://github.com/kreier/hv.io.vn/commit/fd16b0049a6072ce87d210e6d8ebbe858b54d82e,Delete CNAME
https://github.com/kreier/hv.io.vn/commit/7403f9edd0d2f608708ed8c15152ff5a7f11ad0e,Create CNAME
https://github.com/kreier/homelab/commit/498e774c43a687e76138cff0b696786e2abd6358,Revise GPU specs and performance details in README
https://github.com/kreier/homelab/commit/1b3b94792b92ec138e588a4d1edd2d7f7baec4d9,updated documentation
https://github.com/kreier/hv.io.vn/commit/c4f8e212474f8465500ab9ec59a59f0e75f72105,starting templates
https://github.com/kreier/prime/commit/297749079b51de99166d1580fc1498ded0932f65,updated to CircuitPython 10.0
https://github.com/kreier/hv.io.vn/commit/2444ccafcd75db6b8bf9626a72e80a7a54752dee,Add .DS_Store to .gitignore for Synology Diskstation
https://github.com/kreier/hv.io.vn/commit/b75bcfa528689ab3c96fa9ff944fd5d3d6e40813,Initial commit
https://github.com/kreier/ml/commit/debd14fd674799f61aed7696c608a58dd08462c1,Remove front matter from README
https://github.com/kreier/ml/commit/4bb031def90ec055a4b2a8edc0f5ba67bcad8366,Enhance README with Mermaid diagram and updates
https://github.com/kreier/ml/commit/d96c211356e6ff7428271c56ed443b1156a95d32,Add remote theme and enable mermaid support
https://github.com/kreier/ml/commit/3f5b4694fef214eaf9c2d56afece490fa0968ee7,replace image since Anandtech main page is down in 2026
https://github.com/kreier/homelab/commit/4ecd92cdd05d0db1e16bb67b916007f9c99d00d2,Merge branch 'main' of https://github.com/kreier/homeserver
https://github.com/kreier/homelab/commit/e45616ab90b5b2a19e6dd731f34902c5304d6e05,setting up pi3 and pi4 in the network
https://github.com/kreier/homelab/commit/83459c9bdaf849e3ec1deb5730d4d624425f3bee,Revise README with hardware specs and Docker setup
https://github.com/kreier/homelab/commit/c378b1ad95be356bec31fa6792b7a0c4ba3503ed,visualize server-side and user-side
https://github.com/kreier/prime/commit/b0d8d498ebf3c925baa058e8775d1aa652e57606,updated results from Pi4 run on C
https://github.com/kreier/homelab/commit/7a9cb8526dc5b94698d9d62e3211c63f1e6ba550,Merge branch 'main' of https://github.com/kreier/homeserver
https://github.com/kreier/homelab/commit/fc737ca546ad0eed38b69501d8dae831702152af,traefik and certificate chain to enable https in local network
https://github.com/kreier/homelab/commit/0f9b857a3330bb469f095b090ead703253a985bb,Add Synology Diskstation to .gitignore
https://github.com/kreier/homelab/commit/a45bf5ec75a291a17e72ca62848f2a35d9ac765e,Enhance README with homeserver details and setup
https://github.com/kreier/homelab/commit/6a82497302c805b8e7e0fa84a97d2448289e5529,Initial commit
https://github.com/kreier/prime/commit/e71f5c08b6fc07ff63c49e97438ed3e66fbafef3,preliminary results 2026-01-30
https://github.com/kreier/prime/commit/df6d8aaaccafca3bee85b55e7b492278ecef59b8,results from 2026-01-30
https://github.com/kreier/prime/commit/8809df2795adb82ce9663e2d95337938a309c54b,run 2025-05-11 to 2025-06-29
https://github.com/kreier/timeline/commit/d2237b68312388d41c74cc5ce5f908224ff11562,"Order deprecated to follow reference, export JavaScript matches PANDAS"
https://github.com/kreier/timeline/commit/9e940a285058c0da9e307dd0c78298b8b89aafb8,small fixes in Spanish
https://github.com/kreier/bilder/commit/ed25d5d2ba0ba365c9afdd91ec2d87d5d4873d64,organize cloud storage
https://github.com/kreier/bilder/commit/ca421128271dcf03bb6d5ae5b7373ea124aaa640,target network folder
https://github.com/kreier/bilder/commit/28598972f5e276219ea5c6970b821a6925816ac5,include support for Excel
https://github.com/kreier/swagger/commit/7e005a6ced7b4be66eb0dd43546b820a96aae394,Create CNAME
https://github.com/kreier/swagger/commit/0763e9e56574a708b559f39f79a096f1fbdfabc1,Enhance README with badges and project details
https://github.com/kreier/swagger/commit/fae44d0955dfbe585463264851a615713292cbc0,start installation
https://github.com/kreier/swagger/commit/91cf3713576c67ab72f3cefaaf2bc0fe18ce5bb9,Update .gitignore to include .DS_Store
https://github.com/kreier/swagger/commit/31fd07cab1d1bad4971761525cfbf7b20895f467,Initial commit
https://github.com/kreier/picow/commit/b21ee1b0546ad049468c0991fa6a937b2182f101,Create CNAME
https://github.com/kreier/picow/commit/03ab818ddfeca2781b64492845f73420b246af41,Merge branch 'main' of https://github.com/kreier/picow
https://github.com/kreier/picow/commit/537b68589b4877236e13dc03c8c9b293e0ceec95,prepare for kreier.eu.org
https://github.com/kreier/picow/commit/76a14a87d4219c98f5841faf388c73b3d1f355c4,Delete CNAME
https://github.com/kreier/picow/commit/707e3e62152c3e68a2b436df6f3413298a1eb60c,Revise README with project title and badges
https://github.com/kreier/picow/commit/9634c9ec23005bde90a1167754693c162096ee1a,Create CNAME
https://github.com/kreier/igshcmc/commit/f88fc38e6b8c65efe7117028eed91dfc41016f08,Create CNAME
https://github.com/kreier/igshcmc/commit/1bfb3b94d8ad0c41c08299ee3a28a3dd91c1dce5,old saiht.org page from 2010
https://github.com/kreier/igshcmc/commit/ec864d6bf44df298297ecdc037c43f309da06b2c,starting framework
https://github.com/kreier/igshcmc/commit/404b6cd680d6b7539eea87d114105d3b35e07b94,Initial commit
https://github.com/kreier/tl/commit/6ae25e0be4ba3560915c4959376eaa85d5159977,"simplified html, new folder"
https://github.com/kreier/tl/commit/3317e5c24a6bf666a6d8db7efd69e69652f7c962,extract CSS and JS from HTML file
https://github.com/kreier/timeline/commit/f4c92f0d6dbc20c1ff130eb33ac87c63240d68b3,render special characters
https://github.com/kreier/tl/commit/701b449d9e3115f76418f71837b78cc22505b358,"convert pdf to svg, rasterized images downsampled to 300 dpi"
https://github.com/kreier/statistics-diary/commit/23c3a4226c9ac6ec5f4bcda8e1dfb563f7f31751,Change commit message for update workflow
https://github.com/kreier/quartz/commit/974ccdf59cb9dc7b2bcc0ed675fa11806d1f5ff4,"Quartz sync: Jan 20, 2026, 1:35 AM"
https://github.com/kreier/obsidian/commit/3c63764ae62e6ba524d32a42187c26d96b70be8e,"Quartz sync: Jan 20, 2026, 1:35 AM"
https://github.com/kreier/statistics-diary/commit/d9738cc1c77ef22f5400eebd12e1f60f710f3e74,Rename workflow and update scripts for statistics
https://github.com/kreier/statistics-diary/commit/40192b3b8bba777733a53b718cae64367cf50b9b,update Github description and process
https://github.com/kreier/statistics-diary/commit/4a8f3ca909bbb0270e87d8b64a93fdc2adac8d8e,Revise README with updated statistics and project details
https://github.com/kreier/tl/commit/49dd2cac59a5e8389b44650719359b2262a8eee3,Revise README with project title and images
https://github.com/kreier/tl/commit/576cfdfc735e2143a5c950a6a997d1c71a08a1cd,document progress
https://github.com/kreier/tl/commit/4337224d03036846d7f40e4d88f62c3d894dab1b,include pinch & zoom
https://github.com/kreier/timeline/commit/4644f40ce599e404e95a91239042955e574f7de8,include a v6.01 image from 2026
https://github.com/kreier/tl/commit/ed9cc80c7fc8aebc42558e807a713c9b2dac762d,first fixed zoom edition
https://github.com/kreier/tl/commit/77b0448651dfa48c922ba2d3890e5293e1f41772,Update .gitignore to include .DS_Store
https://github.com/kreier/tl/commit/8615b6f446f9a0dc26e1c63b6e26aade9f877d20,Initial commit
https://github.com/kreier/logo/commit/2932141a6220b73344018070bcacabd1976df519,Include TL timeline logo
https://github.com/kreier/logo/commit/695e96ab7fdb758ac23943884191cf984e1b4c82,new logo for timeline subdomain
https://github.com/kreier/logo/commit/0100dbd2a928cb02ff36db7efff55222d79cdeb9,Adjust image width in README.md
https://github.com/kreier/timeline/commit/396055814605a9ce0c9b135d78b5a017064007a7,updated statistics on translation progress
https://github.com/kreier/timeline/commit/891d983c4cd664e2b4fed75605a70ab81a501e92,Merge pull request #79 from kreier/6.01
https://github.com/kreier/timeline/commit/4e389c9abad22c71e630b8a3694b23d27ff3edec,Merge branch '6.01' of https://github.com/kreier/timeline into 6.01
https://github.com/kreier/timeline/commit/59a390da3d7cbdc5b1a9eb1eae26d03fc674a518,"update Spanish and Vietnamese, fix location error bug"
https://github.com/kreier/timeline/commit/da6e59201cc6160f38e36de1937d2c47065a06ca,Merge pull request #78 from kreier/main
https://github.com/kreier/timeline/commit/ef53cfd2cbff5509946adeb7557a7b4ef8b16504,"update English and German, minor fix"
https://github.com/kreier/timeline/commit/0f7e6cd768dc84cdff5663126848e82f28d2725e,"Include 7 generations of Cain's family tree, plus 13 persons"
https://github.com/kreier/timeline/commit/ad6925bd6adc9bdab5ccb6c8de1a036134ef7364,clean-up January 2026
https://github.com/kreier/timeline/commit/0b8a7768321eb39ca026fb4ff8e2657f43e1536f,updated 31 languages with automated translation
https://github.com/kreier/timeline/commit/518411e4409f7151f80248aefa1ceb36c91f927b,"auto-translate to find missing values, then translate"
https://github.com/kreier/timeline/commit/fc9bf4f63e1078cbc532e0f9d2a6f5e4e76c0adb,updated 40 dictionaries with a script
https://github.com/kreier/timeline/commit/0c45afffe2a7d43d3ac516f0eb19701e5a4497aa,Automatically update 11 dictionaries
https://github.com/kreier/timeline/commit/774e8830121d7da550cf72feffe0a0fbe3baef85,automatically update English reference column
https://github.com/kreier/timeline/commit/7e747f49ea3b0eb0a8884e299099653d090da054,match version number and date
https://github.com/kreier/timeline/commit/de7cc6f2d49e727eed80f1b493bd44e85618e5c5,"show which lines have tag changed, mark as unchecked"
https://github.com/kreier/timeline/commit/9b46dfd9d38db29585e67ce02fa4e6c7e25acf65,removed redundant C.E. entries
https://github.com/kreier/timeline/commit/67bb9b242aa0c2fd957eae020b79dc274e9953d0,"updated German translation, rendering"
https://github.com/vex-ssis/2026/commit/d728f1f44fb827e55c24239692f6b5e34eb967f1,Add details for January V5RC event in Vietnam
https://github.com/kreier/calendar/commit/4ba9ff8936dfb993f28e9c99aa3752e2fd1fa416,Expand for my Diary 1989-2028
https://github.com/kreier/obsidian/commit/6b0399b8edcd90590071d779167d7251c5608bd8,parsing artifact from 2025/12/21
https://github.com/kreier/obsidian/commit/30a62ac78181d564543b386b709e60edb907ee68,Make comparison between vaults easier
https://github.com/kreier/obsidian/commit/4a078ff6edd4bee62627d741bffd8d38577f3837,Update early January 2026
https://github.com/kreier/quartz/commit/707d2a67b758db4bfc4e641e73eb9b495fa895dd,"Quartz sync: Jan 15, 2026, 6:35 PM"
https://github.com/kreier/obsidian/commit/d3eb5355ff0b16565d642d0406932680c723598d,"Quartz sync: Jan 15, 2026, 6:35 PM"
https://github.com/timeline24/timeline24.github.io/commit/45d11cd6854f37938e4f11bab9d25046ccc71e70,Revise dimensions for digital and print editions
https://github.com/kreier/timeline/commit/2ffd7dc772f62d7effdec0694d28a75900507774,fix encoding and links
https://github.com/kreier/python2018/commit/dc1d242c00a9b9ab43dcfcab2dbbf36b22f42714,"fix typo from 2019, update statistics"
https://github.com/kreier/python2018/commit/94ad05173100b169180ee62d57e36c7af95d4e0a,Merge pull request #41 from kreier/dependabot/pip/filelock-3.20.3
https://github.com/kreier/python2018/commit/1a20b7865d3ef5038529b34fb4cc3a7a1e92e509,Add artifact upload step to GitHub Pages workflow with correct path
https://github.com/kreier/python2018/commit/955bd2e4b07175ac0431472151dcd9afdac09664,Merge pull request #40 from kreier/dependabot/pip/bokeh-3.8.2
https://github.com/kreier/quartz/commit/f99c30e297b93d46037b14c5c2eb5a1a6aeccd57,Merge pull request #22 from kreier/dependabot/npm_and_yarn/production-dependencies-623566deaf
https://github.com/kreier/quartz/commit/ee259afb7492e72d5e6a70d5bd2ce9362e31795d,"Quartz sync: Jan 13, 2026, 5:36 PM"
https://github.com/kreier/quartz/commit/2e5633db67c04210ba99572d7d543c0889e93c79,Merge branch 'v4' of https://github.com/jackyzha0/quartz into v4
https://github.com/kreier/timeline/commit/037f4fa019f1368bd0830cb39e292fab4ba12c4a,updated statistics with tags
https://github.com/kreier/timeline/commit/fc6944581471510545945fb902e6d64ce006f01e,Colored breakdown of the contribution for each category for each language
https://github.com/kreier/timeline/commit/17c201d8b4edae673225a0e13078500346c97085,Newly rendered U+02B9 as สน (modifier letter prime) with NotoSans and Aptos mixed
https://github.com/kreier/timeline/commit/9fbc9e7bd5c6c956bea8bfaf5ba24dcf6bed5451,"BCE and CE are automatically checked, dictionary updated"
https://github.com/kreier/timeline/commit/9f5060462e1bc757ed7e758481a0a561cfaa8d7a,"extra values labelled ""deprecated"", no downcast Pandas warning"
https://github.com/kreier/timeline/commit/82c4f72e79f45c4f470d0a36365828de7d7b4056,"reflection on the translation effort, grouped by tags"
https://github.com/kreier/timeline/commit/603e36a0d3a44f5d333a9c6bc94e93a4a8a60ada,"add tags to each entry, determine translation efford"
https://github.com/kreier/timeline/commit/7eb180d03814788e3977b577127ee2542bae37a5,"sort dictionary, include tag"
https://github.com/kreier/timeline/commit/a6540b3f6e7b7cb732b77b7db9dfbf191524a463,first steps in key comparison of dictionaries
https://github.com/kreier/timeline/commit/7e1832b8b24fac86b3e9f7c41147963f032cea80,"cleaned English version and reference dictionary, 529 left"
https://github.com/kreier/timeline/commit/a41ea77c5f45062b14b52c4462a97886eb057656,text for periods left/center/right specified
https://github.com/kreier/timeline/commit/567fea7cb591fb809e38469f8c0e7c1e6788edf8,"check dictionaries for unused entries, reduce translation work"
https://github.com/kreier/timeline/commit/c043494c2990854958453df9a86f9bf0bb35263e,"include pronunciation hints for several names, restructured columns"
https://github.com/kreier/timeline/commit/f8b933a87da3c2d3ff0be795ef093933eebc7806,Replace Aptos with NotoSans if modifier letter prime is found in string
https://github.com/kreier/timeline/commit/46e5ba379f54ff5fc5fc0830b6c4f5af79382f6b,fix the name change in dictionary_reference.csv
https://github.com/kreier/timeline/commit/3b1d67f0d8629a29fc2eb749079beca779eb9c89,make the fpdf2 version the main 6000.py program
https://github.com/kreier/timeline/commit/c0b1e1ee385a08dcf0f0dc793459b88ec9d94304,move the reportlab version on a parking position
https://github.com/kreier/timeline/commit/3341427b1e473afd076170675c2467561b2579d3,preparing for 6.01
https://github.com/kreier/timeline/commit/119a1bda466f4631f1c050ca78d52b388abe8e5c,introduce tags for each key in the dictionary
https://github.com/kreier/timeline/commit/c0acefbf283a123234a830991be160af2f741ca0,"fix graph, now languages shown, and data values"
https://github.com/kreier/timeline/commit/612896c5f85e1e28e7c95e53bc43f4a073e5781a,updated remaining dictionaries
https://github.com/kreier/statistics-diary/commit/42a7469f658e2cb537ec03c5c94c6a11b0baccaa,New project for 2034
https://github.com/kreier/timeline/commit/27e25544b0563f8474fb4378bce78c67e31e229b,updated translation with more automation
https://github.com/kreier/timeline/commit/9d11520de34dfba443b943f067c6d126caa2170a,"Update on translation progress, fix on English"
https://github.com/kreier/statistics-diary/commit/4b88fc563b4ed1de78b8aaf90ba339f6435bd9ff,Update README with pixel calculations and statistics
https://github.com/kreier/quartz/commit/3482f93073b59faddf6f8b1f2b3fc8d01145e746,include some 2026 history
https://github.com/kreier/obsidian/commit/debfad66e98416d288e08149e12812e2c85072d0,include some 2026 history
https://github.com/timeline24/timeline24.github.io/commit/1043a919f289027d9b5c1f7ecef0db71ba3e1b6f,Revise language table in README.md
https://github.com/kreier/timeline/commit/db9546e4c6a4151fa630f5cd4ddf71377058ea43,"include Python programs for check and statistics, update databases"
https://github.com/kreier/timeline/commit/73f9bf416954b964c9a302de6d91c5ba4d165298,"introduce column for checked translation, cleanup"
https://github.com/kreier/logo/commit/1402ef58d8d294cb15bdb9925b1518ac4585d798,add favicon and 32pix icon
https://github.com/kreier/logo/commit/62358cf622b5a5972f72dcf491272f47e3a91680,Merge branch 'main' of https://github.com/kreier/logo
https://github.com/kreier/logo/commit/9962aebe47c1401b9a3374e120f612472e89236e,fixed ratio to increase size of K
https://github.com/kreier/logo/commit/420ba834f68643159ee054a3e42e9fc9ece14171,Enhance README with webpage links and design specs
https://github.com/kreier/logo/commit/72e0b59caee4c082e3a3df002695ad91fd1de00d,updated guidelines and keylines
https://github.com/kreier/thesis08/commit/46af483bbc20d623ffbd6d665e5f42b872f3822f,now 44 pages with all chapters
https://github.com/kreier/thesis08/commit/be49a1d081a79c3a98f335d2643613e5dd7a5c47,expanded chapter 6
https://github.com/kreier/thesis08/commit/e7ea44164363ba325a5622f0f1472918b05c5236,document images first 4 chapters
https://github.com/kreier/obsidian/commit/2d791e28257b85ea7e9f538b2d4a25dab021a23f,"updated version from January 1st, 2026"
https://github.com/kreier/logo/commit/0875f27242d799063d3edbf3952027cd1307aef4,updated designs for saiht.de
https://github.com/kreier/quartz/commit/a288c28f27abe9a5be93247c4b51225ea38fc5e4,"Quartz sync: Jan 1, 2026, 2:53 PM"
https://github.com/kreier/obsidian/commit/c651093aac8248546638c555f3376deff9d03aa1,"Quartz sync: Jan 1, 2026, 2:53 PM"
https://github.com/kreier/quartz/commit/fb977171f86dc6463fab9f8a2ff5aee740e4a57e,"Quartz sync: Jan 1, 2026, 2:43 PM"
https://github.com/kreier/obsidian/commit/594d3710e61b44ecbd8c60843f03739dca2ceee2,"Quartz sync: Jan 1, 2026, 2:43 PM"
https://github.com/kreier/statistics-diary/commit/96f5b2c494d9e23d763150953795a5e3751f2b37,remove daily run
https://github.com/kreier/statistics-diary/commit/8049ba1f36ae41e99de79f3d5a939db4259ba566,extend visuals and structure
https://github.com/kreier/thesis08/commit/e39e18e15776a370e7c3437286803e109dc92b62,now 49 pages
https://github.com/kreier/thesis08/commit/1540b69fc36062dac841d11df2b661fb45a1e5a2,pdflatex competes 43 pages until 4.1
https://github.com/kreier/thesis08/commit/8c0c99458d2f9133994aba2da4b63db1919b4fd7,finished bibliography
https://github.com/kreier/thesis08/commit/7abf429b38a7c9de17c71408be6a90bee02f3596,expand bibliography to original 63 entries
https://github.com/kreier/quartz/commit/5a85cf1ee3849c6a1b3810ee9731a84ed37a5f50,Fix title to have no question mark
https://github.com/kreier/obsidian/commit/bec93c395df94ffb29daa916f1bb3a58b3a30bde,Fix title to have no question mark
https://github.com/kreier/thesis08/commit/61f6809dc200cfc225271e67762a2804a9e57c84,prepare upload to arXiv
https://github.com/kreier/quartz/commit/ea7a3e9264340f9f7db9d26f435edda8aaea8609,"Fix a few links, include external pictures"
https://github.com/kreier/obsidian/commit/f641eed98757c8b6c829988cc493e6d1227dbe5b,"Fix a few links, include external pictures"
https://github.com/kreier/quartz/commit/267a6093dbaf8733e4e5bf4fbc038a705e97f425,update entries from December and June
https://github.com/kreier/obsidian/commit/7ce4df897b42f37fa985a040a31ca12a9c9da169,update entries from December and June
https://github.com/kreier/quartz/commit/85ef5b3520943fd9d84d65469e977ed81613f579,Refactor workflow to update statistics-diary trigger
https://github.com/kreier/quartz/commit/54ad2d3d09eb41bea127135fe226c79d8d8b45f1,Trigger statistics-diary workflow after deployment
https://github.com/kreier/statistics-diary/commit/122558a649606ec4fd19aae3be35dde126be040c,Add repository_dispatch event to update workflow
https://github.com/kreier/statistics-diary/commit/f3ad6d549c8930ed9926c26d95e046358660aa4f,Add update version badge to README
https://github.com/kreier/statistics-diary/commit/095f1ffcc1fe6660140053bec232acb14bea53ba,Add permissions for write access in update workflow
https://github.com/kreier/statistics-diary/commit/2e19ae5d262ddc0e5b89be22a6519773dfae049d,Update GitHub Actions workflow for version updates
https://github.com/kreier/statistics-diary/commit/ea275ca3f8a4703d45bf84ed06861d3397b5cd07,for GitHub Action runners absolute paths - fix
https://github.com/kreier/statistics-diary/commit/c05300827c973f9994a9145e7bdb8a792ff09675,Add GitHub Actions workflow to update version
https://github.com/kreier/statistics-diary/commit/ba688edad405a11512b9c065fe919adafa3af97e,prepare for Github Automation
https://github.com/kreier/tripitaka/commit/e0eff1e9974f4286bcaafe0a3d5c1b0cdb68d6d9,"Fix formatting in README table for clarity, right align numbers"
https://github.com/kreier/communicationspeed/commit/ea73ca33f789f91378d545958aab4b921bfd72a4,Update README with source link for average speed
https://github.com/kreier/tripitaka/commit/a79d8f2d944dd5e235d8af033fbef60a889b6094,Enhance README with additional details and links
https://github.com/kreier/quartz/commit/0c15ba0acd17978337683114c4076d5540917007,"Quartz sync: Dec 26, 2025, 9:45 AM"
https://github.com/kreier/obsidian/commit/9a364b1712454a40020a90e7efe030b1fb289857,"Quartz sync: Dec 26, 2025, 9:45 AM"
https://github.com/kreier/quartz/commit/b329826ad192a2b4bef5a5756c8aeeb02a4ea405,"Quartz sync: Dec 26, 2025, 7:29 AM"
https://github.com/kreier/obsidian/commit/5f8567f1fd7a4c18000c673f6722af8759e55aad,"Quartz sync: Dec 26, 2025, 7:29 AM"
https://github.com/kreier/quartz/commit/c3ec044ecf41e22dfc12eab62871cd32ce423a24,Merge pull request #19 from kreier/dependabot/npm_and_yarn/production-dependencies-82a7bb8ce6
https://github.com/kreier/quartz/commit/d977e74f79a9a96202ec8a95c71ebeda0780cf92,Merge branch 'v4' of https://github.com/jackyzha0/quartz into v4
https://github.com/kreier/quartz/commit/80d5c2a595d615d0a582666f7f7713e1217bf49b,reorganized travel
https://github.com/kreier/obsidian/commit/ffc2ec2e86fe618df4c65cf5db4f832f5e4d0091,reorganized travel
https://github.com/kreier/quartz/commit/f754e65d620a592eda29d76f62913f8f619b5548,update from coffee Trung 3T
https://github.com/kreier/obsidian/commit/df96a9bd50999becc69934f4fa227379b41bc361,update from coffee Trung 3T
https://github.com/kreier/statistics-diary/commit/daedca19bab5413f8d5cf42eaa5b08870b31d374,Enhance README with more detailed statistics and categories
https://github.com/kreier/statistics-diary/commit/70294d18cfa1f3a4b31572f46f50122936deb1fc,combined graphics
https://github.com/kreier/quartz/commit/db898320f858223fb0d8aeb8ef89319153e91d40,"Quartz sync: Dec 23, 2025, 11:37 PM"
https://github.com/kreier/obsidian/commit/ca0156cb37f6574c1f7f01a5f3853b8993fb45e8,"Quartz sync: Dec 23, 2025, 11:37 PM"
https://github.com/kreier/statistics-diary/commit/99c73c051914461191c7dd1edb458b7312440b41,extended parsing of Obsidian markdown files
https://github.com/kreier/saiht-parser/commit/821963cb68965856a18bdc1238ed3b0614b5c779,Revise README for project and historical context
https://github.com/kreier/obsidian/commit/313593dc9e3df70783b485ebc00e4ed8f0b7d7a4,Enhance README with badges and statistics
https://github.com/kreier/quartz/commit/9fae8edda59878480609465e67f41a162a00a86f,"Quartz sync: Dec 22, 2025, 11:14 PM"
https://github.com/kreier/obsidian/commit/1497a58735d3a88420e0966fde1b5c5ebdecdef2,"Quartz sync: Dec 22, 2025, 11:14 PM"
https://github.com/kreier/calendar/commit/f84acefebc36831e03a307f23e7934ac38773321,add missing years
https://github.com/kreier/quartz/commit/7ffc89e1097020a54bf410100919d06b0c1cf707,"Quartz sync: Dec 22, 2025, 5:48 PM"
https://github.com/kreier/obsidian/commit/77f19d34da9ad48c00963c3967fca85cd1501312,"Quartz sync: Dec 22, 2025, 5:48 PM"
https://github.com/kreier/obsidian/commit/c75173663cf30426a2a7cf5b02349f6bb2669b0a,Merge branch 'main' of https://github.com/kreier/obsidian
https://github.com/kreier/obsidian/commit/cc372edf62927eb7054ed0a342732a4bd5ff61f5,backup of quartz vault
https://github.com/kreier/quartz/commit/e77b7cc8b180f0259fc5c3826cc4ce752274699e,"Quartz sync: Dec 22, 2025, 4:52 PM"
https://github.com/kreier/obsidian/commit/3d96db000f8fc87e212e277cf8ebd4b1c360ee07,"Quartz sync: Dec 22, 2025, 4:52 PM"
https://github.com/kreier/quartz/commit/8b5f78c1dbc96d1254bd9b1ccd64bf2af2fa3b7e,Merge branch 'v4' of https://github.com/jackyzha0/quartz into v4
https://github.com/kreier/solarmeter/commit/9844bd382fb9a46e79aa33375a118cf626abf19b,Merge pull request #4 from kreier/1.0
https://github.com/kreier/statistics-diary/commit/9c47fd10a62c5c427468ccc70b7d1d51023e9e15,"parsing three locations, starting word count"
https://github.com/kreier/statistics-diary/commit/52a63449ba01c2a6d717e8197407a044970b7868,Merge branch 'main' of https://github.com/kreier/statistics-diary
https://github.com/kreier/statistics-diary/commit/6753fb69e75483bfa19b5279a467d4d73d9b43ac,parse the first 2 folders
https://github.com/kreier/statistics-diary/commit/7ec66f81973306d0810a5dd4e43e2e32606fb225,Add history section with statistics and links
https://github.com/kreier/timeline/commit/3d27961f50ac314e9f36527c7a5625199a43801d,"include NotoSans for bold font support, for Dutch"
https://github.com/kreier/timeline/commit/6c8f70f432ac1863419c8d3852a21180a6fb1224,get support for U +0331 COMBINING MACRON BELOW for dutch
https://github.com/kreier/timeline/commit/822224f93889eac9cbccf98974a70b2876e21e0e,"updated Thai to looped font, and a few more lines"
https://github.com/kreier/timeline/commit/3b11b7f9cc93b543ec9b82616d87275da0ce4e93,update to Thai
https://github.com/timeline24/timeline24.github.io/commit/93e71500255f75441fc3761f654386f89504429d,Include Dutch
https://github.com/kreier/timeline/commit/b3d5984069aadbd475e55ba70a7367bab473b30d,updated Dutch
https://github.com/kreier/timeline/commit/c3d0bae32aefe8d3a288c6f4fd46dc35d4595c77,include Dutch (nl - Nederland)
https://github.com/kreier/obsidian/commit/cb25e8213c9007054a7c9a69055e0d2851b253c6,Add files via upload
https://github.com/kreier/obsidian/commit/f1f75b11757b79d2c0b9f9a201eb028e6c32cfe0,Create README.md for data repository
https://github.com/kreier/quartz/commit/59e3a28332ce53bdf04974dbc18d4e03b2605de1,"Quartz sync: Dec 20, 2025, 1:12 AM"
https://github.com/kreier/obsidian/commit/c19cae30412aeaa7f748de013b305833ba6cc4d2,"Quartz sync: Dec 20, 2025, 1:12 AM"
https://github.com/kreier/quartz/commit/39fe3cf0c956b996269b13ca94bd870f06a8b77a,"Quartz sync: Dec 19, 2025, 11:47 PM"
https://github.com/kreier/obsidian/commit/bc334e66ebbb1ff43a3a474ff4ca66a7928fd8b0,"Quartz sync: Dec 19, 2025, 11:47 PM"
https://github.com/kreier/impact/commit/6bc1409bb9827cd11e6a8fff04c0a3ce7bb6cd41,Update .gitignore to ignore .DS_Store
https://github.com/kreier/impact/commit/057bcf7c897729567861acccc54023ea0659a134,Update build status badge in documentation
https://github.com/kreier/impact/commit/7796f6bae9af4a89b384516fc5d1532d0a3b721a,Add initial impact measurement code
https://github.com/kreier/impact/commit/18a1dd09e311680e0fc6ff64da66da7744e33e9a,"Update README with build status and project details, no more Travis CI and hitcounter"
https://github.com/kreier/impact/commit/e74ee1a1697f12ac4ea4683d7c2660bf0702fd70,Add impact.py for rubber duck trajectory calculations
https://github.com/kreier/statistics-diary/commit/3bae51d6ae42739638315c309a9293a1e727f189,"include a ""daily visual"""
https://github.com/kreier/statistics-diary/commit/092003b6e4bdae2474fc684822daf1e130125abc,brainstorming about structure
https://github.com/kreier/statistics-diary/commit/58e000b50c3b58f79baec093e438d118c2d6939e,Revise README for clarity and project overview
https://github.com/kreier/statistics-diary/commit/e2cfb1fb65f0cca3c7da2fdc1faadcb9b17c6546,Add files via upload
https://github.com/kreier/statistics-diary/commit/d4e8fe84ae29ebbe558033f93574d6a46e117403,Add README with examples and planned outlook
https://github.com/kreier/statistics-diary/commit/18ef95b0bdaba573798b8e7b4edf4a2bf47da959,Update .gitignore to include .DS_Store
https://github.com/kreier/statistics-diary/commit/f31d7d96476fa361cc2c63f829e4c5380bf94abd,Initial commit
https://github.com/kreier/python2018/commit/d0d1e08b3a01bfd96aa7794eb7071dfe291622e2,Update parse_repositories.py
https://github.com/kreier/python2018/commit/91ad96ff8884df9d4015a83c7745344d9d555f0a,list my 165 or 170 repositories
https://github.com/kreier/python2018/commit/13ebe31698e8503031a9e6b0de7aa7621f931462,Merge pull request #39 from kreier/dependabot/pip/filelock-3.20.1
https://github.com/kreier/quartz/commit/c674a4c2f552acd438cc605db7aecbd72cb507bd,"Quartz sync: Dec 15, 2025, 7:01 PM"
https://github.com/kreier/obsidian/commit/60f3736f24b499828c6d7f1081ab08a7642fb10a,"Quartz sync: Dec 15, 2025, 7:01 PM"
https://github.com/kreier/timeline/commit/f7e8c668bc1994ee7dd7d584028c09f56cc6ad9a,extended korean
https://github.com/kreier/quartz/commit/fa6a4f64be8611ac92d4e61ea2f8fe26924f2a38,"Quartz sync: Dec 13, 2025, 3:21 PM"
https://github.com/kreier/obsidian/commit/0ac3f96af78574110e9a384fdd97607ed05338f1,"Quartz sync: Dec 13, 2025, 3:21 PM"
https://github.com/kreier/quartz/commit/46424457bbf05001be0118858ce99b8b60409bb1,Merge branch 'v4' of https://github.com/jackyzha0/quartz into v4
https://github.com/kreier/quartz/commit/83db3f4ca03902e95d00efa4178f926718fb5dbe,"Quartz sync: Dec 9, 2025, 11:58 AM"
https://github.com/kreier/obsidian/commit/97685ea0b28ae1ca065b36dfa14c42f26197245b,"Quartz sync: Dec 9, 2025, 11:58 AM"
https://github.com/kreier/quartz/commit/1e904729587c8e099a37c10e4d96bce87bf63041,Merge branch 'v4' of https://github.com/kreier/quartz into v4
https://github.com/kreier/quartz/commit/3038044dc51fef7fd15237971c5f77d9a2fee980,"Quartz sync: Dec 9, 2025, 11:51 AM"
https://github.com/kreier/obsidian/commit/06441b286828b817e3b515e5c7bf099e8cd88b79,"Quartz sync: Dec 9, 2025, 11:51 AM"
https://github.com/kreier/quartz/commit/69506a5a074432971b3370874bf446b8f0ddab0a,Merge pull request #14 from kreier/dependabot/npm_and_yarn/production-dependencies-d381b28d70
https://github.com/kreier/quartz/commit/9d5bb3485860b90512d9a8996a35fe080060bb3b,Merge branch 'v4' of https://github.com/kreier/quartz into v4
https://github.com/kreier/quartz/commit/64397977398c20b65698a450beba40bf093eab3f,"Quartz sync: Dec 9, 2025, 1:31 AM"
https://github.com/kreier/obsidian/commit/ef49da94ab730405f4ab596b8ab9ebe881fb3d09,"Quartz sync: Dec 9, 2025, 1:31 AM"
https://github.com/kreier/quartz/commit/9c156353014bd29c85adaf4a5bea3fcecbe795da,Merge branch 'v4' of https://github.com/jackyzha0/quartz into v4
https://github.com/kreier/quartz/commit/49d6a7a00e8a338b1e16808c663347f391065573,Merge pull request #11 from kreier/dependabot/github_actions/ci-dependencies-70833b80ab
https://github.com/kreier/quartz/commit/a26be209eea71dbaa5ac71b62be11da4324c9e27,"Quartz sync: Dec 9, 2025, 1:20 AM"
https://github.com/kreier/obsidian/commit/fa9f93cd166030f233988d3e34a777ed7b97a2d7,"Quartz sync: Dec 9, 2025, 1:20 AM"
https://github.com/timeline24/timeline24.github.io/commit/3f5cbc126a91ba804fb8066f19f16c4f7838f559,version 5.11 from 2025-12-02
https://github.com/vex-ssis/2026/commit/a8a935b8dce9af5e9f6c7d8f6129543701177379,"Enhance README with team performance details, include 6 pictures"
https://github.com/vex-ssis/2026/commit/28bbe3f8d5c83d646b235441656c9ef9372f7b14,impressions from 2025-11-22 and 23
https://github.com/vex-ssis/2026/commit/40e41f27ea16be75e9242bb6875304188643b0da,Revise event details and team qualifications 2025-11-23
https://github.com/kreier/promised-seed/commit/f41f9948c517d373db230dcc1266621cbd357dc7,include comparison with A0 project from 2005
https://github.com/kreier/promised-seed/commit/0a8f58c123b2b156a34e026b5206fa85b29ef9c7,image of v0.1 from 2025-11-30
https://github.com/kreier/promised-seed/commit/17e0307383947939303107d8cdfbb1f3e48212f3,compare required size for graph
https://github.com/kreier/promised-seed/commit/7cadfd25040898a46653bc0922cdf2268472bedb,Enhance README with motivation and size details
https://github.com/kreier/promised-seed/commit/b76c2ef65e94340668e835848b431e13a72a2649,proper use of the dictionary for pdf_title
https://github.com/kreier/promised-seed/commit/e2d23ecbf64b579a0a7dafbef3bc1c1aba534c46,include Title to this project
https://github.com/kreier/promised-seed/commit/b1766af069152047a706e493bc9dd27f02a67d36,"relocate QR code, fixed"
https://github.com/kreier/promised-seed/commit/596e7c239a8eba020036a482ff682341598eb07f,first successful overview
https://github.com/kreier/thesis08/commit/eb9adc43da0a93e5e3a9e21d66601b95d25315b6,"first 6 literature items, appendix"
https://github.com/kreier/thesis08/commit/50df4aec8c9a02c6e9d5dbbcb0193ab7005ab6a0,include Literaturverzeichnis as TEX
https://github.com/kreier/thesis08/commit/0c21a9be95a6299a4998713a5f69456e71356a7d,"split Diplomarbeit into parts, recreate structure"
https://github.com/kreier/thesis08/commit/79af6ed89cc18b465a5651cd1a0b3761f796296b,progress in chapter 2 and 3
https://github.com/kreier/thesis08/commit/6306c84457b9fe3ec932b92f3d2a8afeece1aa41,first extension
https://github.com/kreier/promised-seed/commit/049265effb0ff0c9b65cc2a50b7cbd3c3c96ff69,"include more women, set structure for couples and children"
https://github.com/kreier/promised-seed/commit/f1d76fc0fbbeb9ab1624402b741d9dc1133bf2de,"restructured, families for Mary and Josephs side"
https://github.com/kreier/thesis08/commit/929c0d52ec8efeb9ad328f504de49e86b76c382e,Revise README for 2025 diploma thesis updates
https://github.com/kreier/thesis08/commit/925e03bb37c811512b9c17c855e5dc56f5631f40,Remove {% that is interpreted as Liquid tag by Jekyll
https://github.com/kreier/thesis08/commit/c879233e231b02c7dcc96601fd2a05091aaeac88,include images for visualization
https://github.com/kreier/thesis08/commit/73f5aa86a18c461cf41d50c98a871bc199341457,first successful render 2025-11-25
https://github.com/kreier/thesis08/commit/d92317e3154a5838c5aded1fa51322cf0735b4a1,Add README for recreating Diplomarbeit in 2025
https://github.com/kreier/thesis08/commit/d2789e6cad380a41d433e99170f7e7183826bd34,recreate Diplomarbeit from source
https://github.com/kreier/thesis08/commit/99e7abfce235da4bebe3f714abc94cf14d30e676,reconstructed html with pdftohtml
https://github.com/kreier/thesis08/commit/7d2c0bb08bd051a3bcd5c120840bd2f453d3a15e,extracted images with Poppler tools
https://github.com/kreier/thesis08/commit/c310b1faa983a4653c34ddf2e62cbc1377e295b0,created with pdf2txt
https://github.com/kreier/thesis08/commit/a88ec5bcbf251446a4fc1ea78798ea4312dcceb2,created with pdfminer.six
https://github.com/kreier/thesis08/commit/0ece4f0665a45dfb90935171ab83f5beb563cb58,step 1 recreating the TEX files
https://github.com/vex-ssis/2025/commit/2f643b3289f4b204a16e5ef5e11b18e842f3744a,Revise team details and awards in README
https://github.com/vex-ssis/2025/commit/b5466c2496517edbc9794780ed3bb0787e89ac1e,Update README with new teams and Online Challenges info
https://github.com/kreier/thesis08/commit/9bff391bd84f5b2302291cfe46ad7be80f95485c,Revise README for thesis details and add badges
https://github.com/kreier/thesis08/commit/ea7b51f7086fd0ec68cb77130cdfd571d0abca4e,"Final render from January 24, 2008"
https://github.com/kreier/thesis08/commit/cf741d05b8733f347b52d25d81004a8e5d12b064,Revise README for Diplothesis08 project
https://github.com/vex-ssis/2025/commit/a106ece0bb55949061a71d32dd4f0cca349c1822,Update VEX Robotics Championship details in README
https://github.com/vex-ssis/2026/commit/c7a3cd32598d028f81724abb35ce58edaae3ec2a,"Update README with virtual skills standings, fix typo"
https://github.com/vex-ssis/2026/commit/8697e107cc143cc1a005d4e7375cbe99b83f7e15,update recent results
https://github.com/kreier/language-families/commit/021595cbde62cfc99c2e1dc276e1813c2210b665,Article from nature > nature human behaviour
https://github.com/kreier/language-families/commit/ba2f1ffd6668ed797490cacfc6583a9a93ac6533,Update README with new sections and historical context
https://github.com/kreier/language-families/commit/a58570f92862354e4c7a0296c8abac2e251a250d,Merge branch 'main' of https://github.com/kreier/language-families
https://github.com/kreier/language-families/commit/e67b9a1b74e25df9d1e75bd120324046320012c6,for placing visuals
https://github.com/kreier/language-families/commit/0425a601f9eb2aad36cd46232a6177dcdcefd915,Enduring constraints on grammar revealed by Bayesian spatiophylogenetic analyses
https://github.com/vex-ssis/2025/commit/0455ae9e6a512cde66ca301d568f401ae092c974,Update competition spots and seasons in README
https://github.com/vex-ssis/2026/commit/422cf54ecbe943b1e582b9ff5861e8a68fa6ad53,Revise event information and add signature event details
https://github.com/vex-ssis/.github/commit/530062cb65f27b8dc561dee40994d80ac457b7d9,Add history of Vietnam's participation at VEX Worlds
https://github.com/vex-ssis/.github/commit/1e654bf6e40d9ecab4bf35fb40c74edf507d2bd9,Revise README for 2025-2026 and event updates
https://github.com/kreier/timeline/commit/85fe795b8b16b1cf4bf21c0b2161310567aa472e,update PDF producer and creator
https://github.com/kreier/promised-seed/commit/2344e41173aaca57560f3e2982fba4b8d97656cb,update PDF producer and creator
https://github.com/kreier/promised-seed/commit/e1539063c13a664e6ba6e41d652fb91753cab64c,include producer
https://github.com/kreier/promised-seed/commit/4dc069524236684aee5b27c0a5e19fa57fd33b29,cleaning up for v0.1 release
https://github.com/kreier/promised-seed/commit/d3e922f01f670fce1870bacfb90988f713d65b86,got a A3 document generated!
https://github.com/kreier/quartz/commit/25ad2309448eefa0ec95a7b489f3b465fe1bd1d6,"Quartz sync: Nov 19, 2025, 2:00 AM"
https://github.com/kreier/obsidian/commit/16ef033d3d28077438a32c2656474d0a096b350b,"Quartz sync: Nov 19, 2025, 2:00 AM"
https://github.com/kreier/timeline/commit/366d0ddaab29b357db675cb58c3c414468279e5f,ISO-8859-1 (Latin-1) or Windows-1250 errors fixed
https://github.com/kreier/timeline/commit/9c13b45e7a941893a962bb4c3feca3febf6fcdcb,expanded history of 2006
https://github.com/kreier/timeline/commit/532636872a78185b2330373a900fc0d134f4b042,linked vertical timeline from 2006
https://github.com/kreier/timeline/commit/017c59a5f107d67250d3a4763c6d933e37aa6416,include a recent empire visualization
https://github.com/kreier/timeline/commit/9295fb359bd2a6674dcf93f09a048beb8dec9201,document 2006 history
https://github.com/kreier/timeline/commit/94cbf2765c3ff967e0ecd053361c75d1518ba111,"include structure, reorganize"
https://github.com/kreier/promised-seed/commit/68bdc779f7d71e5e1a865e124a3720faf9d998a5,Include the history
https://github.com/kreier/promised-seed/commit/398158e4d91ff975793b2137847b3754e6d4f729,Merge branch 'main' of https://github.com/kreier/promised-seed
https://github.com/kreier/promised-seed/commit/bead54c4160781101bc5ce2a795c2a6d22d984f2,history and size considerations
https://github.com/kreier/promised-seed/commit/b211c07ac67cef8574700f832f649e723c94fff8,Update .gitignore to include .DS_Store for Synology Diskstation
https://github.com/kreier/promised-seed/commit/94848ca1528a39d621691b86b90451101a7d629b,Initial commit
https://github.com/kreier/quartz/commit/d4fa0422dececda82553c165c5b983e70acd046a,"Quartz sync: Nov 16, 2025, 2:42 AM"
https://github.com/kreier/obsidian/commit/54a12270dd0b84f1f116477c544a5697d8588b11,"Quartz sync: Nov 16, 2025, 2:42 AM"
https://github.com/kreier/quartz/commit/11e4fc15f8ddedd56c9f8ab5940d1fd19b745d01,"Quartz sync: Nov 16, 2025, 2:21 AM"
https://github.com/kreier/obsidian/commit/325a4a173a85d7899aa9258c1f5839a39a0880ba,"Quartz sync: Nov 16, 2025, 2:21 AM"
https://github.com/kreier/quartz/commit/807f7cfb60f2e1732088f24763df731cd96df5a0,"Quartz sync: Nov 16, 2025, 2:17 AM"
https://github.com/kreier/obsidian/commit/600d10176df23fe0ea6311cbe2d9c31e16b6d888,"Quartz sync: Nov 16, 2025, 2:17 AM"
https://github.com/kreier/logo/commit/c288d8a008e243cd7c4d29e7ba8961f606e925dd,5x5 raster for logo
https://github.com/kreier/quartz/commit/6e5e879f37670a54ce054fce2d7467f2e107f26c,slowly finding a working structure and date format
https://github.com/kreier/obsidian/commit/f6a7cf7d364fca22537214504c659e6b815bfe32,slowly finding a working structure and date format
https://github.com/kreier/quartz/commit/f8c373ebf78244aa2aee7f830f39e66ee4db065b,Merge pull request #8 from kreier/dependabot/npm_and_yarn/production-dependencies-3f756e6727
https://github.com/kreier/quartz/commit/023239fdd0731569d270e5f7831e46c8cb6ce968,"Quartz sync: Nov 15, 2025, 12:38 PM"
https://github.com/kreier/obsidian/commit/ca0ebcb89da0fc49d1d0c7bf2c6dd7ebff34c117,"Quartz sync: Nov 15, 2025, 12:38 PM"
https://github.com/kreier/quartz/commit/043f0939b5672fc593dd74549ea81fe03f788eac,Merge branch 'v4' of https://github.com/jackyzha0/quartz into v4
https://github.com/kreier/quartz/commit/e91c46d779682068b3ededfc623107c29577c720,little restructure
https://github.com/kreier/obsidian/commit/b5c26dc32db98e7985077b61865fbc7e25b622ca,little restructure
https://github.com/kreier/quartz/commit/070ab9da4f9b523e73bf9ad62c2240b477777397,Merge pull request #7 from kreier/dependabot/github_actions/ci-dependencies-5aba28dcfe
https://github.com/kreier/quartz/commit/be2bc1c0ca88269baccf9f4ecc12e30ff81f1c76,Merge pull request #6 from kreier/dependabot/npm_and_yarn/production-dependencies-a5d154a665
https://github.com/kreier/quartz/commit/7e3d66e3f6090a4ced74d4c4aa1ee2deef828d81,Merge branch 'v4' into dependabot/npm_and_yarn/production-dependencies-a5d154a665
https://github.com/kreier/quartz/commit/1cd4bac43c722d639fa42ab9bfdd2c43ec615d8a,Merge branch 'v4' of https://github.com/jackyzha0/quartz into v4
https://github.com/kreier/timeline/commit/e46ec304b64de3646e2aa2c262c57a56fc0e77dc,Merge pull request #76 from kreier/5.11
https://github.com/kreier/timeline/commit/6ff93d8bb380f88950990fc64e09fa411926c334,"reorganize China 3, 16 and Sui periods to avoid overlap in de"
https://github.com/kreier/timeline/commit/87a542a92878c4b5c7778d28472c98231108d447,move three and 16 kingdoms up with Sui dynasty
https://github.com/kreier/timeline/commit/272fcd39ddda597825c86f46793f167f2d916f60,include Sui dynasty for broken rice
https://github.com/kreier/timeline/commit/47ad0bbe7471db3c970dc0955e26c63bed4a83bf,Merge pull request #75 from kreier/main
https://github.com/kreier/timeline/commit/d261d155c61d6b69f5186c56b22b04b9955d3521,Merge pull request #74 from kreier/5.10
https://github.com/kreier/study/commit/b3c3a620f5e3527a4bfa88fef4e7cbc67a7fce5b,Finished 2025-11-07
https://github.com/kreier/study/commit/aee3014a2c3c4cd103383f6ce96602bd67fb7d33,2025/11/06
https://github.com/kreier/study/commit/1a45ca55f554cba9fb0ca738f2a87e3799a66240,2025/11/05
https://github.com/kreier/study/commit/7e1e4d5bbf8090ec1203760a361c81ca5246b7e2,trip Hanoi to Sapa
https://github.com/kreier/quartz/commit/4e3e33687e13945ee35f234aff9e2337e68611eb,updated structure with distinct folder names (for Breadcrumbs)
https://github.com/kreier/obsidian/commit/cccf0c8878d4af8982fcac52c9010bfad034bc30,updated structure with distinct folder names (for Breadcrumbs)
https://github.com/kreier/quartz/commit/fb4402919989f65b1de09bbb04fabb74161a5d5c,Projects and project was still mixed up
https://github.com/kreier/obsidian/commit/b76e62bbbf9a64c13b5ef90b56a6d1a38894a984,Projects and project was still mixed up
https://github.com/kreier/quartz/commit/e970e13581b322beef7e403bf84d98ba23313efb,"new overview, empty link removed"
https://github.com/kreier/obsidian/commit/cd89de84453421eb1da3b6394fcb5796f506173c,"new overview, empty link removed"
https://github.com/kreier/quartz/commit/b71b31a5e9e1375cc0aca1549193920f4337a729,"remove canvas, reorganize"
https://github.com/kreier/obsidian/commit/c1a2b66371cdc73d54c94002b7161c29224d3142,"remove canvas, reorganize"
https://github.com/kreier/quartz/commit/afaf872284a06ee32abcaaa30930f8286e323954,"reorganized, removed suffix"
https://github.com/kreier/obsidian/commit/50aade6e20ecf0baec002a8edc661270595a7070,"reorganized, removed suffix"
https://github.com/kreier/quartz/commit/55be1d16cd8760dc9bd0ff157dcd278b7f9b9ca8,"tags added to kreier.org, sitemap and timeline. And created date."
https://github.com/kreier/obsidian/commit/801643b4f6e997e41ba11983da91a5c4467c6691,"tags added to kreier.org, sitemap and timeline. And created date."
https://github.com/kreier/quartz/commit/ad9a364a95aac6473d95e34180f5a2016670b75c,finally all nodes are connected for the Graph
https://github.com/kreier/obsidian/commit/f89824ddafb6b0ac20625e7bddf4bd4d98dd0a09,finally all nodes are connected for the Graph
https://github.com/kreier/quartz/commit/fa06818a15213c7a94c1fbe9536bd604947631f6,Hanoi morning update
https://github.com/kreier/obsidian/commit/52da3c47aaaa244ab37c1db0b6d55cb94b5217ed,Hanoi morning update
https://github.com/kreier/timeline/commit/2d8731482e7bae80f76c402b027eafe6fbd4b709,Update dictionary_zh.csv
https://github.com/kreier/quartz/commit/40109c773b49234609fd5fed588cbd2a9772b4df,Merge branch 'v4' of https://github.com/kreier/quartz into v4
https://github.com/kreier/quartz/commit/97b836252ec6c9496c8b45713c1b871ed363e9ac,fix small details
https://github.com/kreier/quartz/commit/fd7a36d80785435102a8a6f7f8521861cc56a004,Add GitHub Actions workflow for deploying to Pages
https://github.com/kreier/quartz/commit/30343c1c70edf182c72c9e883c208fba6c2fa32d,Add GitHub Actions workflow for deploying to Pages
https://github.com/kreier/quartz/commit/83ed6efddcf5286cfa92a5588e6f288ecf6cb4ae,Reorganized
https://github.com/kreier/obsidian/commit/9a6c6bee7338ed2363060d01bd7bd2f4b18f6b08,Reorganized
https://github.com/kreier/quartz/commit/fc2b583e7b08d7b61eff983528fc9459f56814ab,"Quartz sync: Oct 21, 2025, 10:47 PM"
https://github.com/kreier/obsidian/commit/a7c11513b98d2923113b1fb853e9906dcb245b30,"Quartz sync: Oct 21, 2025, 10:47 PM"
https://github.com/kreier/obsidian/commit/b8505845f22b768611664cebb29c61c10e6e0db6,Prepare for Quartz 4 with npm and node.js
https://github.com/kreier/notes/commit/b91bbf34b4d8773dc975283591a0a6d0b5087ca5,Initial commit
https://github.com/kreier/obsidian/commit/757d919a782dd7067e32b4774cb39895f67830b1,New entry at new location of fault
https://github.com/kreier/study/commit/22c4f3a78def604ed557ee2b99ce71b460ee3f96,returned 2025-10-20 from Phnom Penh
https://github.com/kreier/obsidian/commit/bd9109486f95cd116eb88c52776b841f6651d66b,backup 2014
https://github.com/kreier/obsidian/commit/edecc1e2a3e6439a6d1363466b698f48a433da0d,Update .gitignore to ignore .DS_Store for Synology Diskstation
https://github.com/kreier/obsidian/commit/c1e00d3ad7578cb20354bf3c971306e9194a09e7,Initial commit
https://github.com/kreier/saiht-parser/commit/5d57a62d25aad1309da88ff10127b2cffae8d5b6,Merge pull request #5 from kreier/beta for v25.10.05beta
https://github.com/kreier/saiht-parser/commit/1299ff4bdad242ee87cc8d8f1b99bfdf47db21a3,now properly sorted
https://github.com/kreier/saiht-parser/commit/cda65844800a4075f7ff13749d5576a28cb4605f,"two new articles, including sort"
https://github.com/kreier/saiht-parser/commit/8633dbfe5a7ec1987f943e93f9e377f323f86fe1,Merge pull request #4 from kreier/alpha
https://github.com/kreier/saiht-parser/commit/31d71f876db3ffe8173613c6d299af91883aa2f2,some work from 2015
https://github.com/kreier/saiht-parser/commit/03d7b98f1796b6a0c05494e17f3254957c02c9a8,Rename index.html to index_old.html
https://github.com/kreier/saiht-parser/commit/d9e0aa2b5c757d3e829b6f77e2e39ca9caed6414,Merge pull request #3 from kreier/alpha
https://github.com/kreier/saiht-parser/commit/d0729c8429156a88ac2390cd0c217253004786d4,L1 and L2 lists linked
https://github.com/kreier/saiht-parser/commit/b05aea4be649c3d4c0d1c0a1cdb0397abc95ac73,L2 and L1 parsing with text done
https://github.com/kreier/saiht-parser/commit/f8a5802ab9e7be218bea51f05cf9bf64b841e658,"number event fixed, L2 output works"
https://github.com/kreier/saiht-parser/commit/ecf7a09784a5415d4a2479977d943247ba5db697,Merge pull request #2 from kreier/alpha
https://github.com/kreier/saiht-parser/commit/cf07ccf4a3c63c06c39703ce504647206cff5761,include YAML - Aint Markup Language
https://github.com/kreier/saiht-parser/commit/e44822fe0677c1768af69666c7f98193132d32df,automatic generation of README.md works
https://github.com/kreier/saiht-parser/commit/e6bed6368839bd6a0e823681ae69de7550e10c02,v25.10.03 creates list.csv for all events
https://github.com/kreier/saiht-parser/commit/22149d33b693e3b966c4c587eee1a81a8aabc72d,Merge pull request #1 from kreier/alpha for v25.10.02
https://github.com/kreier/saiht-parser/commit/94511ef1aed24a4d260784549e21f57502f8f110,actually did not apply for Mexico. They offered
https://github.com/kreier/saiht-parser/commit/1d3d3346fa18d071e2e5dd0a00ff57e8a9d2b270,"parsing of subfolder works, seach for MD files"
https://github.com/kreier/saiht-parser/commit/056d1f095da8537927b972b709b50ce4ab3865b9,"fix typos, include a list"
https://github.com/kreier/saiht-parser/commit/9b716d60d662724c823f498bc9185a79735a9ef7,more history from teaching
https://github.com/kreier/timeline/commit/acad89dc6b508dfb853718720156300dfd4328a9,reduced image size to reduce final file size
https://github.com/kreier/timeline/commit/f77ee57040db26e6e9da1f6312cb5801c6e122a8,FINALLY include Gudruns image from 2024
https://github.com/kreier/saiht-parser/commit/f7dcb95f27b54bac40049f6854829583675ba631,fix typos
https://github.com/kreier/saiht-parser/commit/3652ab6f5a3a55da895cdd3f5a842762f36caba3,"expanded history, typo"
https://github.com/kreier/saiht-parser/commit/61a83d7ddd67a5cdfa4a06509ea08012092e63a7,more visuals
https://github.com/kreier/saiht-parser/commit/e1739be50cb76c5d1d96adb44c62b736858b4a88,"typos, grammar"
https://github.com/kreier/saiht-parser/commit/8691dc2b29aef7c6d2a38b6fdbd3212bc664ec85,extended history of last 12 years
https://github.com/kreier/saiht-parser/commit/aa77f68d218d8b91c04ad5b8a9ce8e905cccdc71,"typos, grammar"
https://github.com/kreier/saiht-parser/commit/c0ea00ffea819c13e7dcdcf89da4d5937bfd08c3,extended reflection of the last 12 years
https://github.com/kreier/saiht-parser/commit/f83efb5b559d785a9951164b8a868706b0e307c0,Test in correct folder
https://github.com/kreier/saiht-parser/commit/067ac98476b18f5d9eb3a5958eb004c9446f021c,"same content, but named README.md for github pages"
https://github.com/kreier/saiht-parser/commit/af29bb43f01b32d1dcfb598c21378dfa77f06894,review 2025-10-17
https://github.com/kreier/study/commit/8ec259932d864ea5f553f74ca50201698b7f19ac,a few days in Phnom Penh
https://github.com/kreier/saiht-parser/commit/f792d4e8bf35eec0f0a5e6ec79b846093efc7f75,first rough outline
https://github.com/kreier/saiht-parser/commit/be65fd23bc2d16c712cba079fae9530ce2755fff,Update .gitignore for Synology Diskstation
https://github.com/kreier/python2018/commit/82163f1c3d1dc890c2ada19f2832ce81ed874ad4,"Jekyll works, but ignores the config if the filename is wrong"
https://github.com/kreier/python2018/commit/1c2754080dc087b0066b19f9555f974119531ba6,found the culprit - index.md
https://github.com/kreier/saiht-parser/commit/05ab54b648a889289c7b05f0b98390cd5899d60c,outline structure and idea
https://github.com/kreier/python2018/commit/2e5acc2e3e763b8ec577bb0b049e2b1f06d15c30,Jekyll site generation looks broken
https://github.com/kreier/python2018/commit/3d6f9b5f4b312642514e56053c77c80db3f39d03,Website with Jekyll
https://github.com/kreier/python2018/commit/b39ffb244cb68372a0fbf1763b0bd0110a0b54c4,Create jekyll-gh-pages.yml
https://github.com/kreier/saiht-parser/commit/19ea170038626971c4f359dce80703a45d719feb,Initial commit
https://github.com/kreier/python2018/commit/960d77d973cb856c1dba0d2238e0d6cd78241abd,"Update esptool, but leave Minerva unchanged"
https://github.com/kreier/python2018/commit/2674e743d415d068f9c14e196a1c4ee2ddb1d2ff,Merge pull request #38 from kreier/dependabot/pip/gevent-23.9.0
https://github.com/kreier/python2018/commit/d583f652905ee99785d00ccd480b5aca7d4baada,Merge pull request #37 from kreier/dependabot/pip/dash-2.15.0
https://github.com/kreier/python2018/commit/b2136db9417694f4c603557bd593c8444fc1cd2f,Merge pull request #36 from kreier/dependabot/pip/zipp-3.19.1
https://github.com/kreier/python2018/commit/bde69e496a3489e0c7cad72d2d6011eb9eeffff2,Merge pull request #35 from kreier/dependabot/pip/dash-html-components-2.0.0
https://github.com/kreier/python2018/commit/a4ccb17e0204adf45b48ddc2721796f871d8c0c3,Merge pull request #33 from kreier/dependabot/pip/idna-3.7
https://github.com/kreier/python2018/commit/0ae4c2b53183721526c56e91d3abd81db7f4d755,Merge pull request #34 from kreier/dependabot/pip/jinja2-3.1.6
https://github.com/kreier/logo/commit/03a7e3a8e0a512f173089109b4265e5e4bd5e807,ideas from 2018 and 2025
https://github.com/kreier/bilder/commit/f11a1160f517eaf40716435c114693d92a798990,ideas 2025
https://github.com/kreier/prime_gaps_line/commit/839074fd73bf829b5cbaeb3364faa75aad26205f,cosmetic sugar
https://github.com/kreier/python2018/commit/7e8bbf555602548bfa4354fccfb9a823195d0357,Merge pull request #32 from kreier/dependabot/pip/cryptography-44.0.1
https://github.com/kreier/python2018/commit/19d389483dbb3fb5e79e764ee631c9ca6d3adb54,Merge pull request #30 from kreier/dependabot/pip/certifi-2024.7.4
https://github.com/kreier/python2018/commit/34d103e2c4fdf6468aebeb147fe38edb8fc7b06c,Merge pull request #31 from kreier/dependabot/pip/numexpr-2.8.5
https://github.com/kreier/python2018/commit/961d7b0af24840c9b1c3384c6df6fa54f155db41,Merge pull request #29 from kreier/dependabot/pip/dash-core-components-2.0.0
https://github.com/kreier/python2018/commit/0b00ad427a0a74c6dba521ed1ef66e4bf1b3dab8,"No more TravisCI, but a version"
https://github.com/kreier/python2018/commit/ea45517897fcfb5660f40ab5c60ea2d9df4cef1f,Merge pull request #28 from kreier/dependabot/pip/certifi-2023.7.22
https://github.com/kreier/python2018/commit/8635a9f1c1d43020741d47ccd2359ec95cb79abb,Merge pull request #27 from kreier/dependabot/pip/cryptography-41.0.2
https://github.com/kreier/python2018/commit/e1a8478ead92930724bd0fba50b199a0b8f8acd2,Merge pull request #25 from kreier/dependabot/pip/flask-2.3.2
https://github.com/kreier/python2018/commit/cb7b0f0e8f7fe9b344868cff05dcc4cb556b6da4,Merge pull request #24 from kreier/dependabot/pip/future-0.18.3
https://github.com/kreier/128x64/commit/39128c24d648fc15e044c7fce8fa612768d364b5,include visuals for this project
https://github.com/kreier/logo/commit/fb2510b7a1ef6f1363de4baf1bc2d2831b93be15,extend examples from 2019
https://github.com/kreier/study/commit/43cd0a87ad33a4332a42c13ab7aa061d994663f4,2025-10-12
https://github.com/kreier/logo/commit/5b02cccf40aeca57be46f8b89a0f74295c9d01e0,Actually include the logos for documentation
https://github.com/kreier/communicationspeed/commit/dc193e97abd9ad83d59a15d7c7559e89bcc2531d,Merge pull request #5 from kreier/speech
https://github.com/kreier/communicationspeed/commit/6ead04dcec8513540bbd0f5fec6bbe5445997b5d,foundation for investigation
https://github.com/kreier/timeline/commit/3828cf217cd0b7200ed6e19cfdcf38a1eb5940cd,New history in German added
https://github.com/kreier/timeline/commit/d927a656fa67497eb05454721e9e25760cd851e9,Merge pull request #73 from kreier/main
https://github.com/kreier/timeline/commit/69421f5e081c6ca601efb1f3d7a36d87dba28876,"include Seljuk, Vandal, Francia, Lombard"
https://github.com/kreier/timeline/commit/6300b17bfb028bd217e94a4d480f20497a5b32b5,Update README.md
https://github.com/kreier/timeline/commit/96f2a48c5e3542783a04f8adade8ba0b3735a421,Merge pull request #72 from kreier/5.10
https://github.com/kreier/timeline/commit/b81b631e9aa362c891a484c463575c98ac019c6e,update visuals and history
https://github.com/kreier/communicationspeed/commit/05477e93e7ed334548d50c3872e8b6eeeb7af3c9,fix filename
https://github.com/kreier/communicationspeed/commit/4e8b503d4c97d56f2bee3a898993d86614445dc8,updated graph
https://github.com/kreier/communicationspeed/commit/c610ba50864e506eb1aa784bf922290517789958,differentiate further
https://github.com/kreier/communicationspeed/commit/95724588605b557b339e150675e7fd0a427a77ad,Merge pull request #4 from kreier/type
https://github.com/kreier/communicationspeed/commit/c46121375889fa704aef0cf20ab2745beb17c9c3,Update README.md
https://github.com/kreier/communicationspeed/commit/050b1c6b0c96c14df119582952caafc0cde679eb,include data tables
https://github.com/kreier/communicationspeed/commit/cfebdb4c9fb7093ad80c6f0a1b669a88f08a81fe,include study from 2019
https://github.com/kreier/communicationspeed/commit/4e2a29260f3fcac194f1fdf4278f0f05373a814d,include visual
https://github.com/kreier/communicationspeed/commit/e740a96d39087e4a0341287d67c157783eedc00f,Merge pull request #2 from kreier/speech
https://github.com/kreier/communicationspeed/commit/e8cbef2bdd5ef82a1c1bd4d5a1feaf2aad926684,Update README.md
https://github.com/kreier/communicationspeed/commit/420e74b52e367f926520e2a86706f77f4ccd1c09,Merge pull request #1 from kreier/speech
https://github.com/kreier/communicationspeed/commit/8e77acf78a5cae9400d0a827e7bc695ce5703070,"LaTeX not rendered for the website, so replaced with image"
https://github.com/kreier/communicationspeed/commit/65de6feacf97e4b04c3283ae1f151e108dd93951,Create text-to-speech.py
https://github.com/kreier/communicationspeed/commit/5c2c748d15854a4e26e5321a5a45aa59b5015467,Update .gitignore for Synology Diskstation
https://github.com/kreier/communicationspeed/commit/5624d81d67ce75afa094db1ddd9e92c6e7dff096,Update README.md
https://github.com/kreier/communicationspeed/commit/6e3271667a2f7c1d3c9eaefa4cb93ddd0038bdc8,Initial commit
https://github.com/vex-ssis/2025/commit/62074175da9ed2e4bece17c28c33583646c74c34,include SSIS team names
https://github.com/ssis-robotics/team426-2023/commit/2d6fb7b6e7b5a15726d1ac928fa209a19d2daeea,Create gradle-publish.yml
https://github.com/ssis-robotics/team426-2023/commit/28b3dcc209c36c0e7a6d541421f6afd4ed686083,include two badges for website documentation
https://github.com/ssis-unity/unity2022/commit/cfe74040df170bc80f318c770a644c577cb5fada,include license and release
https://github.com/timeline25/timeline25.github.io/commit/faa77d9f0d0d06fbd155fd51d8be3615ab39b3cc,Create a new file just in your browser - even on a smartphone
https://github.com/timeline25/timeline25.github.io/commit/ddd2d4d1112a9bf8fe1c45eaa00dee45e5f09e2b,Create code.py
https://github.com/kreier/timeline/commit/9b2bb7995354609a32a8ce4096be517cf2ed8395,fix minor mistakes to support Jupyter generation again
https://github.com/kreier/timeline/commit/ac9ddb5c048b6c57fe309c5c2f0fb6dc36aacbd6,Updated to v5.10 with new Daniel 2 image from fiverr
https://github.com/kreier/timeline/commit/f344ddb0f1a76378ca804035b72223427d61b37b,version v5.10 for documentation 2025-10-07
https://github.com/kreier/timeline/commit/4abf01a90c00637417c56d68f096e64562974826,fix Babel (Ba-bรชn) and one overflow 7)
https://github.com/kreier/timeline/commit/a3c32b2c2b8c9a60446731be6c20cae1d9e227a5,Merge pull request #70 from kreier/main
https://github.com/kreier/timeline/commit/b3f211893904cec22237ac7b995aba4de34f721d,include Deborah and Jael
https://github.com/kreier/timeline/commit/e60aceb48605004f472569889cc24e25c025c1b2,update Vietnamese with 20 families and nations
https://github.com/kreier/timeline/commit/92b15dca0720391d086a6892bb3d6c43f52ae8d0,include Aleppo Codex
https://github.com/kreier/timeline/commit/4d7b86898d0133fe39ddb207639c52b747bf6570,expand Vietnamese to 5.10
https://github.com/kreier/timeline/commit/0f1cf56e41513d77a28b23a72b4c9725f3851e52,include Aleppo Codex
https://github.com/kreier/timeline/commit/0c5ff7c8bef691009d69a20b267f7fffbfcb1853,version 5.10 from 2025-10-01
https://github.com/kreier/timeline/commit/25ced641b79060c30838d94339ea82471471eef2,missing QR codes will be automatically created
https://github.com/kreier/timeline/commit/04e591b911b02b9cf34ca7d1c5fb7f16e58be548,"restore to 5.9 for comparison in float values, fixed 2026"
https://github.com/kreier/timeline/commit/4c117ac345f7060a9047a6c6edfecdda62e3e0c4,"fixed fiverr2 Daniel 2 image, made new default image"
https://github.com/kreier/timeline/commit/8eb864f46537a5e70a315f3e89bed8926b53e53e,Trแปnh lords and Nguyแปn lords is better than Revival Lรช dynasty
https://github.com/kreier/cru/commit/00693a119a4f7dd5787f4f69e26aed5e603e2957,restore original GPL-3 text
https://github.com/kreier/cru/commit/757d0114ff40a491ff9b19b35524662ea1b349ce,Merge branch 'main' of https://github.com/kreier/cru
https://github.com/kreier/cru/commit/c53ac36db139dd4cdb35625c1fa17bb5caa9144a,use license text provided by ToastyX
https://github.com/kreier/cru/commit/e76be94843d724be22daa1206ae4bd6a1f4e7636,Merge pull request #3 from kreier/1.5.3
https://github.com/kreier/cru/commit/0f10d982c7769155f2f3af74edb61d6de077334f,mirror reference extension blocks from monitortests.com/download/dat
https://github.com/kreier/cru/commit/28234597d98d8b9267540dcbf8849ed3bd37aa1b,Update to new v1.5.3 and information from 2025-08-26
https://github.com/kreier/cru/commit/9a5a3c8180139e750013c1a1ade4cdffe5d6d35a,version 1.5.3 from 2025-04-28
https://github.com/kreier/timeline/commit/a793a5604398522f370f4458983cd0fe7849d6ee,update Ukrainian and German
https://github.com/kreier/timeline/commit/1def51b60da4469338f5caf81fd341040144ecf9,create required QR code with python
https://github.com/kreier/study/commit/886bda5cca966a5f92e165cdf9e7f68b73db7f26,2025-09-30
https://github.com/kreier/ESP32/commit/c8a7439ebcc762b24d52443fbaf3a6add7b824fe,cleanup
https://github.com/timeline24/timeline24.github.io/commit/db3faf4df53c3666ca3a936595e4ce2a20c6a424,version 5.9 from 2025-09-29
https://github.com/kreier/timeline/commit/f6918f6068807c28470d3a03ab96af21746431b2,fix missing images for webpage
https://github.com/kreier/timeline/commit/155bf5ad8d1ce153b949c64d97145b56aebdf72c,Merge pull request #69 from kreier/5.9
https://github.com/kreier/timeline/commit/8056241ec5fbdee19cfd56f84076ebc9175aec5f,Link more translations
https://github.com/kreier/timeline/commit/d4693c7632dc9d5a17baf975c3b0e2272eafc060,now 194 languages supported by googletrans API
https://github.com/kreier/timeline/commit/70586e6e7637300e93bce9195ac764d1c6daf3fe,updated languages
https://github.com/kreier/timeline/commit/aaad928d65d130e83fdedac7590dc2f9a3684a61,fix autotranslate for googletrans 4.0.x
https://github.com/kreier/timeline/commit/64d662a11ac9f38afb3a54435f08351759e7f675,add American Civil War
https://github.com/kreier/nam-electric/commit/91fc6d3f726451dd71b53f85261ae40b86ec82c2,Update README.md with badges
https://github.com/kreier/nam-electric/commit/98b00fe0ee4fe5867976416176dd0accf311374a,include Jupyter Notebook solution
https://github.com/kreier/nam-electric/commit/1dfc5f481464af5f72cd379add646861f177b8ce,Update .gitignore for Synology
https://github.com/kreier/nam-electric/commit/4ce5165242de5680e2a0d17046e56ed55d5d05b9,include visuals
https://github.com/kreier/nam-electric/commit/9ad78f27d9a065e10ee433a30b66901f9e3e4624,to be linked into the Jupyter notebook
https://github.com/kreier/nam-electric/commit/f74a837229856e852b299956071bbc662e9c6169,Create README.md
https://github.com/kreier/nam-electric/commit/7a7ed6fc63a9dc387e5c5b834a3b9f77b3b3de94,Initial commit
https://github.com/kreier/language-families/commit/8a7044dcc610685e980da3f1448430e57445476d,include more information about digital Geographic Informastion Systems
https://github.com/kreier/language-families/commit/6b9c844ef15897d504dfb35fba0b29a7d2efd21d,Merge branch 'main' of https://github.com/kreier/language-families
https://github.com/kreier/language-families/commit/c2465e2aeb05f9b4eba8df0591e7c11776aabb3e,New Zealand example map colored
https://github.com/kreier/language-families/commit/bdee9aecbf94f782a586956aeea679244165772a,Update .gitignore for Synology
https://github.com/kreier/language-families/commit/9d718ac5ed9f73e36652f75d0f053d2e537432ff,Update README.md
https://github.com/kreier/language-families/commit/6c36b6b08096f6a0d11346153308ea96bd2308ee,two examples from Wikipedia
https://github.com/kreier/language-families/commit/79b9204e8437817756e575681652ce1e6fe063a7,placeholder for more images
https://github.com/kreier/language-families/commit/a764be65951ca6a5b275f249abe4eb1298c6deb3,Initial commit
https://github.com/timeline24/timeline24.github.io/commit/293b3bde5c3af5d9c2d34a833d7523e45908f6af,version 5.9 from 2025-09-25 ms
https://github.com/kreier/timeline/commit/9ae5ec560e9cf0b9e936268ac22d74c09b475171,"Update comparison image for first 4000 years, and latest edition"
https://github.com/kreier/timeline/commit/a66fdc225020cdfdb0dd9e4ffe1de9b89f30e3f8,Merge pull request #68 from kreier/5.9
https://github.com/kreier/timeline/commit/70f70ffa5c500336fa4affa1b1fbab2d8153b2eb,updated images for documentation
https://github.com/kreier/study/commit/58ac9febae2df42817afa7aea0b81e7151ec7cfa,continue listening
https://github.com/kreier/timeline/commit/72461099735bae73a72deb76f0802774163a7347,"update Cebuano, Estonian (et) and Malay (ms)"
https://github.com/timeline24/timeline24.github.io/commit/a0bcab26107ccdc96ce89bd4652a8ebac8df55bf,version 5.9 from 2025-09-25 ceb
https://github.com/kreier/timeline/commit/013ad15c800eeda0c6aee1b56644089531221822,Merge pull request #67 from kreier/5.9
https://github.com/kreier/timeline/commit/f7ffdaf6e6f309a94cb5e59b366e80833ff9b6ed,"fix English, upgrade French to 5.9"
https://github.com/kreier/timeline/commit/aebb733c67c54a856704c3aa250b895a440c40ff,"new translation for 72 new key phrases, finished German"
https://github.com/kreier/timeline/commit/5cdf9bb107252d61767afafa82199a62c16f15d8,"minor fixes, overprint for 20) Hivites [Gibeon] over Deluge"
https://github.com/kreier/timeline/commit/9b1f17def59b56d58c5858f0061355fd795b38b9,"check for duplicates, fix small mistakes"
https://github.com/kreier/timeline/commit/a447cb83a06d0ce93dfb2d50904d624ae104d352,reorganized Noah-Terah chart
https://github.com/kreier/timeline/commit/025be810dc6b5c89e4893ebcfc49a91945bffb7b,include Hivites - the Gibeonites were Hivites!
https://github.com/kreier/timeline/commit/2f481fabb2128955f68b2e04c5fec88cbc792cba,"fix typos, include Amorites"
https://github.com/kreier/timeline/commit/eaf05f8dca0b0e3e9f3c188d59518419a6e93614,extended footnotes for 12 more nations
https://github.com/kreier/movies/commit/80cfe4fb852783e7fe94aecbf86ce43ddeee2a91,update website
https://github.com/kreier/movies/commit/f49085400c40e1407c7688e1332b1c7d6ca66b5d,Include history from 2014
https://github.com/kreier/movies/commit/738c344386933e8b93c3aa15adf087fabaaa0e9a,include graph from October 2014
https://github.com/kreier/movies/commit/8122b55f01abe49d989cbd49e72c55ae814246d4,update September 2025
https://github.com/kreier/movies/commit/f123c80350d65eda017cff716477ac03e15b85eb,try some imdb APIs
https://github.com/kreier/timeline/commit/cdb815d5be961f6093866f708cc6b5c2c8b879d7,extend family tree of Terah to Noah
https://github.com/kreier/timeline/commit/1a781a11f9f29697d4d158453e6928b7da0cfa5c,include Edo and Meiji period of Japan
https://github.com/kreier/timeline/commit/b26a12a9f7986b13d31a9c263d63290b3fc8d65f,include 4 Vietnamese dynasties
https://github.com/kreier/timeline/commit/f286079d1b65d5f7c072a2c03f63b9faaf1a161c,Include Wulfila Bible and Pismis 24 NIRCam 2025/09/11
https://github.com/kreier/study/commit/42d4cb3707c74e3fafbffd8e86fbf4362ed2838f,percentages till Offenbarung
https://github.com/kreier/study/commit/b9c008831a8aaabf488f36555d92a2df3a616f82,into Psalms on September 19th
https://github.com/kreier/timeline/commit/daeabf330dade6692b2fac9719efe3ba1890ea0b,increase from 131 to 172 files
https://github.com/kreier/timeline/commit/7be1d5e941935bdd16433b8c16764ca9ee9d1b92,include 20+ new source files
https://github.com/timeline24/timeline24.github.io/commit/83fc77cf923259baae8599b1c490fbf567e0c34c,version 5.5 from 2025-09-17
https://github.com/timeline24/timeline24.github.io/commit/7172f68002febd47635f06526aea2031f25d7e05,version 5.5 from 2025-09-17
https://github.com/kreier/timeline/commit/972982bf88e60f7715b44789cf7a224956d7c168,Merge branch 'main' of https://github.com/kreier/timeline
https://github.com/kreier/timeline/commit/68272a32f2adb1957b238b79fa5906988b74ec73,little translation fixes
https://github.com/kreier/timeline/commit/abdd4cc2f9eda1c87b1e63dd0b454b8373597a92,Include more languages
https://github.com/kreier/timeline/commit/3301bb7a4847963a257263475eaaceb54602bbfd,fix French translation
https://github.com/kreier/timeline/commit/3fbcde1a37734c7ad540000dc381deb11527b36d,Merge branch 'main' of https://github.com/kreier/timeline
https://github.com/kreier/timeline/commit/5f138dc4d6a9725118c7d9f05f51de3cd8d877ca,swap columns
https://github.com/kreier/timeline/commit/208d08a603708c0668ebfbe0dd518674224bd108,version 5.5 from 2025-09-17
https://github.com/kreier/timeline/commit/49ff0ea52078eaa09bd5442d61992ae174d982c8,"include Pismis 24 image from NASA September 4th, 2025"
https://github.com/kreier/timeline/commit/d4c00f2d104d09f9a4e08423b6090010c7888f30,"include Portuguese, Ukrainian and Punjabi"
https://github.com/kreier/timeline/commit/65207a6baec6c5a1cb86648ff280c006861e47d3,fix small mistakes in Russian
https://github.com/kreier/timeline/commit/ff2676c845999a18f5aafe24b6aae7e9324df5e2,reorganize order in auto-translated dictionaries
https://github.com/kreier/timeline/commit/c7613f95c220fb9b2a00595fb22b57b8ea53d320,"add support for Cebuano, Malay and Greek"
https://github.com/kreier/timeline/commit/ac9a3716fb76d125f71e5b5f416d8d54405e3944,update Armenian
https://github.com/kreier/T400/commit/096a2d43ee777390624315b4a53ec6ac29b15337,new page build process
https://github.com/kreier/T400/commit/b2b215cadeb6af79dc2b6a386ad01db91e1e6c96,Updated T400_OLED.ino with u8g2 OLED driver
https://github.com/kreier/T400/commit/3d8b7f7a852ee2c83d2c67f6f0fcd8c70ee995e7,updated badges to 2025
https://github.com/kreier/T300/commit/873480ce2cf50acd39ec53cdd39687f10b8840cc,updated build status badge
https://github.com/kreier/T300/commit/463d755905402b410ef8c6f2ff39ddf45298bfaf,Build is no longer done with Travis-CI
https://github.com/kreier/study/commit/082964b551105ce427e5ab9bf0e5d2f74e37cbe4,updated audio data September 2025
https://github.com/kreier/study/commit/b22aa83ca485b58d231eb671b4f4ef85c34b2281,"audio recordings bible 100% de and en, 34% vi"
https://github.com/kreier/study/commit/d4df0f82f071ba9373485cd9d4351767d33f0202,finished 2. Kรถnige
https://github.com/LiBeKra/KLZ/commit/3662340a527abc7fe039cd657bb4326b4092c2bf,updated with password protection
https://github.com/LiBeKra/KLZ/commit/3964c6ec2d1979b343ce05e9d9145b23c30fe13d,moved to archive
https://github.com/kreier/timeline/commit/0c9f21ab970bf0d8727e90d20c962d5f4ba24e98,Merge branch 'main' of https://github.com/kreier/timeline
https://github.com/kreier/timeline/commit/7fec0573fba8cd431c3cb845438b4047692b43e6,added Armenian support
https://github.com/kreier/study/commit/0ea693c048745dabab7091dfe43ee6e4a0dbc355,finished Richter und Ruth
https://github.com/vex-ssis/2026/commit/16d98cb3f5918812064d6316284768e3b93c0b3b,Update .gitignore for Synology
https://github.com/kreier/study/commit/c8e8d8fd5754bb847977850cb676fd7858c44ffb,Thursday audio update. Almost 20% in German!
https://github.com/kreier/timeline/commit/fc688eb49588d87519b3b64ef4a4534873f862c1,fix update prior to start of 5.9
https://github.com/kreier/timeline/commit/637675b329460c44cf0eeea16de43b7a9e530e55,updated Russian to 5.8
https://github.com/kreier/study/commit/9310cb0446025ace43679ed2e88a3949d7638762,start bible reading in German
https://github.com/vex-ssis/.github/commit/2fa9030709fb27c1a5fd2a1c81d65d10fcba4e77,include Push Back 2025-2026
https://github.com/vex-ssis/2026/commit/81d055075d009b97701a0a9fd9ae58d81d6788c8,include Mayhem 2025
https://github.com/vex-ssis/2026/commit/f60cfc579dfeed4f8e74e643778432bfe24cd520,add transparency
https://github.com/vex-ssis/2026/commit/c90d345116d9c341c7e1e8aeb0c6e07a7887c0e5,images for Mayhem2025 in February 2026
https://github.com/vex-ssis/2025/commit/b317786d88df64adc7b04e6081f20fb4ea561689,Include results from world for 1599V
https://github.com/kreier/timeline/commit/2c2dc61e45f6eb9c53bda7734dfbca3da881c6f9,translated to 42 to Kikongo
https://github.com/kreier/timeline/commit/d0f0fbdd0ac201c580d0ad75a7d3b429bfb2165b,updated French
https://github.com/kreier/timeline/commit/059ccd7ca11ad56a317af6cf5d081b7cebc1121b,add Kikongo
https://github.com/LiBeKra/Probability-calculus/commit/dd16a51142aef9556e608cf2140d6d7f510469f1,matplotlib generated
https://github.com/LiBeKra/Probability-calculus/commit/b96c7bf2ebf981ab708d4f1b39a3b85b1e4e1d93,add more eye candy and cosmetic sugar
https://github.com/LiBeKra/Probability-calculus/commit/ab83a702cdb05f7b1522e3645e317c4489d4a3fb,Merge branch 'main' of https://github.com/LiBeKra/Probability-calculus
https://github.com/LiBeKra/Probability-calculus/commit/63add07a654f7c431a8a9de65b732027c795cffe,more 6 aus 49 examples
https://github.com/LiBeKra/Probability-calculus/commit/77ee1ef8632e03593c0749af85564992994adf2b,Update README.md
https://github.com/LiBeKra/Probability-calculus/commit/abdf118790e5260b537c277766959a6af07cc56f,reorganized
https://github.com/LiBeKra/Probability-calculus/commit/27d0d17d90ea9738aa88d3d2862baff8e83bed9c,Deutsche Version
https://github.com/LiBeKra/Probability-calculus/commit/c3cad892378cfcb60d8f34cd13030b9209acdd8a,"easy examples with 2 and 3 dices, written by GPT-5"
https://github.com/LiBeKra/Probability-calculus/commit/3c0b69aded32019efd1c4d28270de8c51537193d,first python program
https://github.com/LiBeKra/Probability-calculus/commit/631cd14ee04139766be052ca14a965e42d0aaa9f,Create LICENSE
https://github.com/kreier/study/commit/4671b8c13ead8546d553298c284989f3abac1401,Create kapitel_audio_en_vi_de.xlsx
https://github.com/kreier/study/commit/e60a1c78da29be6a7591aa1b08a68cd246471a23,Short historic background back to 2023
https://github.com/kreier/study/commit/5684f85a5439a7c22224d625b4b664bd672a7262,start listening Bible reading in German
https://github.com/kreier/benchmark/commit/1975531f72c9e251aabe874622a8d8f1aac84fb0,"2025 update on results, newly ordered"
https://github.com/kreier/timeline/commit/ea08ff67d29f6621f35a3d6689dc513fe9938c16,Merge branch 'main' of https://github.com/kreier/timeline
https://github.com/kreier/timeline/commit/cef31475f2940b37dbf4cf4a229d8f474996ba6d,Include history of updated translations
https://github.com/kreier/timeline/commit/986f1a56dcd991896dcbe9f46f88c9d1afe2c87e,include Wulfila bible from 350 CE with Codex Argenteus
https://github.com/kreier/timeline/commit/244509ae939959f6043671ab4b8745ec84750ae5,for demonstration
https://github.com/kreier/timeline/commit/0895b948b1667f9baf81ed999b5844bb8603a442,updated french
https://github.com/timeline24/timeline24.github.io/commit/48deb5570691a2e9c4cccaaf2b83059878e81455,include Swahili
https://github.com/timeline24/timeline24.github.io/commit/c60ab4660cb661b4ff60e368755c2dca42452a13,version 5.8 from 2025-08-15
https://github.com/kreier/timeline/commit/e54fe42274134100d3b2c23a7d73437f7a806e0b,added support for Swahili
https://github.com/LiBeKra/KLZ/commit/f512d789c64999f2fb6b8680dbe1e3dde917115e,Create README.md following idea in a fork
https://github.com/timeline24/timeline24.github.io/commit/9b7680b27c88b284329cf0c71680fd44d3d7af0c,Update README.md
https://github.com/kreier/timeline/commit/1a57195270a839ab5570181afaf1b98833f4876c,updated date 2017-04-02 for the release
https://github.com/kreier/timeline/commit/77c9e958bd3e1dd13dfb280994460bba445378e2,updated Khmer
https://github.com/timeline24/timeline24.github.io/commit/4d7a1260b04aaefdd169351ab70d73acf4e38ba1,version 5.5 from 2025-07-30
https://github.com/kreier/timeline/commit/81fc9acee3a4adf7523d1fdfae16335ec6e87986,updated Khmer
https://github.com/kreier/timeline/commit/3f9ca7e83e4320322f8e45b46df5c227cd3d93ba,Update Kankana-ey since April 2025
https://github.com/kreier/timeline/commit/e71c2df01c95acb4a0d7326f5eb8078d35c0b878,update Ilokano after more than a year
https://github.com/LiBeKra/KLZ/commit/7026a8649238991e35f2bb79b04ad6d447570f8a,Update README.md as landing page for github
https://github.com/timeline24/timeline24.github.io/commit/3089372529af87f41e2020baf19085d125f0a7b3,version 5.7 from 2025-07-14
https://github.com/kreier/timeline/commit/7788c0ba0eb033f5f8c6a321bd6a6a12cc8daf81,fix Japanese Cainan to Kenan
https://github.com/kreier/timeline/commit/d23e0bdba6fcbb81c74f7d4197d062758e17ebdf,"fix Ishbak, Temanites and Xia dynasty in Japanese"
https://github.com/kreier/timeline/commit/5acebd96024aa8c678ea54210de1ab611718f1b0,updated Spanish and Japanese translation
https://github.com/LiBeKra/KLZ/commit/df9a94eb97b882061a9dad8f5c8b690c84022053,Update README.md for Website
https://github.com/LiBeKra/KLZ/commit/632fc265017f683dde9b611913819311fb70e4c0,last edition from 2024-2025
https://github.com/LiBeKra/KLZ/commit/86d4f4e5317a6a6db904f73c606d67ccbc7bd855,Merge branch 'main' of https://github.com/LiBeKra/KLZ
https://github.com/LiBeKra/KLZ/commit/ab1144620dbdcd0b0043721a624d38d1c1fcbc85,update 4 editions from 2024
https://github.com/timeline24/timeline24.github.io/commit/2a2fc0554cfae01cfe69f1a79d4969f7ef160fe0,version 5.6 from 2025-06-24
https://github.com/kreier/timeline/commit/5ec4b471acb1e359105a3e92ce30c5e202e53aa2,upgraded Spanish
https://github.com/kreier/timeline/commit/f391e3a78e1c2a0c93d7ad6ab618c4d205f03b55,include chronology from 1874
https://github.com/LiBeKra/KLZ/commit/2b7d2a58fb345f450a7af89f4c1ea7bbc39ee6d1,include four more editions in the overview
https://github.com/LiBeKra/KLZ/commit/d93269c37dbf3ec1be7c54b0308063c301e2dd48,vierte Ausgabe mit einer Woche Verspรคtung
https://github.com/timeline24/timeline24.github.io/commit/9996fb35793d4603bccee2bbb9bd5f0df160b8ee,Updated link to Mandarin
https://github.com/kreier/timeline/commit/fe5a2fbec66a32352b1283c2cb33f0110ee1eb43,updated Chinese simplified translation
https://github.com/timeline24/timeline24.github.io/commit/30d9ccdf996181a09efbff006c68f9ec9927be94,"fix Korean (language, not person)"
https://github.com/kreier/timeline/commit/852e7b0e6e565abbb4ffa97174670b2459ea9d1e,peer review of Korean translation
https://github.com/kreier/timeline/commit/8d254f243861b4011e01741e44d766d1b9845220,minor fixes Korean
https://github.com/kreier/timeline/commit/a1d49110a4c192ed6c5733b2a1686f1f6ab02524,fix overflow
https://github.com/kreier/timeline/commit/6e5d36a1b50f79172d2ef237c3f155cac2c48dd4,update 5.5
https://github.com/kreier/rp2040/commit/b603361b039f702e30ff8d39ea4968f993a0a56d,include visual of overclocking result
https://github.com/kreier/rp2040/commit/88ea581695b5a1ce439a34bc93a9b70ae51d4eac,Create README.md for overclocking
https://github.com/kreier/prime/commit/b4ec61845acdedd14202b9052a685f5510d84803,"outline, results will follow"
https://github.com/kreier/ESP32/commit/6ae221468baba71806a8dcb0be3991e30e082288,start with ESP-IDF VS Code extension
https://github.com/kreier/ESP8266/commit/98e2e3ea9b3543ba6702610877d12e3f73eedfa3,update 2025
https://github.com/kreier/benchmark/commit/78bf8c2204e2fe69d10ebc6f71cd514c320f5ded,Update README.md
https://github.com/kreier/prime/commit/4e66b7c8c70bba0c7f0135b17709c86ac51bc28e,adjust for wrap-around after 49 days in tick_ms()
https://github.com/kreier/prime/commit/13c002692b191b237fb44d67aeb40a4d84611eb3,results MicroPython 1.21.0 on esp8266
https://github.com/kreier/prime/commit/7ede06dcac06f10b09ab44d2c45b6640b913b03a,resluts ESP32 C3 RISC-V 32bit CPU
https://github.com/kreier/prime/commit/7da7e95e6ea1e9d0cdc68563ad341f79e5a8c2ca,results of LilyGo T8 st7789 with SD
https://github.com/kreier/rp2350/commit/f5696948d423c00f93e4c05e91679bf64508ef40,CPU frequency and badges
https://github.com/kreier/prime/commit/f7bafcfe9755e535262ab3a06a08b5a891df7031,"rp2350 just arrived, benchmarked 2025-05-10"
https://github.com/kreier/rp2350/commit/1aa52a6a9b531f0c345462e9e8d0929a8d143c15,"prime benchmark in circuitpython, 2x speed rp2040"
https://github.com/kreier/rp2350/commit/e5e4370c884b85d5e3cba79ab72b42d99ab3ede3,Update .gitignore
https://github.com/kreier/rp2350/commit/9945592485fcb264d7897e8204ccee7ac653a294,Initial commit
https://github.com/kreier/rp2040/commit/097476db355c4b39f4c09e751b856d33cac5e0d6,"future CoreMark, starting with hello world serial"
https://github.com/kreier/prime/commit/f6f972e19ca17836fc6a1f78f348c7097e496ab3,old 3Blue1Brown explanation for 69
https://github.com/kreier/timeline/commit/214cf9ae773d495cb0c46adcfa8e57917f3b44d0,include commit activity
https://github.com/kreier/benchmark/commit/cd9ce0ae92dc84de8022c0ec04b669387857890f,include three badges
https://github.com/kreier/ml/commit/c9b90e4197eb99688f6cf7c2bab844d241ba8247,add three badges
https://github.com/kreier/jetson/commit/fd9602445dc0b2997da5bda731e69a886b59d3ce,add activity badge
https://github.com/vex-ssis/2026/commit/e884af30d43ee4f6f24e73e57934b58048050742,include list of last years
https://github.com/vex-ssis/2026/commit/1b9de97f5675db9fe2ec331428a345319afed67d,include image
https://github.com/vex-ssis/2026/commit/52046542fa3d1a7deaed0746bb09a458e961bd21,Initial commit
https://github.com/kreier/prime/commit/1298baef6efa478497a95a03c4607a8d34bc7ee4,"minimal rust 8MB, installer msi only 2.7 MB"
https://github.com/kreier/prime/commit/fafd411d6d907e95611db2b6a75ddababf5f62bc,include GUI environment
https://github.com/kreier/llama.cpp-jetson/commit/a944a1785adc7f58c5d6677bfbe574de60139cff,two processes concurrently
https://github.com/kreier/ml/commit/66b8eea556fa1c273a0e96f596f3bd2ce4a7b594,include IBM Granite 4.0 from May 2nd!
https://github.com/kreier/timeline/commit/bc33eb4b90cabf25ce688f7f8610a999165d1734,"include Estonian translation, make googletrans 4.0 work"
https://github.com/kreier/benchmark/commit/dec32ce9b7ec3280a4582319b71d35db5607f805,include process node and architecture
https://github.com/kreier/benchmark/commit/067183e65bf3d3b4eba57a318ec72674a11be8c8,fix data points
https://github.com/kreier/timeline/commit/15a7dc1954eeaffcf79b534d4e37008554233641,fix Capitalization errors
https://github.com/kreier/ml/commit/bf93df9b56215f94495ae5c02cc51424de70959f,include combined image
https://github.com/kreier/ml/commit/022d608877e468ae873a943393be1442b8019bb4,include some updates from benchmarks
https://github.com/kreier/benchmark/commit/de4d1ae8d45082c1320ed769849556bbce1777ed,include small details
https://github.com/kreier/benchmark/commit/ae4ed3f0397d6478f0e85f8ed6c8f3aa605d8e6c,include 2 graphs for toy benchmarks and fastest language
https://github.com/kreier/benchmark/commit/bc8f394c91b697eb237b326076137b01a2c04d74,update graph and 13700T result
https://github.com/kreier/benchmark/commit/5ee6f6febb2a109b91a0652e94265b3977ac0721,updated GFLOPS graphs
https://github.com/kreier/benchmark/commit/45c871ef42f1aff0f7ef618106dae40053f1b483,reorganized
https://github.com/kreier/benchmark/commit/786445c46710968069aaa6cf5a6875773b1f65c5,"update images, include clpeak benchmark"
https://github.com/kreier/rp2040/commit/ea0ac62ee3887b6a8c16ab7529b043fea72a514f,include badges
https://github.com/kreier/rp2040/commit/c2d6b57038420f9a8c7c92f3d4615f0dfd932b09,"blink in C, from examples of the SDK 2.1.1"
https://github.com/kreier/benchmark/commit/7041cd9fd1a5d2ac65e287b41a95b319cb70cfc5,Merge branch 'main' of https://github.com/kreier/benchmark
https://github.com/kreier/benchmark/commit/d3b30953413a3b1c95ffdea9588c5de43f813252,update GFLOPs graphs
https://github.com/kreier/benchmark/commit/5bcb8d717516cf96b532bc101c7b4b7de58c1639,Update recent results LinpackDP
https://github.com/kreier/benchmark/commit/d9b43531b39213390c767454f3ea30e28e4a8a0d,Merge branch 'main' of https://github.com/kreier/benchmark
https://github.com/kreier/benchmark/commit/8271e57c10a54d27b7b182dbf3df7faf43833bd4,include some eye candy
https://github.com/kreier/benchmark/commit/1e300ef19c1ccdcc949cbf0d2c2b06b013454443,include overview
https://github.com/kreier/prime/commit/38986610c40199217ae7c6e9650c0858cefb4dff,Merge branch 'main' of https://github.com/kreier/prime
https://github.com/kreier/prime/commit/582c63e74ce3aeb8c6a23f3aa563d6e3c188ddd8,benchmark i7-13700T 2025-04-26
https://github.com/kreier/prime/commit/d8e532d3e75fcdab83be41065df0821f7d8c30d5,change trigger back to main
https://github.com/kreier/prime/commit/6ae92e1084fa469f13e6a61d603dfae161d4ab36,Merge branch 'main' of https://github.com/kreier/prime
https://github.com/kreier/prime/commit/724e9b9aaa3d8ff349d3f2ddf77436283b57b621,results Jetson 2025-04-26
https://github.com/kreier/prime/commit/4f46420c26d6cb48e6c2c8e96c60032278a0c03f,include badge and Sieve of Eratosthenes
https://github.com/kreier/prime/commit/d28cd6bb603f1469ec72e8b9294197de58a0f717,Update jekyll-gh-pages.yml to recent action script versions
https://github.com/kreier/prime/commit/cabb407f54f6ef5c4bcd78738811948b4122c4de,Update actions/checkout@4 since v3 is no longer supported
https://github.com/kreier/prime/commit/9eaa2a9b66e4310fe4b7fde2883b1398e1e9944a,Update README.md
https://github.com/kreier/cuda/commit/84da567a363dbc3527a0c189e1354bfe89c1ca5f,Create README.md
https://github.com/kreier/cuda/commit/a64fc06d7b04224ac55c5a1ea08581e65f166a13,simple hello world on one thread
https://github.com/kreier/cuda/commit/d714e460b4e006e18b8fa4df075417a67eee3e98,Initial commit
https://github.com/kreier/benchmark/commit/a467ab3e9394c41900c197f58881a2e055beb4a9,faster speed for INT8 with dp4a in v1.8
https://github.com/kreier/benchmark/commit/3e1f51fe13d914589f36275156658240aad628ea,include Apple M1 and i7 13700T
https://github.com/kreier/tripitaka/commit/e95025abb54ee3c56ec46b8e9ff629789f82f160,extracted .epub to .xhtml
https://github.com/kreier/tripitaka/commit/5423749779727eb318c4f911e8b2016342bf3165,add links to subfolders
https://github.com/kreier/tripitaka/commit/9c42cea273ae2998f9d1cfd6372bfc01ffc1ba55,add details for github.io website
https://github.com/kreier/jetson/commit/bda912b74dba2dbcba99ef51258218e07d2b15a6,include memory bandwidth
https://github.com/kreier/jetson/commit/c5ae34b52412aa953061c959ba0c9e4091e2c32a,benchmark results clbench
https://github.com/kreier/jetson/commit/17ad681dc30d1aba95d3a4b92dc38dd2ac18b6fe,include some images
https://github.com/kreier/jetson/commit/f9d21b52f031b1bb34be6e928e7db2d11b2e0ea8,include pictures
https://github.com/kreier/llama.cpp-jetson/commit/678a3cb1205881443ba2f8df02d7bf50ec628289,include small images above bigger subsections for readability
https://github.com/kreier/llama.cpp-jetson/commit/bff1a3edc25e968cb624566fb1f2e9ee8c7960b8,prerequisites
https://github.com/kreier/llama.cpp-jetson/commit/c2930671aea08dc62685662e0a7917bd73e00d75,include small logos for better readability
https://github.com/kreier/llama.cpp-jetson/commit/f3778c7928a85fbb0d796d718e1f35596014b300,include Gemma 3 logo
https://github.com/kreier/llama.cpp-jetson/commit/603909b12be2c88e5dce64b19e9097e80d05b549,Merge branch 'main' of https://github.com/kreier/llama.cpp-jetson
https://github.com/kreier/llama.cpp-jetson/commit/86415f438ad7b1702cadc3024ea1689618bdcb04,"updated graph, include comparison CPU"
https://github.com/kreier/llama.cpp-jetson/commit/1c3e9e5bc9e1b0547fa78882f4d7ba1a71407362,improve wording of a few instructions
https://github.com/kreier/llama.cpp-jetson/commit/0920d107dcd175568dba85ee017c41b9f0ad746a,"fix installation, include image"
https://github.com/kreier/llama.cpp-jetson.nano/commit/9caada5205f104c2b507b0b85c135f7f4fdf8e55,"simplified, reorganized"
https://github.com/kreier/llama.cpp-jetson.nano/commit/ef8b948518145492ebd5ae1eb0e10af55ffe6322,link llama.cpp and image
https://github.com/kreier/llama.cpp-jetson.nano/commit/38b05250e37cd866b6f8190d15f8bfc531d33709,fix source problem
https://github.com/kreier/jetson/commit/b6b4ec8c62887888995cd34310c1649c5c1f360f,"even source does not operate in the shell, but subshell"
https://github.com/kreier/jetson/commit/a6013a5d089059b5e9d5f9bf6742e01bf3443fa1,export only works in the scripts subsession - fixed with source
https://github.com/kreier/jetson/commit/0cbc14d448009c517333c981a25ed1eefc1ff54f,fix path to cuda compiler nvcc
https://github.com/kreier/llama.cpp-jetson.nano/commit/4c0dd2ef97b51ada9eeb95a4264745d01228e5b0,fix grep request to execute script with bash
https://github.com/kreier/llama.cpp-jetson.nano/commit/0019fdc4ddd703571c56b78e20c22c565de5eec2,patch path automatically
https://github.com/kreier/llama.cpp-jetson/commit/5c1c292f8ba2856b0b50765dbf13bc028fee6658,faster memory access with GPU
https://github.com/kreier/hacks/commit/0f81a6ec43c7c81b18d47d433cb3792d8d3d2618,include badges
https://github.com/kreier/hacks/commit/2f8a897a6a8c4f565838eeb43ed8a499b037149e,include a little structure
https://github.com/kreier/timeline/commit/889aa66e53b52a1657e67e8dda6863edee5f6490,reorganized Terah's family
https://github.com/kreier/timeline/commit/0713cd37635db58e7e7b0c17fcf40dc3e30e9f24,comparison to reference is working
https://github.com/kreier/timeline/commit/a46338b18902e038dc94abd27b18763723280f52,special case for Iloko and Kankana-ey
https://github.com/kreier/timeline/commit/794842f8efd16571fbbea86a3bc7206ac0ab5033,"preliminary version 5.4 with Exile capitalized, Tagalog ingredients"
https://github.com/kreier/timeline/commit/155e97a966307a54add6011020253d83a2dd5644,"Update English reference, remove unnecessary spaces"
https://github.com/kreier/timeline/commit/b2f43741f4ebe776dd81d13e7aeedd5973e2c7b1,Capitalized English Captions
https://github.com/kreier/timeline/commit/3a922c5cee699fb565bfbc7b74bdc27328c02270,updated Tagalog
https://github.com/kreier/tripitaka/commit/07ac3ec4afa7460237af1d4d4aa7b360de1f5d36,Adjusted date export
https://github.com/kreier/llama.cpp-jetson/commit/c044ee4e405460728ae1d90a3134e29425c43c83,updated benchmarks
https://github.com/kreier/timeline/commit/aa171559d398a89c83d99d21ffadbd20d1e42c26,fix capitalization and other details
https://github.com/kreier/timeline/commit/b132649be673166837350f18a6369fecf0a5195a,update to 5.4
https://github.com/kreier/llama.cpp-jetson/commit/d095b11913311be709f215ac5b8e24308a5ccf4c,compiled in 60 minutes with faster SD card
https://github.com/kreier/llama.cpp-jetson/commit/ed21b1f89df24a19b6a2c3d4b8d81c2360cebbf4,"document compiler standard libraries, improve readability"
https://github.com/kreier/timeline/commit/7850835fb8acc3467e95a437ab291fd41eb5e52b,minor fixes for 5.4
https://github.com/kreier/timeline/commit/43c6b24f5093d52d50fef33e6bdc00b1f260a698,minor changes to reflect present time
https://github.com/kreier/llama.cpp-jetson/commit/30160d7aa9b2bcfb66a857a125321a0173acddf6,details to gcc 8.4 and 8.5
https://github.com/kreier/llama.cpp-jetson/commit/3845de83abcc216f5925e3477285929bd3700841,fix typos
https://github.com/kreier/llama.cpp-jetson/commit/3da6b6a272eec29ae7c00b02a90499c8cd27cdbc,short description in 11 steps
https://github.com/kreier/llama.cpp-jetson/commit/5fbbdacf5063a24e3479a10ea2f7e509715c998a,Overview of patches in the introduction
https://github.com/kreier/llama.cpp-jetson/commit/33aea20b6e0171a0db49b145f244a77dd1b2ca6b,restructured patches
https://github.com/kreier/llama.cpp-jetson.nano/commit/b06384871ddfb9bf8be34b67365b8692e8500afe,switch to bash since source is not available in sh
https://github.com/kreier/llama.cpp-jetson.nano/commit/d5bf0cb59ad58713c18bcc13b2636bdf68d29920,include newer library for GCC 9.4
https://github.com/kreier/llama.cpp-jetson.nano/commit/6bf07790b429e4061a99704c49e98ce074ed5dbf,build 5113 2025-04-11 with gcc 9.4
https://github.com/kreier/llama.cpp-jetson/commit/766e39ebfac4eb4332ab3b9b9338252fb7110e96,fix details for b4400 and others
https://github.com/kreier/llama.cpp-jetson/commit/e0e2cfc9027608afb83af4f84b4b423fe796b197,"updated graphs TinyLlama inference speed, minor fixes"
https://github.com/kreier/llama.cpp-jetson/commit/90bee2b7bcc2e88d73054a388ad5fdd79154800d,Merge branch 'main' of https://github.com/kreier/llama.cpp-jetson
https://github.com/kreier/llama.cpp-jetson/commit/010c86a8bd90e790376832b3d8af38c2bb5e35db,updated graph speed comparison
https://github.com/kreier/llama.cpp-jetson/commit/0c476df91d7e309934ea9e9b81d6955e9586158b,times for gcc 9.4 8.4 and 8.5
https://github.com/kreier/llama.cpp-jetson/commit/5abd73ac3027f7e73c38c74eaa5f6a0f6fe3c374,fix and document cmake installation
https://github.com/kreier/jetson/commit/508d4f8aa0d5ab22e9c10967fa281ea7bd845507,include build 5050 2025-04-05
https://github.com/kreier/llama.cpp-jetson/commit/b0d6ef59ee95bbf1b5879bed2580f4e066375cd5,include installation of build 5050 in 1 minute
https://github.com/kreier/llama.cpp-jetson/commit/1eb83966b2a9cc268037d1b5e929e05bd0bb024d,fix jtop installation
https://github.com/kreier/jetson/commit/35769ec322f4e380084cf793980ab7ccd0b441e4,"first start relocated, fixed jtop installation"
https://github.com/kreier/llama.cpp-jetson.nano/commit/480424128d568850e2c2e93be3ac4b3d7c1c4e6c,update library path with script
https://github.com/kreier/llama.cpp-jetson.nano/commit/30677c4e417a00993b9791da89e7a282b1ed955a,First startup is 7 minutes
https://github.com/kreier/llama.cpp-jetson.nano/commit/19d4aee1a4aeafec882c2ef28ba831cacf7eb1cc,include 4 more necessary libraries
https://github.com/kreier/jetson/commit/a5c5a7127f02232f11f15b01214d276b86af2879,"document first start, setup and time"
https://github.com/kreier/jetson/commit/ddd4092c5aa39808672ea054f5c7b384fba60800,activate links of Overview
https://github.com/kreier/jetson/commit/bb4b2ddebca271e846e6efbaf789f534586f41d5,structured and reorganized documentation
https://github.com/kreier/llama.cpp-jetson/commit/bfa01a9df0d38ae37e77558811b68de634e75820,exported layers speed up - graph and explanantion
https://github.com/kreier/llama.cpp-jetson/commit/e10c1473f03914ba98fe18ef9ed1a75870790c01,Merge branch 'main' of https://github.com/kreier/llama.cpp-jetson
https://github.com/kreier/llama.cpp-jetson/commit/561b654962d8baf04f9ad5b3319e1a51f0187639,speed dependence on exported layers GPU
https://github.com/kreier/llama.cpp-jetson/commit/bf662b155c9984a54a3bd147a3200bbfbde5f8d8,include graph for prompt processing speed dependence
https://github.com/kreier/llama.cpp-jetson.nano/commit/0f86ce54d24730cd6834c4a721421aea70dc7dac,"fixed description, explained 71 files"
https://github.com/kreier/llama.cpp-jetson/commit/0082d52c725bb240118682426a6ad3ef94cd72ef,faster prompt processing with longer prompts
https://github.com/kreier/llama.cpp-jetson.nano/commit/f91888f5afeeb0de2fe4147aeb5a8b466090b21e,build 5050 from 2025-04-05
https://github.com/kreier/llama.cpp-jetson.nano/commit/913924d4d40c4faa8b3bb1b0d137ca6b00b7958a,Update README.md
https://github.com/kreier/llama.cpp-jetson.nano/commit/7627dc8e80bc9ad2d746fbb737b69d4593c773ce,example answer from llama-server
https://github.com/kreier/llama.cpp-jetson.nano/commit/3d1f831aebb6e3210b99ed7e3a3b5f8064057ca2,fix file location
https://github.com/kreier/llama.cpp-jetson.nano/commit/aec302a27cb832c72cfc87d8082fba8c51ac0563,using temporary directory for install
https://github.com/kreier/llama.cpp-jetson.nano/commit/63f7d5b173bae1db9c5d3ac4e91fa852b244e13e,fix #1 mkdir error
https://github.com/kreier/llama.cpp-jetson.nano/commit/45df7d9cb066d49473d8214fd68833f3902e254b,include available() and require()
https://github.com/kreier/llama.cpp-jetson.nano/commit/12071f23bf3d80827cd6db0b8bdcaf65fb637650,fix INSTALL_DIR path
https://github.com/kreier/llama.cpp-jetson.nano/commit/a4d3258f5c3b50e6701af9b0471a17a30de3d461,build 5050 from April 2025
https://github.com/kreier/llama.cpp-jetson.nano/commit/3031ea699e2522125efe96f57b454899a4ba0077,Initial commit
https://github.com/kreier/aa/commit/b12cb6216783fcfa514daae4220c35f3b0bba01f,Merge branch 'main' of https://github.com/kreier/aa
https://github.com/kreier/aa/commit/820f6037d028d6b1a358687bd10a5c5125b8c4ae,expand cross-references
https://github.com/kreier/aa/commit/74f83466e88c8d24add94c31bc6df99189cee0d4,include reference link and some images
https://github.com/kreier/aa/commit/b0416486e715451eaaf53aadfb1d4d6e78a9af50,Merge branch 'main' of https://github.com/kreier/aa
https://github.com/kreier/aa/commit/ea20cb1a272b546d8de31f6aa3189117c7515a02,include standards
https://github.com/kreier/aa/commit/7b48eaef4963005fa6c6ecf826751208f5e49474,include badges
https://github.com/kreier/aa/commit/8c94cb12f8ddf34efb87894104b3966eeb53f3ed,documentation 2022-2023
https://github.com/kreier/llama.cpp-jetson/commit/4698e643ff902ca33b1073f9421750fd16654ced,"explain relevance, include graph vor comparison"
https://github.com/kreier/llama.cpp-jetson/commit/a8c83f1afde370f806fff29fec263a55d86b7e6e,patches from early 2024
https://github.com/kreier/llama.cpp-jetson/commit/4593b62ef6720cc218a1c130c1fe77d8d6679820,"include more benchmarks, links to data and visualizations"
https://github.com/kreier/llama.cpp-jetson/commit/6ac74b8c7b36d0a1e864380ad00d42526ba8847a,results of 11 different prompts with 3 llm processors
https://github.com/kreier/llama.cpp-jetson/commit/5ea7e121dc5e6e397bb914110feb40367e22f1be,updated graphics and metrics
https://github.com/kreier/llama.cpp-jetson/commit/20aa0921357b5e74a802ae96f1b74932645d2935,optimized screenshots
https://github.com/kreier/jetson/commit/025c61eaf7424c7aff6cc904b3b694dff2822388,optimized screenshots
https://github.com/kreier/jetson/commit/8051c35020c0703ab33efc7080fea69f49d71aed,updated graph
https://github.com/kreier/llama.cpp-jetson/commit/031e37366b9005f39828b994d77db3354cebca7f,updated graph and details
https://github.com/kreier/llama.cpp-jetson/commit/419f4337fc18a7f7c1485341459bdc3bfa8e80a2,fix Gemma3 4b benchmark results
https://github.com/kreier/llama.cpp-jetson/commit/9d524ea0003b374a8e76599e4a758f046f28b93e,applications and Gemma3 4B
https://github.com/kreier/llama.cpp-jetson/commit/d56cb54391e4948bfa13a5a364660475134651cc,Create install.sh
https://github.com/kreier/llama.cpp-jetson/commit/41ee7204a5e752ab527dc4691b0bc6509a3fee7e,reference this repository
https://github.com/kreier/llama.cpp-jetson/commit/86982887b8356af498c2dbfb90a69a503ad5e397,move documentation from gist to repository
https://github.com/kreier/llama.cpp-jetson/commit/9498bdb1e1d88abc18da3d776baef25f630e7758,successfully compiled 2025-04-05
https://github.com/kreier/llama.cpp-jetson/commit/0fd24402325a9b2c58ff208b957e9cbf0d925287,Update .gitignore for Synology
https://github.com/kreier/jetson/commit/e5a8cea1ef9c1c59b4b9e075af731905671a3d70,Merge branch 'main' of https://github.com/kreier/jetson
https://github.com/kreier/jetson/commit/634526b91c4e81d3c7aab94589968b6f9f11cc4e,screenshot from the actual compilation
https://github.com/kreier/llama.cpp-jetson/commit/e9acb80396cbba4086c806d12dc857ec3bf89a91,Initial commit
https://github.com/kreier/jetson/commit/0acc712fdf800f33c4c0deb8bcfe8e5eb3a57bf8,improved documentation
https://github.com/kreier/jetson/commit/606899502f293493a3fadd0dcf52571ddaf21f73,expand on prerequisites
https://github.com/kreier/jetson/commit/567b4f0346481d85c1f137fe513859953077d5da,timestamp compiling b5050
https://github.com/kreier/jetson/commit/0d8cdf4bf346d192d40285cbd22a62963f2d2d03,include latest benchmarks with b5043
https://github.com/kreier/jetson/commit/1f55abb2fc37a2a56480a809341704a9601df117,latest run with gemma3:1b and llama.cpp 5043 CUDA
https://github.com/kreier/jetson/commit/07a2a1a125df0412f5392fadbffebddabe1d5346,patch for b5050
https://github.com/kreier/jetson/commit/95a97678cace98f108340a9645f5141cfd90f30e,visuals for TinyLlama
https://github.com/kreier/jetson/commit/4d1be82620bd6113c137ff975a26d49b1431e63c,optimize graphics
https://github.com/kreier/jetson/commit/0ed91dfa6fd82ab38349c244ad2014bc05a29395,compare speed with Gemma3
https://github.com/kreier/jetson/commit/a86a448ef09a3bda0a2fff0f74837c4386229ff3,restructured instructions to compile with CUDA support
https://github.com/kreier/jetson/commit/7916adccfbe52b1b21036d7a0345f4fc11dcfc91,Old document from March 2025
https://github.com/kreier/jetson/commit/c494bb06d3ca0b8fac5fa9df8d90460381360bc2,Merge branch 'main' of https://github.com/kreier/jetson
https://github.com/kreier/jetson/commit/5166f120ad5c52fecae91004e042976d2aec027b,document GPU usage
https://github.com/kreier/jetson/commit/83648668fd12293145f0c75ed341f0fa0f3592aa,include recend instructions
https://github.com/kreier/ml/commit/a1221831b6600dea66f5519366bfd3616e0d841c,"fix toolkit 12.8.1 installation, including WSL"
https://github.com/kreier/jetson/commit/a9328b66e5735cbebaeee6ba6b78dd67ecc1e4ef,Update benchmark.md
https://github.com/kreier/jetson/commit/27b66ca354e252bf1b325fc14e066dbb9dc14624,result with b4400 from Dec 2024
https://github.com/kreier/jetson/commit/262436c720be350baae467c118a11bf556f1cad4,even newer version of llama.cpp from end 2024
https://github.com/kreier/jetson/commit/13cb2ee475e435d814ca59f3d76ecc53d9969312,results for b1618 with gcc 8.5.0
https://github.com/kreier/jetson/commit/08620b763aae4614994a767524558217e77426e8,"fixed instructions, finally working"
https://github.com/kreier/jetson/commit/d15836f72c9007f7940d2d61ff24a381e28bed38,fixed install script
https://github.com/kreier/jetson/commit/c4384c3f726abe92d4aaf42ace8f784bc488fdfc,restructure for cmake and gcc-8
https://github.com/kreier/jetson/commit/45207407225e7bdb9bc85e1216a236cd3634da7f,document new installation
https://github.com/kreier/jetson/commit/2e8f8ccc7aa985ac434a681ade157d41503e040b,some ideas for automated installation and time requirements
https://github.com/kreier/timeline/commit/85e2a0d1a2ebffa1eea98688e625dd8c3de0bef0,document history and cleanup
https://github.com/kreier/jetson/commit/4ab40900ad4b59458fd37ae3129c3ed6cd71f514,Merge branch 'main' of https://github.com/kreier/jetson
https://github.com/kreier/jetson/commit/f40a48f488b6da747aa2ce7959a54020bafcd67a,results from GPU runs
https://github.com/kreier/jetson/commit/0aa8bf49049c5bd78f837e33d2c46df4ebecd64f,Update benchmark.md
https://github.com/kreier/jetson/commit/2edcbe7b77ea782c7fd810b46a7b4525b39dbac2,GPU actually used!
https://github.com/kreier/jetson/commit/fdecf3b1e4ebe44c00c98e0b863fa350208444b7,document 8x pp512 speed with old GPU build
https://github.com/kreier/jetson/commit/8426384f82a4f322b09b8774cb5fa73194f57084,move images from private to public
https://github.com/kreier/jetson/commit/4843eab6bb7879159e3688dd2a75b1e554921386,Create benchmark.md with some GPU accelerated 1 year old versions
https://github.com/kreier/jetson/commit/f791f732e199b514c2b4a2c4c2e6c7a6ecb4bdae,compute_80 not supported
https://github.com/kreier/jetson/commit/1caa548e8ee849ad1e41e57dc94f0d2508e6016e,"Instructions to compile for gcc-8, gcc-9 and CUDA 10.2"
https://github.com/kreier/timeline/commit/c787687d6a079f01e70ff215513512552f4d6a51,update table with statistics
https://github.com/kreier/timeline/commit/4775c58e8842c7ddbeceb1faaa3b116e64c6d983,Merge pull request #63 from kreier/5.3
https://github.com/kreier/jetson/commit/7588d335287b2db14c76fba8d62426355ca522b2,compiling for CUDA up to 34%
https://github.com/kreier/jetson/commit/6250cf6bf6303de9fea31b98ec933bcd26287303,expand documentation
https://github.com/kreier/jetson/commit/5254adb32ec9ccfd1aaefe9fb5132c4287af497d,include pictures for documentation
https://github.com/hviovn/new-vocabulary/blob/main/README.md,# new-vocabulary Learn new Vietnamese Vocabulary from the Watchtower each week.
https://github.com/hviovn/diary-statistic/blob/main/README.md,# Statistics of My Diary [![GitHub Release](https://img.shields.io/github/v/release/hviovn/diary-statistic)](https://github.com/hviovn/diary-statistic/releases) [![GitHub License](https://img.shields.io/github/license/hviovn/diary-statistic)](https://github.com/hviovn/diary-statistic/blob/main/LICENSE) Visualize my diary entries like GitHub for commits. Here is an example ### 2006 ![2006](docs/assets/activity_2006.svg) 49 articles in 2006
https://github.com/kreier/quartz/blob/v4/README.md,"# Quartz v4 > โ[One] who works with the door open gets all kinds of interruptions, but [they] also occasionally gets clues as to what the world is and what might be important.โ โ Richard Hamming Quartz is a set of tools that helps you publish your [digital garden](https://jzhao.xyz/posts/networked-thought) and notes as a website for free. ๐ Read the documentation and get started: https://quartz.jzhao.xyz/ [Join the Discord Community](https://discord.gg/cRFFHYye7t) ## Sponsors"
https://github.com/kreier/obsidian/blob/main/README.md,"# Obsidian ![GitHub Release](https://img.shields.io/github/v/release/kreier/obsidian) ![GitHub License](https://img.shields.io/github/license/kreier/obsidian) A central place to collect and organize my ideas. And parse some statistics. ## Statistics | folder | files | folders | size | words | images | |------------|-------|---------|-------------|-------|--------| | computer | 1731 | 76 | 162,437,617 | | | | freizeit | 947 | 35 | 49,929,432 | | | | geschichte | 18 | 0 | 946,419 | | | | physik | 72 | 6 | 17,622,758 | | | | projekte | 444 | 29 | 21,701,977 | | | | urlaub | 1342 | 20 | 89,448,124 | | | | glossar | 29 | 1 | 2,015,004 | | | | logfeile | 253 | 2 | 27,589,395 | | | Well, that's for the old legacy project. Still, the counting needs to be done one day."
https://github.com/kreier/homelab/blob/main/README.md,"# Homelab ![GitHub License](https://img.shields.io/github/license/kreier/homeserver) ![GitHub Release](https://img.shields.io/github/v/release/kreier/homeserver) Documentation on my journey to a little homelab. It currently consist of 3 routers, 1 managed switch, 3 always running servers and one LLM server that can be activated on demand: - LLM server [llm.server.home](#serverhome) with 30 GB GDDR5 on demand - Raspberry Pi 4 [pi4.home](#pi4home-for-home-assistant-and-dns) for Home Assistant, DNS Resolver and filter - Raspberry Pi 3 [pi3.home](#pi3home-for-home-assistant-and-pihole-in-secondary-network) - [History](#history) ## Penta-GPU server This machine runs only when started manually, and is switched off most of the time. It's more a playground to see what's possible with local LLMs due to its 3 GPUs and 22 GB of fast VRAM. Other specifications: - Intel [i3-6100](https://www.intel.com/content/www/us/en/products/sku/90729/intel-core-i36100-processor-3m-cache-3-70-ghz/specifications.html) 2C/4T 3.7 GHz Skylake - EVGA [Z170 Classified 4-way](https://www.evga.com/support/manuals/files/151-SS-E179.pdf) motherboard with Quad-SLI, 6 PCIe slots - RAM: 32 GB DDR4 2400 (early 2026 reduced to 16 GB) - GPU: all NVIDIA - P104-100 8GB GDDR5X [314 GB/s](https://kreier.github.io/benchmark/gpu/opencl/) 5005 MHz PCIe 1.0 x4 - GTX 1070 8GB GDDR5 [220 GB/s](https://kreier.github.io/benchmark/gpu/) 3802 MHz PCIe 3.0 x16 (x8 on the mainmoard) - P106-100 6GB GDDR5 [176 GB/s](https://kreier.github.io/benchmark/gpu/opencl/) 4006 MHz PCIe 1.0 x16 (x8 on the mainmoard) - P104-100 8GB GDDR5X [314 GB/s](https://kreier.github.io/benchmark/gpu/opencl/) 5005 MHz PCIe 1.0 x4 - NVMe: 256 Toshiba PCIe 4.0 x4 - SSD: 240 Kingston SATA3 for the models of LLM used by Ollama This image shows the 47 layers of [glm-4.7-flash](https://ollama.com/library/glm-4.7-flash):q4_K_M using 19 of the 22 GB VRAM. Each GPU has about 1 GB headroom for the K-V-pairs related to their layers when doing inference over longer context. An update of the tested maximum context length follows. 2026-02-05 ![nvtop 3x GPU](docs/assets/2026-01-27nvtop.jpeg) One week later with 53 layers from [nemotron-3-nano](https://ollama.com/library/nemotron-3-nano) and **31.6B** parameter the power of the CPU spikes to more than 400 Watt: ![nvtop 5x GPU](docs/assets/2026-02-19_ollama_nemotron2.png) ### Software As stable foundation until April 2029, and with Ubuntu Pro (ESM) until April 2034 this should be enough time to just keep this system running. Almost all other modules run in a docker container. With a fixed IP 10.10.10.40 the services get their own subdomains of server.home. It is routed with a Raspberry Pi 1B in the same network, using pihole. - **traefik** to handle the domain names and access from the web - **wordpress** under wp.server.home as a test wordpress installation - **ollama** as the backbone for the llms being accessed over Open WebUI and n8n - **Open WebUI** is accessed via llm.server.home - **Grafana** creates beautiful visuals of the use of the server - **n8n** tries to automate some workflows and use open APIs and LLMs in the process - Further wordpress installations: - hofkoh.server.home to have an image of the old **hofkoh.de** - saihtorg.server.home to have an image of the old **saiht.org** Over SSH I can see some details with btop and nvtop about the systems stage. And OpenWebUI renders a beautiful LLM interface that allows to upload documents and rendered LaTeX output, structured text and tables ![OpenWebUI output](docs/assets/2026-01-27openWebUI.jpeg) ### Docker I was surprizes how simple the setup with docker is. Inside your home folder you create a folder `/docker` and for each container a subfolder, for example `~/docker/wordpress`. Then you put a YAML `docker-compose.yml` file in there that describes services (db, wordpress), volumes and networks. For a first start you need ``` sh docker compose up -d docker compose down docker restart traefik ``` You can also forward instructions into the docker container, or open a console in it: ``` sh docker exec -it ollama ollama run mistral --verbose docker exec -it ollama bash ``` Don't forget to create your network: ```sh docker network create my_network docker network ls ``` ### Traefik and SSL/TLS Now I have a root certificate for server.home. Once it is imported, all the other sites as subdomains are trusted with the wildcard *.server.home certificate. All network traffic even inside the local network is therefore encrypted. Link to certificate: ## 8500.home Technically it is an i5-8500T processor inside the HP EliteDesk mini 800 G4 with 2 NVMe slots inside. The motivation was not just size, but the power consumption of just 4 Watt when idle. And homeservers are idle most of the time, why waste a lot of electricity. It has a separate network and is actually connected to the internet to n8n.io.vn or c103.io.vn ### Hardware - i5-8500T - 32 GB DDR4 2400 MT/s with - NVMe PCIe 4.0 x4 512 GB - USB Network 2.5 GB ### Software There was a lot to learn about the several layers of abstraction. Here is a little table as visual vertical block: | Level | Layer | Component | Function | | :--- | :--- | :--- | :--- | | **0** | **Physical** | HP EliteDesk 800 G4 (i5-8500T) | The ""Bare Metal"" hardware and raw silicon. | | **1** | **Hypervisor** | Proxmox VE | Type-1 Hypervisor managing hardware resources. | | **2** | **Virtual OS** | Ubuntu 24.04.3 LTS | The Guest VM with its own kernel and file system. | | **3** | **Container Engine** | Docker & Docker Compose | The runtime that isolates apps from the OS. | | **4** | **Routing** | Traefik | The ""Front Door"" that handles SSL and traffic. | | **5** | **Applications** | WordPress, Ollama, Home Assistant | The specific services providing data and logic. | With the UHD 630 we can even use the GPU to support ollama: You will need to ""Pass-through"" the GPU device from Proxmox (Level 2) $\rightarrow$ Ubuntu (Level 3) $\rightarrow$ Docker (Level 4) so that Ollama (Level 5) can use it. ## pi4.home for Home Assistant and DNS I would like to have a few unique domain names for different services, maybe subdomains. That's not supported by my Asus router RT-AX55. I can only get a `pi4.home` assigned to a predetermined IP, further parts could possibly be done with `traefik` and subfolders. But better to have a dedicated DNS server. Here is where the Raspberry Pi 4 steps in. Traefik is forwarding incoming requests to the right container, but getting a DNS entry is another question. With Pihole I also get a great AD blocker. Its surprizing that about 25% of all DNS requests have to be blocked! ### Pihole AD blocker and DNS server It's nice to have a graphical interface. It just took a little longer to get the service running on 10.10.10.4/admin over http to be accepted locally on https://pi4.hv.io.vn/admin with a valid certificate. But it works now! ### n8n.hv.io.vn to automate things It is just an attempt to use this tool. Maybe some extra accounts will help to not have this spread out. ### ai.hv.io.vn This is where the fontend of Open WebUI responds to my requests, in the backbone it connects to the ollama server. It might first have to power it up, but after less than 60 seconds the machine is ready. ### OpenClaw This would be reckless, but I'm curious nonetheless. The old Clawdbot made some waves end 2025 and early 2026. What can we actually build? ### ha2.hv.io.vn This is in my own network, all Wifi sensors in my home run on the other network. But I can connect to some Bluetooth temperature and humidity sensor and show it on the info panel. And toner status of the laser printer. ## pi3.home for Home Assistant and Pihole in secondary network The network for gadgets and devices I don't know a lot about. ## History ### 2024 I started to build my own LLM server, and I knew already that I need a lot of RAM and processing power. So I got a used [Xeon E5-2696v3](https://www.techpowerup.com/cpu-specs/xeon-e5-2696-v3.c2903) 18C/36T and 128 GB ECC RAM. It fit's larger models like the llama3.1:70b but comes to a crawl of **only 0.2 token/s** since I only have [8.27 GB/s](https://github.com/kreier/benchmark/tree/main/gpu/opencl) memory bandwidth. The i5-8500 would probably get 34 GB/s and speed up to 1 token/s. **In 2026** I realized that there must be a glitch. The model stated above was the llama3.1:70b with 4 bit quantization. The download is 39 GB, and it used 42 GB RAM with ollama. The smaller llama3.1:70b-instruct-q3_K_M is only 34 GB in download and uses 38 GB RAM. Yet here I get a much faster 0.83 token/s speed. Assuming linear dependency on model size and memory speed this aligns with all other measurements (30GB, 19GB, 12GB, 8GB) of the E5-2696 v3. The comparison below should therefore assume 0.74 as reference, 4.6x faster and relating to 38 GB/s memory speed. Being quad-channel of up to 68 GB/s this is more in line with the expectation. The P104-100 would still be 10x faster! ### 2025 GPUs do not only posess a lot of parallel compute power (important for the initial **PP** - prompt processing for an LLM task) but usually also have a fast memory. My P104-100 for example has [314 GB/s](https://github.com/kreier/benchmark/tree/main/gpu/opencl) memory bandwidth for the 8 GB of GDDR5X RAM, that's 38x faster than the DDR3 ECC RAM. Which would result in ca. 7.6 token/s for the [llama3.1:70b model](https://ollama.com/library/llama3.1) in 4bit quantization, requiring 43 GB (that I don't have). And since the GPUs require a lot of power, they also get hot. My Z170 would support 4 graphics cards, but using only 2 slots per GPU is actually rather narrow. It is better to have one slot empty space for airflow between them. But then you can only fit 3 GPUs on the motherboard: The GTX 1060 has a broken HDMI port, but I still can use the 3 DP to connect a display. So I moved it to my E3-1226 v3 machine. I lost 6 GB VRAM of the combined 26 GB. Then one P106-100 broke, so I replaced it with a P104-100. **More memory**, and much **faster**! Now 2 GB more and with 320 GB/s bandwidth. That is the machine that is now running. The theoretical power consupmtion of the three GPUs is 180W + 150W + 120W = 450W but in reality during inference and prompt processing they only use 150W. | GPU | power old | power new | GB/s | |----------|:-----:|:-----:|:----:| | 3060 Ti | 200 | | 448 | | P106-100 | 120 | 120 | 192 | | P106-100 | 120 | | 192 | | GTX 1060 | 120 | | 192 | | GTX 1070 | | 150 | 256 | | P104-100 | | 180 | 320 | | P104-100 | | 180 | 320 | | total | 560 | 630 | | ### January 2026 With more time in training models the available modesl also get significantly better. Now I can use a [19GB glm-4.7-flash](https://ollama.com/library/glm-4.7-flash) that DOES fit into the **22 GB VRAM,** distributed over my 3 GPUs (all 47 layers). The speed should now be 17.2 token/s if we use a linear approach (or 12 resp. 10 for the slower 1070 and P106). Effectively I get 23 token/s in Open WebUI, probably due to being a MoE model to effectively double the speed again (see my insight on [speculative execution](https://kreier.github.io/ml/#faster-inference-with-speculative-execution) from 2024-11-27) Now I finally have a usable system. I get **23 token/s** instead of theoretically only 7.6 token on llama3.1:70b (3x as fast) while also getting a similar or better result: | Benchmark | Llama 3.1 70B (Instruct) | GLM-4.7-Flash | Winner | |--------------------------|--------------------------|---------------|---------------| | MMLU (General Knowledge) | ~84.0% (5-shot) | ~81.2% | Llama 3.1 70B | | GSM8K (Math Reasoning) | ~94.8% | ~89.5% | Llama 3.1 70B | | HumanEval (Coding) | ~79.3% | ~82.4% | GLM-4.7-Flash | There are a few models that fit into the 22 GB: - 19 GB [glm-4.7-flash](https://ollama.com/library/glm-4.7-flash) with MoE and reasoning - 17 GB [translategemma:27b](https://ollama.com/library/translategemma) for 55 languages, maybe [timeline project](https://github.com/kreier/timeline)? - 20 GB [qwen3-vl:30b](https://ollama.com/library/qwen3-vl) vision-language model in the Qwen family A short chat wit Gemini revealed that to fully use the context window of 198K one need 40.5 GB VRAM, even though the model weights are only 15 GB. That's because the KV Cache needs 0.12 GB per 1k tokens in the MLA architecture. Maybe I should investigate that with a few longer text documents, since my available VRAM has been reduced by 4 GB in 2026, while also reducing the power consumption from 560W to 450W. (This will change in February, another P104-100 is added). The last GPU was only connected PCIe 1.0 x1 anyway (0.25 GB/s vs. 16 GB/s for 3.0 x16). | year | GPU | RAM | GB/s | |:----:|:--------:|:-----:|:----:| | 2023 | M1 | 8 GB | 68 | | 2024 | 3070 Ti | 8 GB | 608 | | 2025 | P106-100 | 26 GB | 192 | | 2026 | P104-100 | 30 GB | 320 | ### February 2026 This repository was renamed from Homeserver to Homelab, since more than just the server play a role here. Within a month the network expanded, and the server got a fourth GPU and 8GB of GDDR5X RAM. Now even larger models run, and all without a riser card. Unfortunately it also lost 16 GB of RAM. But maybe in 2027 it can get 16 GB DDR4 2667 back. And a CPU upgrade to a 7600K and an attempted 5 GHz frequency. Let's see. Now we can use more models in ollama with 30 GB VRAM: - [Qwen2.5:32b](https://ollama.com/library/qwen2.5) with 32.8B parameter and 20.4 GB memory required. - [nemotron-3-nano](https://ollama.com/library/nemotron-3-nano) with and 24 GB required. I got the H61 and H81 mainboards repaired for 100k VND each. Some filter capacitors were broken, they run fine again. And the P106-100 could not be fixed. But placed inside the G2030 it started working again and performed the OpenCL Benchmark without problems! Microfracture on the mainboard? Replaced thermal paste? Anyway, it works again. In January 2025 I tried [Qwen2.5:32b](https://ollama.com/library/qwen2.5) with 32.76B parameters and its 65 layers of 20 GB to fit into my 26 GB VRAM (8/6/6/6) machine. With 32 GB DDR4 I could run about **0.92 t/s** from the CPU, limited by the memory bandwidth of about 32 GB/s. But I **could not** get the layers split and load into VRAM successfully. See [ollama_multi_GPU.csv](https://github.com/kreier/benchmark/blob/main/llm/ollama_multi_GPU.csv). With **3 GPUs** (8/6/6) and 20 GB VRAM I could offload 80% to the GPU and got 21/14/15 layers there. The speed increased to 2.34 token/s. With a fourth GPU (8/6/6/6) I could get 98% of layers to the GPU: 19/15/15/15 and increased the inference to 5.11 token/s. **Why not 100%?** Just one more layer, you got already 21 into the 8GB GPU earlier! Well, I even commented on ollama Github about similar problems ([#7509 of ollama](https://github.com/ollama/ollama/issues/7509#issuecomment-2585521606) and I think in the time since then it has been fixed.) With the parameter `num_gpu=65` I got all layers offloaded, but also had an unstable system and **6.37 t/s**. Retest in 2026 with 30 GB of VRAM (8/8/8/6) and the layers are easily offloaded 18/18/18/11 and the inference is up to **8.42 token/s**. About 10x as fast as the CPU, with memory up to 320 GB/s on GDDR5X. A comparable model in size in 2026 is now available with [nemotron-3-nano](https://ollama.com/library/nemotron-3-nano) with 31.6B parameters, 53 layers and 24 GB model size. The context window is no longer just 32K but 1M! Now more MoE models are available, and the general speed has further increased for the same hardware, while the quality of the models also improved. Even though the memory footprint is 4GB larger the model is significantly faster! I get 38 t/s instead of just 8, almost 5x the speed because of MoE. And the answer is also much more sophisticated. Here a few more details of the comparison: | model | size | parameter | context | token/s | prompt | GPUs | layer | |--------------------------------------------------------------------|-----:|:---------:|--------:|:-------:|:------:|:----:|:-----:| | [qwen2.5:32b](https://ollama.com/library/qwen2.5) | 20GB | 32.8B | 32K | 8 | 75 | 4 | 65 | | [qwen3:32b](https://ollama.com/library/qwen3) | 20GB | 32.8B | 40K | 8 | 52 | 3 | 65 | | [gemma3:27b](https://ollama.com/library/gemma3) | 17GB | 27.4B | 128K | 9 | 50 | 3 | 63 | | [glm-4.7-flash:q4_K_M](https://ollama.com/library/glm-4.7-flash) | 19GB | 29.9B | 198K | 25 | 81 | 3 | 48 | | [nemotron-3-nano:30b](https://ollama.com/library/nemotron-3-nano) | 24GB | 31.6B | 1000K | 38 | 116 | 4 | 53 | | [gpt-oss:20b](https://ollama.com/library/gpt-oss) | 14GB | 20.9B | 128K | 42 | 238 | 2 | 25 | | [gemma3:4b](https://ollama.com/library/gemma3) | 4GB | 4.3B | 128K | 45 | 322 | 1 | 35 | Surprisingly the largest model in this 30B class is also the fastest: nemotron-3-nano. With its MoE architecture it rivals much smaller 20B and 4B models! All that on 10 year old hardware."
https://github.com/kreier/llama.cpp-jetson/blob/main/README.md,"# Llama.cpp with CUDA support on a Jetson Nano ![GitHub Release](https://img.shields.io/github/v/release/kreier/llama.cpp-jetson) ![GitHub License](https://img.shields.io/github/license/kreier/llama.cpp-jetson) [![pages-build-deployment](https://github.com/kreier/llama.cpp-jetson/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/llama.cpp-jetson/actions/workflows/pages/pages-build-deployment) It is possible to compile a recent llama.cpp with GPU support, using `gcc 8.5` and `nvcc 10.2` (latest supported CUDA compiler from Nvidia for the 2019 Jetson Nano). The steps to compile a new version are described here. You can also install a compiled version with [this other repository](https://github.com/kreier/llama.cpp-jetson.nano) in a few minutes. - [Prerequisites](#prerequisites) - [Procedure](#procedure) - 5 minutes, plus 85 minutes for the compilation in the last step - [Benchmark](#benchmark) - [B1: TinyLlama-1.1-Chat](#b1-tinyllama-11b-chat-2023-12-31) - [B2: Gemma3:1b](#b2-gemma31b-2025-03-12) - [Variance in PP (prompt processing) when using the GPU](#explaining-the-variance-in-prompt-processing-when-using-the-gpu) - [B3: Gemma3:4b](#b3-gemma34b) - [Running ollama and llama-server at the same time](#running-ollama-and-llama-server-at-the-same-time) - [B4: LFM2.5-1.2B-Thinking](#b4-lfm25-12b-thinking) - [Compile llama.cpp for CPU mode](#compile-llamacpp-for-cpu-mode) - 24 minutes - [Install build 5050](#install-build-5050) - 1 minute, first start needs extra 6:30 min (later 12 seconds) - [Install prerequisites](#install-prerequisites) - [Install `cmake >= 3.14`](#install-cmake--314) - 38 minutes - [Choosing the right compiler](#choosing-the-right-compiler) - [GCC 9.4](#gcc-94) - 4 minutes - [GCC 8.4](#gcc-84) - 24 seconds - [GCC 8.5](#gcc-85) - 3 hours - [History](#history) - [Sources](#sources) The Jetson Nano indeed uses the GPU ([footnote 1](#footnotes)) to generate tokens with 100% GPU load, 1.5 GB GPU memory and 4 Watt power usage, while the CPU is only used in the 14% range with 0.6 Watt. It is on average **20% faster** than the pure CPU use with ollama or a CPU build - see the [benchmark](#benchmark) section below! ## Prerequisites The following software packages need to be installed. The section ""[Install prerequisites](#install-prerequisites)"" describes the process in detail. The installation of `gcc 8.5` and `cmake 3.27` might take several hours. - Nvidia CUDA Compiler nvcc 10.2 - `nvcc --version` - GCC and CXX (g++) 8.5 - `gcc --version` - cmake >= 3.14 - `cmake --version` - `nano`, `curl`, `libcurl4-openssl-dev`, `python3-pip` and `jtop` ## Procedure Newer versions of llama.cpp are constantly relased. We will check out a specific version (b5050 from April 2025) known to be working to ensure this repository keeps working in the future. If you want to try a more recent version remove the steps `git checkout 23106f9` and `git checkout -b llamaJetsonNanoCUDA` in the following instructions: ### 1. Clone repository ``` sh git clone https://github.com/ggml-org/llama.cpp llama5050gpu.cpp cd llama5050gpu.cpp git checkout 23106f9 git checkout -b llamaJetsonNanoCUDA ``` For the next steps 2. to 5. we have to make changes to these 6 files: - CMakeLists.txt 14 - ggml/CMakeLists.txt 274 - ggml/src/ggml-cuda/common.cuh 455 - ggml/src/ggml-cuda/fattn-common.cuh 623 - ggml/src/ggml-cuda/fattn-vec-f32.cuh 71 - ggml/src/ggml-cuda/fattn-vec-f16.cuh 73 In early 2025 llama.cpp started supporting and using `bfloat16`, a feature not included in nvcc 10.2. We have two options: - Option A: Create two new files - /usr/local/cuda/include/cuda_bf16.h - /usr/local/cuda/include/cuda_bf16.hpp - Option B: Edit 3 files - ggml/src/ggml-cuda/vendors/cuda.h - ggml/src/ggml-cuda/convert.cu - ggml/src/ggml-cuda/mmv.cu Details for each option are described below in step 2 to 7: ### 2. Add a limit to the CUDA architecture in `CMakeLists.txt` Edit the file *CMakeLists.txt* with `nano CMakeLists.txt`. Add the following 3 lines after line 14 (with **Ctrl+\_** you can jump to this line, check line with **Ctrl+c**): ``` if(NOT DEFINED ${CMAKE_CUDA_ARCHITECTURES}) set(CMAKE_CUDA_ARCHITECTURES 50 61) endif() ``` Save with **Ctrl+o** and exit with **Ctrl+x**. ### 3. Add two linker instructions after line 274 in `ggml/CMakeLists.txt` Edit the file with `nano ggml/CMakeLists.txt` and enter two new lines after `set_target_properties(ggml PROPERTIES PUBLIC_HEADER ""${GGML_PUBLIC_HEADERS}"")` and before `#if (GGML_METAL)`. It should then look like: ``` h set_target_properties(ggml PROPERTIES PUBLIC_HEADER ""${GGML_PUBLIC_HEADERS}"") target_link_libraries(ggml PRIVATE stdc++fs) add_link_options(-Wl,--copy-dt-needed-entries) #if (GGML_METAL) # set_target_properties(ggml PROPERTIES RESOURCE ""${CMAKE_CURRENT_SOURCE_DIR}/src/ggml-metal.metal"") #endif() ``` With `target_link_libraries(ggml PRIVATE stdc++fs)` and `add_link_options(-Wl,--copy-dt-needed-entries)` we avoid some static link issues that don't appear in later gcc versions. See [nocoffei's comment](https://nocoffei.com/?p=352). ### 4. Remove *constexpr* from line 455 in `ggml/src/ggml-cuda/common.cuh` Use `nano ggml/src/ggml-cuda/common.cuh` to remove the **constexpr** after the *static* in line 455. This feature from CUDA C++ 17 we don't support anyway. After that it looks like: ``` h // TODO: move to ggml-common.h static __device__ int8_t kvalues_iq4nl[16] = {-127, -104, -83, -65, -49, -35, -22, -10, 1, 13, 25, 38, 53, 69, 89, 113}; ``` ### 5. Comment lines containing *__buildin_assume* by adding ""//"" in 3 files Comment the lines by adding a // in front of these 3 files. This avoids the compiler error *""__builtin_assume"" is undefined*. - line 623, `nano ggml/src/ggml-cuda/fattn-common.cuh` - line 71, `nano ggml/src/ggml-cuda/fattn-vec-f32.cuh` - line 73, `nano ggml/src/ggml-cuda/fattn-vec-f16.cuh` If you have a version lower than b4400 you can skip the next step. In January 2025 with version larger than b4400 llama.cpp started including support for `bfloat16`. There is a standard library `cuda_bf16.h` in the folder `/usr/local/cuda/targets/aarch64-linux/include` for nvcc 11.0 and larger. It has more than 5000 lines. One cannot simply copy and paste a version from Cuda 11 to our folder for Cuda 10.2 and hope it would work. The same applies to its companion `cuda_bf16.hpp` with 3800 lines. Since it is linked to version 11 or 12, the error messages keep expanding (e.g. `/usr/local/cuda/include/cuda_bf16.h:4322:10: fatal error: nv/target: No such file or directory`). We have two working options: ### 6. Option A: Create a `cuda_bf16.h` that redefines `nv_bfloat16` as `half` Create two new files in the folder `/usr/local/cuda/include/`, starting with `cuda_bf16.h`. You need root privileges, so execute `sudo nano /usr/local/cuda/include/cuda_bf16.h` and give it the following content: ``` h #ifndef CUDA_BF16_H #define CUDA_BF16_H #include // Define nv_bfloat16 as half typedef half nv_bfloat16; #endif // CUDA_BF16_H ``` Create the second file `sudo nano /usr/local/cuda/include/cuda_bf16.hpp` with the content ``` hpp #ifndef CUDA_BF16_HPP #define CUDA_BF16_HPP #include ""cuda_bf16.h"" namespace cuda { class BFloat16 { public: nv_bfloat16 value; __host__ __device__ BFloat16() : value(0) {} __host__ __device__ BFloat16(float f) { value = __float2half(f); } __host__ __device__ operator float() const { return __half2float(value); } }; } // namespace cuda #endif // CUDA_BF16_HPP ``` ### 6. Option B: Comment all code related to *bfloat16* in 3 files The second solution is to remove all references to the *bfloat16* data type in the 3 files referencing them. First we have to __NOT__ include the nonexisting `cuda_bf16.h`. Just add two // in front of line 6 with `nano ggml/src/ggml-cuda/vendors/cuda.h`. After that it looks like this: ``` h #include #include //#include #include ``` That is not enough, the new data type `nv_bfloat16` is referenced 8 times in 2 files. Replace each instance of them with `half` - 684 in `ggml/src/ggml-cuda/convert.cu` - 60 in `ggml/src/ggml-cuda/mmv.cu` - 67 in `ggml/src/ggml-cuda/mmv.cu` - 68 in `ggml/src/ggml-cuda/mmv.cu` - 235 in `ggml/src/ggml-cuda/mmv.cu` (2x) - 282 in `ggml/src/ggml-cuda/mmv.cu` (2x) **DONE!** Only two more instructions left. ### 7. Execute `cmake -B build` with more flags to avoid the CUDA17 errors We need to add a few extra flags to the recommended first instruction `cmake -B build`. If not done several errors like *Target ""ggml-cuda"" requires the language dialect ""CUDA17"" (with compiler extensions)* would stop the compilation. We still have a few warnings *constexpr if statements are a C++17 feature*, but we can ignore them. ``` sh cmake -B build -DGGML_CUDA=ON -DLLAMA_CURL=ON -DCMAKE_CUDA_STANDARD=14 -DCMAKE_CUDA_STANDARD_REQUIRED=true -DGGML_CPU_ARM_ARCH=armv8-a -DGGML_NATIVE=off ``` And 15 seconds later we're ready for the last step, the instruction that will take **85 minutes** (faster SD card: 60 minutes) to have llama.cpp compiled: ``` sh cmake --build build --config Release ``` Successfully compiled! ![output compiling](https://raw.githubusercontent.com/kreier/llama.cpp-jetson/main/docs/compile5050.png) After that you can start a conversation with Gemma3 about finer details of our universe: ``` sh ./build/bin/llama-cli -hf ggml-org/gemma-3-1b-it-GGUF -p ""Explain quantum entanglement"" --n-gpu-layers 99 ``` ![llama.cpp 5043 GPU](https://raw.githubusercontent.com/kreier/llama.cpp-jetson/main/docs/llama5043gpu.png) The answers vary, sometimes it throws in a video from Veritasium. And it could easily *""Write a 1000 word essay about the French Revolution""* with $pp = 21 \frac{token}{s}$ and $tg = 5.13 \frac{token}{s}$. Impressive! ## Benchmark We use the same Jetson Nano machine from 2019, no overclocking settings. The test prompt for `llama-cli`, `ollama` and the older `main` is ""Explain quantum entanglement"". Tests include the latest ollama 0.6.4 from April 2025 in CPU mode and several versions of llama.cpp compiled in pure CPU mode and with GPU support, using different amounts of layers offloaded to the GPU. The three LLM models considerd in the benchmarks are: - 2023-12-31 **B1:** [TinyLlama-1.1B-Chat Q4 K M](https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF?show_file_info=tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf) with 669 MB, 22 layers, 1.1 billion parameters and 2048 context length - 2025-03-12 **B2:** [Gemma3:1b Q4 K M](https://huggingface.co/ggml-org/gemma-3-1b-it-GGUF?local-app=llama.cpp) with 806 MB, 27 layers, 1 billion parameters and 32768 context length - 2025-04-03 **B3:** [Gemma3:4b_it_qat_q4_0](https://huggingface.co/google/gemma-3-4b-it-qat-q4_0-gguf) with 3.16 GB, 35 layers, 3.88 billion parameters, image-to-text support (normalized 896x896) and 128000 total input context ### B1: TinyLlama-1.1B-Chat 2023-12-31 The first prompt is for older builds b1618 and b2275 that use `main`, while b4400 and b5050 use the second `llama-cli` call. Put the prompt in the cli after the startup. ``` sh ./main -hf TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF --n-gpu-layers 25 -p ""Explain quantum entanglement"" ./build/bin/llama-cli -hf TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF --n-gpu-layers 25 llama-cli -hf kreier/tiny ``` llama.cpp has also a build-in benchmark program alled `llama-bench`, here tested with the CUDA version b5043: ``` sh m@n:~/./build/bin/llama-bench -m ../.cache/llama.cpp/TheBloke_TinyLlama-1.1B-Chat-v1.0.Q2_K.gguf --n-gpu-layers 99 ggml_cuda_init: found 1 CUDA devices: Device 0: NVIDIA Tegra X1, compute capability 5.3, VMM: no | model | size | params | backend | ngl | test | t/s | | ---------------------- | ---------: | -----: | ------- | --: | ----: | -----------: | | llama 1B Q4_K - Medium | 636.18 MiB | 1.10 B | CUDA | 99 | pp512 | 80.57 ยฑ 0.33 | | llama 1B Q4_K - Medium | 636.18 MiB | 1.10 B | CUDA | 99 | tg128 | 6.69 ยฑ 0.00 | build: c262bedd (5043) ``` The prompt processing speed seems to be too high in this benchmark (found the answer a few days later, see [explanation later in this document](#explaining-the-variance-in-prompt-processing-when-using-the-gpu)) for the small models run on the Jetson Nano. To have a more realistic comparison for the graph below the `llama-cli` was used to determine both the pp and tg metrics. Similar results were achieved with longer prompts like ""Write a 1000 word essay about the French Revolution"". ![TinyLlama as svg](https://raw.githubusercontent.com/kreier/llama.cpp-jetson/main/docs/TinyLlama_20250411.svg) **Explanation**: Earlier editions of llama.cpp like b1618 from December 2023 or b4400 from December 2024 got faster in all their metrics with improvements to their code. The native speed of a CPU compile from April 2025 (b5036) has the same speed (within error) as a CPU build from ollama 0.6.4 from the same time for both pp and tg. The main metric to compare here is the **token generation**. Initial versions with GPU acceleration with all layers in December 2023 was slower than the current CPU version (5.25 vs 3.94), by the end of 2024 the GPU *is accelerating* the token generation, and with CUDA it is around **20% faster** (5.25 vs. 6.28 average)! Here just tg in green over CPU/GPU and time: ![TinyLlama as svg](https://raw.githubusercontent.com/kreier/llama.cpp-jetson/main/docs/TinyLlama_20250411_tg.svg) As expected, the prompt processing is even further accelerated, since it is very compute intensive. But it only contributes to a small time amount of the final answer. *Another observation:* A GPU optimized version is significantly slower than a CPU optimized version for the Jetson with the shared memory architecture when not all layers are offloaded to the GPU. ### B2: Gemma3:1b 2025-03-12 This much more recent [model from March 2025](https://huggingface.co/ggml-org/gemma-3-1b-it-GGUF?local-app=llama.cpp) is slightly larger with 806 MB but much more capable than TinyLlama, and comparable in speed. The prompt is ""Explain quantum entanglement"" ``` sh llama-cli -hf ggml-org/gemma-3-1b-it-GGUF --n-gpu-layers 99 llama-cli -hf unsloth/gemma-3-1b-it-GGUF:Q4_K_M ./build/bin/llama-bench -m ../.cache/llama.cpp/ggml-org_gemma-3-1b-it-GGUF_gemma-3-1b-it-Q4_K_M.gguf --n-gpu-layers 0 ``` There is also an integrated benchmark program `build/bin/llama-bench -m ggml-org/gemma-3-1b-it-GGUF` in llama.cpp. The results for prompt processing seem artificially high ([graph and explanation later in this document](#explaining-the-variance-in-prompt-processing-when-using-the-gpu)), but demonstrate a dependence on the number of layers used: | layers | 0 | 5 | 10 | 15 | 20 | 25 | 27 | CPU | |:-----------------:|:-----:|:-----:|:------:|:------:|:------:|:------:|:------:|:----:| | prompt processing | 96.63 | 97.41 | 100.46 | 105.14 | 109.68 | 113.95 | 115.75 | 7.47 | | token generation | 2.57 | 2.86 | 3.21 | 3.65 | 4.21 | 5.01 | 5.84 | 4.27 | A general result of the benchmark looks like this: ``` sh ggml_cuda_init: found 1 CUDA devices: Device 0: NVIDIA Tegra X1, compute capability 5.3, VMM: no | model | size | params | backend | ngl | test | t/s | | ----------------------- | ---------: | -------: | ------- | --: | ----: | ------------: | | gemma3 1B Q4_K - Medium | 762.49 MiB | 999.89 M | CUDA | 27 | pp512 | 115.75 ยฑ 0.08 | | gemma3 1B Q4_K - Medium | 762.49 MiB | 999.89 M | CUDA | 27 | tg128 | 5.84 ยฑ 0.01 | build: 193c3e03 (5038) ``` While a compiled CPU version of llama.cpp is comparable in speed with a recent ollama version, so might a GPU version be slower when not offloading layers to the GPU, but be **20% faster** if the model is offloaded to the GPU! #### Applications for Gemma 3 1b One might wonder if there are some applications for this small 1 billion parameter model that runs on the Jetson with GPU acceleration. Here are a few I found: - [Fix broken JSON from user gracefully for better UX](https://www.reddit.com/r/LocalLLaMA/comments/1jcmyuc/comment/mkrgch7/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) on reddit, prompt is ""Fix syntax issue in this and respond with corrected JSON but not anything else"", The output is a plane JSON and I can take it back to .NET - [Fine-Tuning Gemma 3 1B-IT for Financial Sentiment Analysis: A Step-by-Step Guide](https://medium.com/@lucamassaron/fine-tuning-gemma-3-1b-it-for-financial-sentiment-analysis-a-step-by-step-guide-1a025d2fc75d) by [Luca Massaron](https://medium.com/@lucamassaron), 2025-03-26 on medium.com #### Extended testing with 11 prompts on 3 llm interpreters To better evaluate the improvements with the GPU usage I tested 11 prompts on ollama 0.6.4 with CPU, llama.cpp b5058 compiled for CPU and then llama.cpp b5050 for GPU. The initial **prompt processing** now 2.4x faster than ollama and more than 3.1x faster than llama.cpp for CPU. But for our prompts that's only 1-4 seconds. The more important **token generation** is 11% faster with CUDA than on CPU with ollama, and on **average 25% faster** than llama.cpp on CPU. All details can be found in [this Google sheet](https://docs.google.com/spreadsheets/d/1jJhGaHdU4valkIb42PoklJUs4nkPywOTQi1LQ52G1lY/edit?usp=sharing). The standard deviation on the prompt processing is rather large, since depending on the prompt the speed varies 11-44 token/second. Here are the numerical values: | llm software | prompt processing | token generation | |---------------------|:-----------------:|:----------------:| | ollama CPU 0.6.4 | 9.56 ยฑ 0.3 | 4.69 ยฑ 0.23 | | llama.cpp CPU b5058 | 7.5 ยฑ 0.3 | 4.22 ยฑ 0.14 | | llama.cpp GPU b5050 | 23.29 ยฑ 9.6 | 5.26 ยฑ 0.37 | Here are the 11 questions or prompts: - Explain quantum entanglement - Write a 1000 word essay about the French revolution - Compare Goldilocks to Cinderella - Write a python program that generates 100 random strings for a name and family name, and export them as a csv file - Write a haiku about artificial intelligence - Explain the fundamental theorem of calculus and its symbols - What is CRISPR and what can it be used for? - If a train travels 100 miles in 2 hours, and then travels 50 miles in 1 hour, what is its average speed for the entire trip? Let's think step by step. - You are a travel guide. Recommend a 3-day itinerary for someone visiting Tokio, focusing on local culture and food. - Imagine there is a circular pond in an oasis, with two trees at the edge of the pond, on opposite sides. Bob sets up a hammock by hanging it between the two trees. He gets into the hammock and falls asleep. If he were to roll over in his sleep and fall out of the hammock, where would he fall? - What is e? In a combined graph it looks like this: #### Explaining the variance in prompt processing when using the GPU The big variance in processing speed for the input tokens was surprizing. Having a closer look it appeared that longer input prompts achieve a faster speed. This would in part explain the very high results when using `llama-bench` since it labels its speed results as `pp512` which is rather large. The 11 prompts from this benchmark range only from 12 to 76 tokens in Gemma3. The following graph visualizes that this dependency from the prompt length exists, while it does not change in CPU mode. And the token generation rate tg is also not affected, this only has a slightly faster generation speed in the first seconds: ![pp and tg versus number of input tokens](docs/gemma3_b5050_pp_tg.png) You see in the left graph that the token generation with GPU is slightly faster than the CPU mode (blue vs. yellow) for all input lengths. The prompt processing is faster, and with CPU independent of prompt length (red) but faster with longer prompts (green). #### Increased speed in token generation when exporting more layers to the GPU Another parameter affecting the speed of generating an answer is the number of layers exported to the GPU with `--n-gpu-layers 99`. In this case the **prompt processing** is largely unaffected, while it **more than doubles** the speed of the **token generation** - even with the unified memory of the Jetson Nano. A CPU compile as only `4.27` in token generation: #### Reason for GPU 20% faster than CPU Since inference speed is usually limited by the memory bandwidth (known as ""latency bottleneck"") it is surprizing to see some increased speed for the use of the GPU on the shared 4GB LPDDR4 memory with a theoretical speed of **25.60 GB/s**. With the CPU I get only 26% or **6.7 GB/s**: ``` sh mk@jetson:~$ sysbench memory --memory-block-size=32m run sysbench 1.0.11 (using system LuaJIT 2.1.0-beta3) 68903.00 MiB transferred (6887.13 MiB/sec) ``` The memory access for the GPU seems to be 2.4x faster with **16.5 GB/s** or 64% of the theoretical maximum. Maybe a feature of the MMU? The result is from a compiled `bandwidthTest` in the sample folder: ``` sh mk@nano:/usr/local/cuda/samples/1_Utilities/bandwidthTest$ ./bandwidthTest [CUDA Bandwidth Test] - Starting... Running on... Device 0: NVIDIA Tegra X1 Quick Mode Host to Device Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(GB/s) 32000000 7.1 Device to Host Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(GB/s) 32000000 10.3 Device to Device Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(GB/s) 32000000 16.5 Result = PASS NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled. ``` ### B3: Gemma3:4b One might think that a quantized version of Gemma 3 with 4 billion parameters might work with the 4 GB RAM of the Jetson Nano. And to a degree it does, but not in a usable way. One advantage of the 4B model is its multimodality, so it could also be used for images. It would be slow, but there might be usecases where the Jetson would just crunch images and data in solitude, and we would return next day to examine the results. Well, here is my take on it: I tried 4 quantization levels: Q2, Q3, Q4 and the original file from Google. Plus the 1b version for comparison. - **1b:latest** - gemma3:1b - **4b:Q2** - hf.co/unsloth/gemma-3-4b-it-GGUF:Q2_K - **4b:Q3** - hf.co/unsloth/gemma-3-4b-it-GGUF:Q3_K_M - **4b:Q4** - hf.co/unsloth/gemma-3-4b-it-GGUF:Q4_K_M - **4b:latest** - gemma3:latest Here are the sizes of the files and the used memory **in Gigabyte** with *ollama 0.6.4* (April 2025) on Jetson, x86_64 CPU and Nvidia GPU: | model | file | Jetson | CPU | GPU | |:--------------------------------------- |:---------:|:------:|:---:|:---:| | gemma3:1b | 0.815 | 1.9 | 1.5 | 1.9 | | hf.co/unsloth/gemma-3-4b-it-GGUF:Q2_K | 1.7 | 1.9 | 3.9 | 4.4 | | hf.co/unsloth/gemma-3-4b-it-GGUF:Q3_K_M | 2.9 | 2.3 | 4.3 | 4.7 | | hf.co/unsloth/gemma-3-4b-it-GGUF:Q4_K_M | 3.3 | 2.8 | 4.7 | 5.2 | | gemma3:latest | 3.3 | -- | 5.7 | 6.2 | With llama.cpp I tried to offload all 37 layers to the GPU, but it only worked for the Q2 quantization. Ollama 0.6.4 worked in pure CPU mode until Q4 on the Jetson with the unsloth variant, but crashed with Google's version. | type | pp | tg | pp | tg | pp | tg | pp | tg | | --------- |:---------:|:---------:|:------:|:------:|:------:|:------:|:------:|:------:| | 1b:latest | 17.58 | 5.37 | 12.74 | 4.77 | 71.63 | 31.73 | 76.11 | 166.47 | | 4b:Q2 | 1.77 | 1.52 | 1.98 | 1.51 | 45.55 | 14.98 | 65.96 | 87.21 | | 4b:Q3 | -- | -- | 5.81 | 1.52 | 20.16 | 13.04 | 72.81 | 77.31 | | 4b:Q4 | -- | -- | 2.32 | 1.61 | 18.57 | 11.64 | 69.28 | 90.41 | | 4b:latest | -- | -- | -- | -- | 20.51 | 12.69 | 75.67 | 90.25 | | machine | llama.cpp | llama.cpp | Jetson | Jetson | 13700T | 13700T | 3060Ti | 3060Ti | ### Running ollama and llama-server at the same time With the compiled CUDA version of llama.cpp we can now run `./llama5135.cpp/build/bin/llama-server -m ~/.cache/llama.cpp/kreier_gemma3-1b_gemma3-1b.gguf -ngl 99 --host 0.0.0.0` with 4.7 t/s and `ollama run --verbose gemma3:1b` with 3.9 token/s at the same time: ![Ollama and llama-server](docs/ollama+llama.cpp.png) ``` sh **What do you think? Would you like me to:** * Write another story? * Expand on a particular part of this story? * Suggest a genre (e.g., mystery, fantasy)? total duration: 3m43.341644716s load duration: 453.781209ms prompt eval count: 13 token(s) prompt eval duration: 1.894296054s prompt eval rate: 6.86 tokens/s eval count: 854 token(s) eval duration: 3m40.892523137s eval rate: 3.87 tokens/s >>> /bye mk@nano:~$ ollama ps NAME ID SIZE PROCESSOR UNTIL gemma3:1b 8648f39daa8f 854 MB 100% CPU 53 seconds from now ``` Without `llama-server` running the background `ollama` is only slightly faster with 4.49 t/s (16% faster). The independent systems for CPU and GPU therefore don't slow down one another very much, even though using the same unified memory. ![Liquid](docs/liquid.png) ### B4: LFM2.5-1.2B-Thinking A little later in 2025 a new sub-2B model arrived that significantly outperformed both Gemma3:1b and Llama3.2:1B Instruct. But it's not supported by `b5050` yet. Can we build a newer llama.cpp and get a smarter agent? The use cases for bfloat16 increase ... Look here on ollama: [https://ollama.com/library/lfm2.5-thinking](https://ollama.com/library/lfm2.5-thinking) - Latest update: January 20, 2026. - 588k downloads on ollama.com - 47k downloads on Huggingface: [https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking](https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking) ## Compile llama.cpp for CPU mode This can be done with `gcc 8.5` or `gcc 9.4` in 24 minutes and was tested with a version as recent as April 2025. You can follow the [instructions from llama.cpp](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md). We added the parameter `-DLLAMA_CURL=ON` to support an easy model download from huggingface with the `-hf` command: ``` sh git clone https://github.com/ggml-org/llama.cpp cd llama.cpp cmake -B build -DLLAMA_CURL=ON cmake --build build --config Release ``` After finishing the compilation its time for the first model and AI chat: ``` ./build/bin/llama-cli -hf ggml-org/gemma-3-1b-it-GGUF ``` ## Install build 5050 The fastest way to get llama.cpp with CUDA support running is installing the compiled files with this script in 44 seconds from [this repository](https://github.com/kreier/llama.cpp-jetson.nano): ``` sh curl -fsSL https://kreier.github.io/llama.cpp-jetson.nano/install.sh | bash && source ~/.bashrc ``` The first start with Gemma3 will take **almost 7 minutes** after `main: load model the model and apply lora adapter, if any`, but later runs start in **12 seconds**: ``` sh llama-cli -hf ggml-org/gemma-3-1b-it-GGUF --n-gpu-layers 99 ``` A copy of [TinyLlama](https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF) has the same **6:30 min** startup pause at the `main: load model the model and apply lora adapter, if any` step. It can be started with `llama-cli -hf kreier/tiny`. If you downloaded Gemma3:1b with `llama-cli -hf kreier/gemma3-1b` you can start your webserver with `llama-server -m ~/.cache/llama.cpp/kreier_gemma3-1b_gemma3-1b.gguf --host 0.0.0.0 --n-gpu-layers 99`. ## Install prerequisites The [latest image from Nvidia](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write) for the 2019 Jetson Nano contains a ubuntu 18.04 LTS distribution with a kernel *Kernel GNU/Linux 4.9.201-tegra*, the *GNU Compiler Collection 7.5.0 (G++ 7.5.0) from 2019*, the *NVIDIA Cuda Compiler nvcc 10.3.200* and has *Jetpack 4.6.1-b110* (check with `sudo apt-cache show nvidia-jetpack`) installed. If `nvcc --version` does not confirm the installed Cuda Compiler you need to update the links with this automated script: `curl -fsSL https://kreier.github.io/jetson/fix/cuda-path.sh | bash && source ~/.bashrc` or manually with these two lines: ``` sh export PATH=/usr/local/cuda/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} ``` As best practice you can add these to the end of your *.bashrc* with `nano .bashrc`. ### Update the system - can be skipped I tested this, and you can skip this step and 2 hours, the procedure works well with the provided older packages. Usually I updated the system and the installed packages to the latest available versions, and with a vanilla image currently about 348 packages have to be updated. Without the upgrade your system states: - JetPack 4.6.1 (32.7.1-20220219090432) - `dpkg-query --show nvidia-l4t-core` - kernel Linux nano 4.9.253-tegra from February 19, 2022 - `uname -a` The upgrade will take several hours. I tested and it is actually not necessary to **upgrade** to compile llama.cpp. And it is not necessary to run the compiled version of llama.cpp b5050 available [here](https://github.com/kreier/llama.cpp-jetson.nano). ``` sh sudo apt update sudo apt upgrade ``` At two occations you are asked to decide if you want to update a specific settings file. And a third interruption is about starting the docker daemon. All three are towards the end of the update cycle. One of the things updated (perform a reboot) is the jetpack and kernel: - JetPack 4.6.6 (L4T 32.7.6-20241104234540) - `dpkg-query --show nvidia-l4t-core` - kernel Linux nano 4.9.337-tegra from November 4, 2024 - `uname -a` Now there are 3 further things to install or update: - **4 minutes**: a few additional packages like `jtop` to check system activity - **38 minutes**: cmake >= 3.14 (we chose 3.27) - **3 hours**: gcc 8.5.0 (it works with 9.4 too, if not to export to another machine - then only 4 minutes) ### Install additional helpful packages ``` sh sudo apt update sudo apt install nano curl libcurl4-openssl-dev python3-pip pip3 -H install -U jetson-stats ``` The last one `jetson-stats` can be called later as `jtop`. ### Install `cmake >= 3.14` Purge any old `cmake` installation and install a newer `3.27`. It will take **38 minutes** (`bootstrap` and `make` each take 18 minutes). ``` sh sudo apt-get remove --purge cmake sudo apt-get install libssl-dev wget https://cmake.org/files/v3.27/cmake-3.27.1.tar.gz tar -xzvf cmake-3.27.1.tar.gz cd cmake-3.27.1 ./bootstrap make -j4 sudo make install ``` ## Choosing the right compiler ### GCC 9.4 This compiler from June 1, 2021 can be easily installed from an apt repository in a few minutes, using ``` sh sudo apt install build-essential software-properties-common manpages-dev -y sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y sudo apt update sudo apt install gcc-9 g++-9 -y sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 9 sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 9 ``` Yet versions 9 and higher are not compatible with `nvcc 10.2` and show `error: #error -- unsupported GNU version! gcc versions later than 8 are not supported!`. The reasons are found in line 136 of `/usr/local/cuda/targets/aarch64-linux/include/crt/host_config.h`: ``` h #if defined (__GNUC__) #if __GNUC__ > 8 #error -- unsupported GNU version! gcc versions later than 8 are not supported! #endif /* __GNUC__ > 8 */ ``` You can edit this line. Change **8** to a **9** with `sudo nano /usr/local/cuda/targets/aarch64-linux/include/crt/host_config.h` in line 136. Then the compilation is the same as with 8.5, and the installation is much faster, just 4 minutes instead of 3 hours! The created files rely on the library `/usr/lib/aarch64-linux-gnu/libstdc++.so.6` being linked to `/usr/lib/aarch64-linux-gnu/libstdc++.so.6.0.32`. But gcc 7.5 has only `libstdc++.so.6.0.25`, so the compiled binary will thrown an error if running on a system with only gcc 7.5. Just copying this library and updating the link leads to a crash shortly after starting the CUDA part, don't know why yet. But gcc 9.4 is useful for test purposes. Version gcc 8.5 uses the older library 6.0.25 that is shipped with gcc 7.5. So 9.4 is good for fast testing, 8.5 better for long term compatibility. ### GCC 8.4 This compiler version 8.4 from March 4, 2020 can be installed in the same fast fashion as the mentioned 9.4 above. Will run 24 seconds, with all steps 2 minutes. Just replace three lines: ``` sh sudo apt install gcc-8 g++-8 -y sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 8 sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-8 8 ``` But it throws an error on `llama.cpp/ggml-quants.c` line 407 with: ``` sh ~/llama.cpp/ggml-quants.c: In function โggml_vec_dot_q3_K_q8_Kโ: ~/llama.cpp/ggml-quants.c:407:27: error: implicit declaration of function โvld1q_s8_x4โ; did you mean โvld1q_s8_xโ? [-Werror=implicit-function-declaration] #define ggml_vld1q_s8_x4 vld1q_s8_x4 ``` It seems that in version 8.4 the ARM NEON intrinsic `vld1q_s8_x4` is treated as a built-in function that cannot be replaced by a macro. It might be related to a fix from [ktkachov on 2020-10-13](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=97349) as one of the [199 bug fixes](https://gcc.gnu.org/bugzilla/buglist.cgi?bug_status=RESOLVED&resolution=FIXED&target_milestone=8.5) leading to 8.5. Let's use the next version: ### GCC 8.5 This version was released May 14, 2021. Unfortunately this version is not yet available for ubuntu 18.04 on `ppa:ubuntu-toolchain-r/test`. We have to compile it by ourselves, and this takes some 3 hours (for the `make -j$(nproc)` step). The steps are: ``` sh sudo apt-get install -y build-essential software-properties-common sudo apt-get install -y libgmp-dev libmpfr-dev libmpc-dev wget http://ftp.gnu.org/gnu/gcc/gcc-8.5.0/gcc-8.5.0.tar.gz tar -xvzf gcc-8.5.0.tar.gz cd gcc-8.5.0 ./contrib/download_prerequisites mkdir build && cd build ../configure --enable-languages=c,c++ --disable-multilib make -j$(nproc) # Use all CPU cores sudo make install sudo update-alternatives --install /usr/bin/gcc gcc /usr/local/bin/gcc 100 sudo update-alternatives --install /usr/bin/g++ g++ /usr/local/bin/g++ 100 ``` #### Library libstdc++ updated with gcc 9.x Code compiled with gcc 8.5 runs without a problem on systems only having gcc 7.5 installed (default for the Ubuntu 18.04.6 LTS image provided by Nvidia) since the standard library `libstdc++` is version 6.0.25 for both. It is only updated for the 9.x version of gcc, and then compiled binaries throw an error. | version | release | libstdc++ | GLIBCXX | /usr/lib/gcc/~/version | |---------|------------|-----------|---------|------------------------| | 7.5.0 | 2019-11-14 | 6.0.25 | 3.4.25 | | | 8.4.0 | 2020-03-04 | 6.0.25 | 3.4.25 | | | 8.5.0 | 2021-05-14 | 6.0.25 | 3.4.25 | ~/8/3.4.25 | | 9.4.0 | 2021-06-01 | 6.0.32 | 3.4.32 | ~/9/3.4.32 | | 13.3.0 | 2024-05-21 | 6.0.33 | 3.4.33 | ~/13/3.4.33 | - GCC versions: [https://gcc.gnu.org/releases.html](https://gcc.gnu.org/releases.html) - `ll /usr/lib/aarch64-linux-gnu/libstd*` - `strings /usr/lib/aarch64-linux-gnu/libstdc++.so.6 | grep GLIBCXX` - `strings /usr/lib/gcc/aarch64-linux-gnu/7/libstdc++.so | grep GLIBCXX` - `strings /usr/lib/gcc/aarch64-linux-gnu/8/libstdc++.so | grep GLIBCXX` - `strings /usr/lib/gcc/aarch64-linux-gnu/9/libstdc++.so | grep GLIBCXX` ## History As of April 2025 the current version of llama.cpp can be compiled for the Jetson Nano from 2019 with GPU/CUDA support using `gcc 8.5` and `nvcc 10.2`. Here is a list of a few earlier solutions with description, sorted by their build date. Their performance is later compared in [benchmarks](https://github.com/kreier/jetson/tree/main/llama.cpp#benchmark): - 2025-04-05 [b5050](https://github.com/ggml-org/llama.cpp/releases/tag/b5050) Some extra steps had to be included to handle the new support of `bfloat16` in llama.cpp since January 2025. Procedure is described in [this gist](https://gist.github.com/kreier/6871691130ec3ab907dd2815f9313c5d). After 24 revisions it became the foundation for this repository. - 2024-12-31 [b4400](https://github.com/ggml-org/llama.cpp/releases/tag/b4400) Following the steps from the [gist](https://gist.github.com/kreier/6871691130ec3ab907dd2815f9313c5d) above, step 6 can be ommited. Source: a [build for the Nintendo Switch](https://nocoffei.com/?p=352)! - 2024-02-26 [b2275](https://github.com/ggml-org/llama.cpp/tree/b2275) A [gist by Flor Sanders](https://gist.github.com/FlorSanders/2cf043f7161f52aa4b18fb3a1ab6022f) from 2024-04-11 describes the procedure to combile a version with GPU acceleration. - 2023-12-07 [b1618](https://github.com/ggml-org/llama.cpp/tree/b1618) A [medium.com article from Anurag Dogra](https://medium.com/@anuragdogra2192/llama-cpp-on-nvidia-jetson-nano-a-complete-guide-fb178530bc35) from 2025-03-26 describes the modification needed to compile llama.cpp with `gcc 8.5` and CUDA support. ## Sources - 2025-03-26 [LLAMA.CPP on NVIDIA Jetson Nano: A Complete Guide](https://medium.com/@anuragdogra2192/llama-cpp-on-nvidia-jetson-nano-a-complete-guide-fb178530bc35), *Running LLAMA.cpp on Jetson Nano 4 GB with CUDA 10.2* by Anurag Dogra on medium.com. His modifications compile an older version of llama.cpp with `gcc 8.5` successfully. Because the codebase for llama.cpp is rather old, the performance with GPU support is significantly worse than current versions running purely on the CPU. This motivated to get a more recent llama.cpp version to be compiled. He uses the version [81bc921](https://github.com/ggml-org/llama.cpp/tree/81bc9214a389362010f7a57f4cbc30e5f83a2d28) from December 7, 2023 - [b1618](https://github.com/ggml-org/llama.cpp/tree/b1618) of llama.cpp. - 2025-01-13 Guide to compile a recent llama.cpp with CUDA support for the Nintendo Switch at [nocoffei.com](https://nocoffei.com/?p=352), titled ""Switch AI โจ"". The Nintendo Switch 1 has the same Tegra X1 CPU and Maxwell GPU as the Jetson Nano, but 256 CUDA cores instead of just 128, and a higher clock rate. This article was the main source for this gist. - 2024-04-11 [Setup Guide for `llama.cpp` on Nvidia Jetson Nano 2GB](https://gist.github.com/FlorSanders/2cf043f7161f52aa4b18fb3a1ab6022f) by Flor Sanders in a gist. He describes the steps to install the `gcc 8.5` compiler on the Jetson. In step 5 he checks out the version [a33e6a0](https://github.com/ggml-org/llama.cpp/commit/a33e6a0d2a66104ea9a906bdbf8a94d050189d91) from February 26, 2024 - [b2275](https://github.com/ggml-org/llama.cpp/tree/b2275) - 2024-05-04 [Add binary support for Nvidia Jetson Nano- JetPack 4 #4140](https://github.com/ollama/ollama/issues/4140) on issues for ollama. In his initial statement dtischler assumes llama.cpp would require gcc-11, but it actually compiles fine with gcc-8 in version 8.5 from May 14, 2021 as shown in this gist. ## Footnotes 1. Using ollama and checking the system with `ollama ps` gives a high percentage of GPU usage as an answer. But as can be confirmed with `jtop`, the GPU is actually **not used**. Neither can we see GPU memory used, nor a percentage of utilization, nor the power draw for the GPU increasing. The metrics provided by ollama are obviously not correct."
https://github.com/kreier/wob/blob/main/README.md,"# wob - Wake On Bluetooth ![GitHub Release](https://img.shields.io/github/v/release/kreier/wob) ![GitHub License](https://img.shields.io/github/license/kreier/wob) This should fix my mainboard, where WOL does not work. It should be fixed with a esp32c3 to wake from S3 (Suspend) when it receives a BLE signal. ## Motivation My EVGA Z170 classified 4-way mainboard has **TWO** GbE ports: Intel i210 and i219. The latter even has a specific setting in the BIOS to activate WOL. Both are powered in S5 (Sleep) and recieve traffic, as indicated by their LEDs on the back. But their signal is never picked up by the mainboard, since the hardware and softwware implementation is focused on maximum overclocking, and not running a server. The magic packed arrives, and the mainboard **just ignores it** and keeps sleeping ๐ณ. Let's fix this! ## Limitations I tried this project with a Raspbery Pico W and WLAN. Unfortunately the idle power consumption of this solution is too high. As soon as the penta server enters S3 the Pico looses power. So I need a solution that requires less power. BLE is part of the solution, and a Supermini is just $2 and serves the purpose. Recommendation: - Visual Studio Code with ESP-IDF - Arduino IDE - NeoVIM and CLI ## Code C And here is a code example for the esp32c3. ```c #include #include ""esp_log.h"" #include ""nvs_flash.h"" #include ""esp_pm.h"" // Bluetooth Includes #include ""nimble/nimble_port.h"" #include ""nimble/nimble_port_freertos.h"" #include ""host/ble_hs.h"" #include ""services/gap/ble_svc_gap.h"" #include ""services/gatt/ble_svc_gatt.h"" // USB Includes #include ""tinyusb.h"" #include ""class/hid/hid_device.h"" static const char *TAG = ""PentaWake""; uint16_t wake_handle; // --- USB HID Configuration --- static uint8_t const desc_hid_report[] = { TUD_HID_REPORT_DESC_KEYBOARD(HID_REPORT_ID(1)) }; const tinyusb_config_t tusb_cfg = { .device_descriptor = NULL, .string_descriptor = NULL, .external_phy = false, .configuration_descriptor = NULL, }; // --- BLE GATT Logic --- static int ble_svc_wake_cb(uint16_t conn_handle, uint16_t attr_handle, struct ble_gatt_access_ctxt *ctxt, void *arg) { if (ctxt->op == BLE_GATT_ACCESS_OP_WRITE_CHR) { ESP_LOGI(TAG, ""Wake signal received via BLE!""); // 1. Send USB Remote Wakeup to PC if (tud_suspended()) { tud_remote_wakeup(); } // 2. Send a dummy keystroke just in case the PC is awake but screen is off uint8_t keycode[6] = {HID_KEY_F15}; tud_hid_keyboard_report(1, 0, keycode); vTaskDelay(pdMS_TO_TICKS(50)); tud_hid_keyboard_report(1, 0, NULL); // Release key return 0; } return BLE_ATT_ERR_UNLIKELY; } static const struct ble_gatt_svc_def gatt_svcs[] = { {.type = BLE_GATT_SVC_TYPE_PRIMARY, .uuid = BLE_UUID128_DECLARE(0xDE, 0xAD, 0xBE, 0xEF, 0xBA, 0xBE, 0xCA, 0xFE, 0xDE, 0xAD, 0xBE, 0xEF, 0xBA, 0xBE, 0xCA, 0xFE), .characteristics = (struct ble_gatt_chr_def[]){ {.uuid = BLE_UUID16_DECLARE(0xFF01), .access_cb = ble_svc_wake_cb, .flags = BLE_GATT_CHR_F_WRITE, .val_handle = &wake_handle}, {0}}}, {0}}; void ble_app_advertise(void) { struct ble_hs_adv_fields adv_fields = {0}; adv_fields.flags = BLE_HS_ADV_F_DISC_GEN | BLE_HS_ADV_F_BREDR_UNSUP; adv_fields.name = (uint8_t *)""Power button Penta""; adv_fields.name_len = strlen(""Power button Penta""); adv_fields.name_is_complete = 1; ble_gap_adv_set_fields(&adv_fields); struct ble_gap_adv_params adv_params = {0}; adv_params.conn_mode = BLE_GAP_CONN_MODE_UND; adv_params.disc_mode = BLE_GAP_DISC_MODE_GEN; ble_gap_adv_start(BLE_HS_OWN_ADDR_PUBLIC, NULL, BLE_HS_FOREVER, &adv_params, NULL, NULL); } void ble_host_task(void *param) { nimble_port_run(); nimble_port_freertos_deinit(); } void app_main(void) { // 1. Initialize NVS (Required for BLE) esp_err_t ret = nvs_flash_init(); if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND) { nvs_flash_erase(); nvs_flash_init(); } // 2. Initialize USB HID ESP_ERROR_CHECK(tinyusb_driver_install(&tusb_cfg)); // 3. Initialize BLE nimble_port_init(); ble_svc_gap_device_name_set(""Power button Penta""); ble_svc_gap_init(); ble_svc_gatt_init(); ble_gatts_count_cfg(gatt_svcs); ble_gatts_add_svcs(gatt_svcs); nimble_port_freertos_init(ble_host_task); ble_app_advertise(); // 4. Power Management (Light Sleep) esp_pm_config_esp32c3_t pm_config = { .max_freq_mhz = 160, .min_freq_mhz = 10, .light_sleep_enable = true }; ESP_ERROR_CHECK(esp_pm_configure(&pm_config)); ESP_LOGI(TAG, ""Penta-GPU Wake Controller Started.""); } ``` Vibe coding? Claude responded with more than 300 lines of code for 2 simple prompts! ## Python script to wake from the Raspberry Pi 4 ```py import asyncio from bleak import BleakClient address = ""XX:XX:XX:XX:XX:XX"" # Replace with ESP32-C3 MAC CHAR_UUID = ""0000ff01-0000-1000-8000-00805f9b34fb"" async def main(): async with BleakClient(address) as client: await client.write_gatt_char(CHAR_UUID, b'\x01') print(""Wake signal sent to Penta server."") asyncio.run(main()) ```"
https://github.com/kreier/T100/blob/master/README.md,"# T100 Arduino robot car with bluetooth control [![GitHub release](https://img.shields.io/github/release/kreier/T100.svg)](https://GitHub.com/kreier/T100/releases/) [![MIT license](https://img.shields.io/github/license/kreier/T100?color=brightgreen)](https://kreier.mit-license.org/) [![Build Status](https://github.com/kreier/T100/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/T100/actions/workflows/pages/pages-build-deployment) This is our first working sample of a remotely controlled robot at the American International School Vietnam. It has been build in September 2018. That's how it looks: ![Robot](docs/panorama.jpg) The software for the Arduino is [T100.ino](T100.ino). Library and Android software are described further down. ## Materials All materials were ordered at [CแปฌA HรNG IC ฤรY RแปI](https://icdayroi.com/). This is the list: 1. [Arduino UNO R3 DIP](https://icdayroi.com/arduino-uno-r3-dip) 110.000โซ 2. [Khung Xe Robot](https://icdayroi.com/khung-xe-robot) 68.000โซ 3. [Shield L293D motor arduino](https://icdayroi.com/shield-l293d-motor-arduino) 34.000โซ 4. [Module thu phรกt bluetooth HC-05](https://icdayroi.com/module-thu-phat-bluetooth-hc-05) 80.000โซ 5. Four 10 cm cable 0.25 mmยฒ to connect the motors to the shield 6. Three female-male jumper wire to connect the bluetooth module to the Arduino (+3.3V, GND, RX) 7. So in general: some [jumper wires](https://icdayroi.com/bo-day-cam-test-board-65-soi) 19.000โซ 8. Maybe [a breadboard](https://icdayroi.com/testboard-mini-syb-170) to connect 5.000โซ ## Building steps * Assemble the robot * Connect the motors to M1 and M4 on the L293D shield * Add the AFMotor.h motor library (library/AFMotor.zip) in the Arduino IDE * Upload the program [T100.ino](T100.ino) to your Arduino Uno * Install the software [BlueDuino](https://play.google.com/store/apps/details?id=com.app.aktham.blueduino&hl=en&gl=US) or [Arduino Bluetooth Controller](https://play.google.com/store/apps/details?id=com.appsvalley.bluetooth.arduinocontroller) to your Android phone (old [link from 2018](https://play.google.com/store/apps/details?id=com.satech.arduinocontroller) no longer works in 2024) * Connect to the bluetooth module of the robot * Configure the keys of the remote the following: - ""U"" for up - ""D"" for down - ""L"" for left - ""R"" for right Your result should work: ![Window view](docs/window-view.jpg) ## Limitations The bluetooth module HC-05 (as well as HC-06) are only Bluetooth 2.0 and don't work with iOS, since iOS requires Bluetooth 4.0 Low Energy (BLE). We created the T-110 with the AR-06 BLE (Bluetooth Low Energy - Bluetooth 4.0) module. This project is [described here as T110](../../../T110). ## Video about build in 30 seconds I uploaded [a timelapse video](https://youtu.be/CzpAYpl62GI) about the creation of this robot in 30 seconds. It took 2 hours. [![30 seconds](docs/30seconds.jpg)](https://youtu.be/CzpAYpl62GI) ## Code from 2018 For the most recent version look at [T100.ino](https://github.com/kreier/T100/blob/master/T100.ino). ```cpp #include // download from subdirectory 'library' here and install zip file #include #define LED_PIN 13 AF_DCMotor motor1(1, MOTOR12_64KHZ); // create motor #1, 64KHz pwm AF_DCMotor motor4(4, MOTOR12_64KHZ); // create motor #2, 64KHz pwm SoftwareSerial BTSerial(A0, 3); // RX | TX - pin 2 creates errors on my motor shield, analog pin is fine ... char BTinput = '0'; byte speed = 200; void setup() { motor1.setSpeed(100); motor4.setSpeed(100); // set the speed to 200/255 BTSerial.begin(9600); // HC-10 default speed Serial.begin(57600); // just to check while programming } void loop() { if (BTSerial.available()) { BTinput = BTSerial.read(); if (BTinput == 'A')// up { motor1.run(FORWARD); motor4.run(FORWARD); } if (BTinput == 'C')// down { motor1.run(BACKWARD); motor4.run(BACKWARD); } if (BTinput == 'D')// left { motor1.run(FORWARD); motor4.run(BACKWARD); } if (BTinput == 'B')// right { motor1.run(BACKWARD); motor4.run(FORWARD); } if (BTinput == 'G') // that's the ""X"" key { motor1.run(RELEASE); // stopped motor4.run(RELEASE); } if (BTinput == 'E')// faster - plus 10 - triangle { speed = speed + 10; } if (BTinput == 'H')// slower - minus 10 - square { speed = speed - 10; } if (BTinput == 'F')// maximum speed - circle { speed = 255; } if( speed > 255 ) speed = 255; motor1.setSpeed(speed); motor4.setSpeed(speed); Serial.print(""recieved: ""); Serial.print( BTinput ); Serial.print("" speed: ""); Serial.println( speed ); } } ``` ## Further details Details, instructions and pictures can be found in the [Wiki](https://github.com/kreier/T100/wiki). ## Reactivation 2024 With some minor changes I made it work again in 2024 - mainly the bluetooth connection part and used app was a challenge. See the new [Release notes](https://github.com/kreier/T100/releases/tag/v0.2.2401) for more details. That's how it looks: ![T100 in 2024](docs/T100_2024.jpeg) ## BLE with a simple AT-09 CC2541? Or ESP32C3? Jeffrey started a new project with a remotely contolled car with 2 motors and a steering servo. Brain is a self-developed mainboard from JLCPCB with an ESP32C3 brain and two L9110s motor drivers, LiPo charging circuit etc. Programmed in C from Arduino IDE or NeoVim and bash script with arduino-cli. Two years ago I worked with the bluetooth modules [AT-09 CC2541](https://www.thegioiic.com/at-09-cc2541-mach-thu-phat-bluetooth-4-0) (like [a clone of a clone from 2017](https://blog.yavilevich.com/2017/03/mlt-bt05-ble-module-a-clone-of-a-clone/) that bothered me back in October 2018 until I moved to [T110](https://github.com/kreier/T110) in early 2019 and finally to the ESP32 with the [T200](https://github.com/kreier/T200) running in April 2019. DFRobot BLE controller is no longer available. And [CC2541 modules](https://www.thegioiic.com/hm-10s-cc2541-mach-thu-phat-bluetooth-4-0-ra-chan-giao-tiep-uart) cost as much as a [full ESP32 NodeMCU](https://www.thegioiic.com/esp32-nodemcu-luanode32-module-thu-phat-wifi-30-chan)! Strange times. [Esp32-c3 SuperMini](https://shopee.vn/ESP32-C3-ESP32-S3-Ban-Ph%C3%A1t-Tri%E1%BB%83n-ESP32-C3-SuperMini-WiFi-Bluetooth-ESP32C3-B%E1%BA%A3ng-M%E1%BB%9F-R%E1%BB%99ng%E2%9C%A8CircuitVina-Mall%E2%9C%A8-i.1724990669.50505714776) just 50,461 VND."
https://github.com/kreier/ar65view-svn/blob/main/README.md,"# AR65view ![GitHub Release](https://img.shields.io/github/v/release/kreier/ar65view-svn) ![GitHub License](https://img.shields.io/github/license/kreier/ar65view-svn?style=flat) [![pages-build-deployment](https://github.com/kreier/ar65view-svn/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/ar65view-svn/actions/workflows/pages/pages-build-deployment) The Java-Program ar65view.jar is intended to analyze and manipulate the photo emission data measured by the ARPES experiments AR65 and WESPHOA. Both are part of the work group EES by Prof. Manzke at the Department of Physics, Humboldt University to Berlin, Germany. The program is written in Java 1.5 and runs therefore under Windows as well as Linux and Mac OS. ## Features - Opens the *.1 files of EAC Software for Omicron AR65 files. - Opens the EAC_STEP files with right energy from the same type of files (stepper motor program version). - Opens the *.VIR files of the WESPHOA spectrometer. - Detect and erase spikes from the spectra. - Smoothing of the spectra, using the Savizky-Golay algorythm. - Remove the 'Shirley background' from inelastic scattered electrons. - Normalizing the peak height to a standard of 10000. - Export of modified spectra data to clipboard. ## Known Bugs If a certain file is selected in the JList, the selection of a different directory leads to an error message. (The 'removeAktivation();' in bin.SpectraData( ) doesn't work ). FIX: Just restart the program. ## Release notes ### 0.2.11.02 (February 2011) - Java webstart with JNLP added an new compiled, [sourcecode available](https://sourceforge.net/p/ar65view/code/HEAD/tree/) with SVN on [sourceforge](http://ar65view.sourceforge.net) ### 0.2.11.01 (February 2011) - 'Shirley background' can easily be removed (without negative data) - Look and Feel finally works. - Different language versions now solved by PropertyResourceBundle ### 0.1.08.04 (April 2008) - Support of *.VIR files of the WESPHOA spectrometer. ### 0.1.07.12 (December 2007) - Support of EAC_STEP files with right energy from the same type of files (stepper motor program version) - Energy export to clipboard and Normalize to 10000 implemented. ### 0.1.07.10 (October 2007) - First successful Java Version, developed in Moscow. - Support of *.1 files of EAC Software for Omicron AR65 files."
https://github.com/kreier/ar65view/blob/main/README.md,"# AR65view [![GitHub release](https://img.shields.io/github/release/kreier/ar65view.svg)](https://GitHub.com/kreier/ar65view/releases/) [![MIT license](https://img.shields.io/github/license/kreier/ar65view)](https://kreier.mit-license.org/) [![pages-build-deployment](https://github.com/kreier/ar65view/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/ar65view/actions/workflows/pages/pages-build-deployment) The Java-Program ar65view.jar is intended to analyze and manipulate the photo emission data measured by the ARPES experiments AR65 and WESPHOA. Both are part of the work group EES by Prof. Manzke at the Department of Physics, Humboldt University to Berlin, Germany. The program is written in Java 1.5 and runs therefore under Windows as well as Linux and Mac OS. ## Features - Opens the *.1 files of EAC Software for Omicron AR65 files. - Opens the EAC_STEP files with right energy from the same type of files (stepper motor program version). - Opens the *.VIR files of the WESPHOA spectrometer. - Detect and erase spikes from the spectra. - Smoothing of the spectra, using the Savizky-Golay algorythm. - Remove the 'Shirley background' from inelastic scattered electrons. - Normalizing the peak height to a standard of 10000. - Export of modified spectra data to clipboard. ## Known Bugs If a certain file is selected in the JList, the selection of a different directory leads to an error message. (The 'removeAktivation();' in bin.SpectraData( ) doesn't work ). FIX: Just restart the program. ## Release notes ### 0.2.11.02 (February 2011) - Java webstart with JNLP added an new compiled, [sourcecode available](https://sourceforge.net/p/ar65view/code/HEAD/tree/) with SVN on [sourceforge](http://ar65view.sourceforge.net) ### 0.2.11.01 (February 2011) - 'Shirley background' can easily be removed (without negative data) - Look and Feel finally works. - Different language versions now solved by PropertyResourceBundle ### 0.1.08.04 (April 2008) - Support of *.VIR files of the WESPHOA spectrometer. ### 0.1.07.12 (December 2007) - Support of EAC_STEP files with right energy from the same type of files (stepper motor program version) - Energy export to clipboard and Normalize to 10000 implemented. ### 0.1.07.10 (October 2007) - First successful Java Version, developed in Moscow. - Support of *.1 files of EAC Software for Omicron AR65 files."
https://github.com/kreier/benchmark/blob/main/README.md,"# Benchmark collection ![GitHub Release](https://img.shields.io/github/v/release/kreier/benchmark) ![GitHub commit activity](https://img.shields.io/github/commit-activity/y/kreier/benchmark) ![GitHub License](https://img.shields.io/github/license/kreier/benchmark) There are countless [benchmarks](https://en.wikipedia.org/wiki/Benchmark_(computing)) out there. This here is just an overview of benchmarks and their results I used over the years, starting **1992**. - [Whetstone](whetstone) - 1972 - [Linpack](LinpackDP) DP, double precision or fp64 - 1979 - [Dhrystone](dhrystone) - 1984 - [nbench](nbench) - 1996 - [Memtest86+](memtest) - 1986 - [CoreMark](CoreMark) - 2009 - [GPU](gpu) with [gpu/OpenCL](gpu/opencl) and [gpu/fluidX3D](gpu/fluidX3D) by [ProjectPhysX](https://github.com/ProjectPhysX) - [GeekBench](geekbench) - [3Dmark](3Dmark) - [NVMe](nvm) with CrystalDiskMark and hdtune - 2007 - [Webbrowser ](browserbench) - 2010 Some benchmarks were created back in 1972. I measured the speed of a Lattice C compiler against Omicron Basic on my [Atari ST](https://en.wikipedia.org/wiki/Atari_ST) in 1992. The data collection presented here started in 2007 with Memtest86+ and the website [http://saiht.de/computer/benchmark.html](http://saiht.de/legacy/computer/benchmark.html) . ## [Whetstone](whetstone) - 1972 This [synthetic benchmark from 1972](https://en.wikipedia.org/wiki/Whetstone_(benchmark)) is one of the oldest ones to estimate the [FLOPS - floating point operations](https://en.wikipedia.org/wiki/FLOPS) a CPU can perform per second. Well described in an [article of arstechnica](https://arstechnica.com/information-technology/2013/05/native-level-performance-on-the-web-a-brief-examination-of-asm-js/2/) from 2013. And it is neither related to wet nor a [whetstone](https://en.wikipedia.org/wiki/Sharpening_stone), but the town of [Whetstone](https://en.wikipedia.org/wiki/Whetstone,_Leicestershire) in England. ## [Linpack](LinpackDP) DP - FLOPS since 1979 This is older than Linux and not related, **Lin** is short for linear Algebra, today heavily used in parallel computing with BLAS - Basic Linear Algebra Subprograms. This benchmark from 1979 is well described at [Wikipedia](https://en.wikipedia.org/wiki/LINPACK_benchmarks). It is still usefull today because it scales with IPC (instructions per cycle), frequency and most importantly **number of cores**. It is therefore used since 1993 to determine the speed of supercomputers with a single value to put it in a list for comparison as the [TOP500](https://en.wikipedia.org/wiki/TOP500). It is measured in FLOPS in DP (double precision, 64bit). For LLMs we don't need that much precision, but can compare it partly in modern GPUs and GPGPUs, for example with OpenCL. More further down in the GPU section. ![GFLOPS over time](docs/GFLOPS_time.svg) This graph shows my reality, starting **1992**. The fastest I could my hands on was a 80486 DX with only 2.63 MegaFLOPs in SP single precision, fp32. And my own Atari ST 520 STFM did not even support floating point natively, only integer with 32 bit and some 1 MIPS out of 8 MHz. The baseline of 1 GFLOPS is more than 1000x faster - floating point and 64 bit! The Athlon 64 with 1.8 GHz I got 14 years later in **2006** was very close to this magical limit. But for me the energy efficiency for long battery life in a laptop was *more important*. More power for me was only needed for ML (machine learning), starting another [12 years later](https://kreier.github.io/ml/) in **2018**. The origin of this graph can be seen in this [Google Sheet](https://docs.google.com/spreadsheets/d/17QBJVa8wzo4B1aygXrlk0FWpG4UVwWn3Zo5LsfNnlJM/edit?usp=sharing) (some minor color corrections and edits). ## [Dhrystone](dhrystone) - 1984 If whet (wet) is for floating point operations, then dhry (dry) is for integer performance. This led to the [Dhrystone benchmark](https://en.wikipedia.org/wiki/Dhrystone) in 1984. Gave it a try as well. ## [NBench](nbench) - 1996 [This benchmark (Wikipedia)](https://en.wikipedia.org/wiki/NBench) form the mid 1990s runs on a variety of hardware and has been maintained [until 2012](http://www.math.utah.edu/~mayer/linux/bmark.html) by Uwe F. Mayer. For modern computers it is rather lightwight and can be compiled on a simple linux machine with gcc in merely seconds, then run for some minutes. I collect data for this benchmark since 2006. ## [Memtest 86+](memtest86) - 1986 The data gives some inside to the architechture of the CPU and the speed of the connected memory. ## [CoreMark](CoreMark) - 2009 for embedded systems Intended for embedded systems by [EEMBC](https://github.com/eembc/coremark) in 2009 for embedded system it is too large for an Arduino Uno, but runs from an Arduino Mega 2560 onwards to multithreaded Octacore Xeon processor. The results show that it scales mostly with frequency and a little with improved IPC. ![Results 2020](mix/coremark2024.png) The results vary from some 7 points for the Arduino Mega 2560 (the Leonardo and Uno have not enough RAM) to 39082 for an i7-13700T or 390614 in a 24-thread execution. That's 5580x or 55802x faster, almost 5 magnitudes! That's hard to display with linear bar graphs. The range of frequencies is vast as well from 16 MHz in the Arduino to 4600 MHz in a Quadcore i7, another 280x. Putting these two values (CoreMark and Frequency) into relationship narrows the differences: ![Results 2020](mix/coremark-mhz.png) It is still comparing an old 8bit CPUs with a modern 32bit ARM and 64bit x86 CPUs, with long pipelines, many registers and large caches. The difference in simple IPC is seen. ## [embench](embench) - 2019 for RISC-V comparison When [comparing the power](https://content.riscv.org/wp-content/uploads/2019/06/9.25-Embench-RISC-V-Workshop-Patterson-v3.pdf) of the new [RISC-V](https://en.wikipedia.org/wiki/RISC-V) ISA some people used drystone and coremark on May 12th, 2018. Not everybody was happy. While 4.9 CoreMarks/MHz and 2.5 DMIPS/Mhz sound interesting, there are shortcomings. To provide a proper tool for comparison they developed this suite from 2019 on. Version 0.5 was released in June 2020 at the Embedded World Conference in Nรผrnberg, Germany. ## [3Dmark](3Dmark) - since 1999 for 3D graphics cards Testing the speed of a 3D graphics card is inherent to its purpose of presenting a smooth image for the user. The benchmark from 1999 still runs on modern hardware. I longed for years to eventually have the hardware just to see the benchmark without stutter. Instead of investing in expensive hardware I relied on Moore's law and waited. Endurance payed off! ## [GeekBench](geekbench) 2007, 2019 (5.0) Some collected values from version 2 to 5 and compared in a table. ## [Crystaldisk and hdtune for non volatile memory](nvm) - 2007 Evolved speed of non volatile memory NVM over the years. Compare my Samsung R20 from 2008 with mechanical harddrive to my Lenovo Yoga 370 from 2017 with NVMe: ## [Webbrowser benchmarks](browserbench) - 2010+ The benchmarks drove the innovation in browser development significantly, but became obsolete quite fast as well. Notable examples are Browermark 2.0, Basemark Web 3.0, peacekeeper, octane, sunspider, kraken, Jetstream and Speedometer. ## [GPU](gpu) performance With image classification using GPUs in AlexNet 2012 people saw the potential of GPUs for machine learning. And in 2022 the whole world payed attention with ChatGPT. The performance today is comparable with Supercomputers of the late 90s of the last century: ![GFLOPS logarithmic](gpu/GFLOPS_logarithm.png) A limiting factor for these LLMs is often the memory speed, not just processing power in GFLOPS. Here is how some of them compare to other ways of information transfer like Ethernet, DDR3 and USB4. ![Comparison speed linear](gpu/comparison_speed_linear.png) The speed differences are so vast I had to include a logarithmic graph. This visualizes the magnitudes of differences between the solutions. ![Comparison speed logarithmic](gpu/comparison_speed_logarithmic.png) ## SuperPi 1M Calcualting Pi to 1 million digits does not take too long nowadayes: ## Prime numbers in basic, python and CPU One of my first benchmarks, written 1992 in Omicron Basic on the Atari ST 520 STFM and then compared to an edition in Lattice C. Surprisingly the Basic variant was faster. With text output in Mu it took the ESP32-S2 38.9 seconds. Commenting the print command in line 17 reduced the time to 13.3 seconds. I used it for some microcomputers as well: | Frequency | ESP8266 | ESP32 | Raspberry Pi 1 | Raspberry Pi 4 | |:---------:|:--------:|:--------:|:--------------:|:--------------:| | 40 MHz | - | 44427 ms | | | | 80 MHz | 32807 ms | 23323 ms | | | | 160 MHz | 16113 ms | 11375 ms | | | | 240 MHz | - | 7783 ms | | | ## [Toy Benchmark Programs](toy-benchmark-programs) Ideas are taken from: - 2001 [start - in waybackmachine](https://web.archive.org/web/20010124090400/http://www.bagley.org/~doug/shootout/) - 2002, 2004, 2008, 2018, 2021, 2025 [Sometimes people just make up stuff](https://benchmarksgame-team.pages.debian.net/benchmarksgame/sometimes-people-just-make-up-stuff.html) ### [Benchmark game](https://benchmarksgame-team.pages.debian.net/benchmarksgame/) - Which programming language is the fastest? Compiled in 2018 (with history going back to 2002) several benchmarks compare the execution speed of programs in 24 languages. Many are optimized for multicore parallel execution, to make modern processors comparable. Probably disable the efficiency cores might speed up the processes."
https://github.com/kreier/timeline/blob/main/README.md,"# A Timeline of human history [![GitHub release](https://img.shields.io/github/release/kreier/timeline.svg)](https://GitHub.com/kreier/timeline/releases/) ![GitHub commit activity](https://img.shields.io/github/commit-activity/y/kreier/timeline) [![MIT license](https://img.shields.io/github/license/kreier/timeline)](https://kreier.mit-license.org/) [![pages-build-deployment](https://github.com/kreier/timeline/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/timeline/actions/workflows/pages/pages-build-deployment) This [project](https://github.com/kreier/timeline) creates a graph of Human history with python and ~~reportlab~~ fpdf2. Version v3.5 replicates and expands the information of v1.1 from 2009 on one single page. After 15 (18) years of slow development some images make it into the timeline in early 2024 with v4.2. ![timeline 4.6](docs/timeline20240516_4.6.png) Compare this 4000 year timespan of **v5.10 from 2025** with the same time period in **v1.1 from 2009** (below): ![timeline 5.10 first 4000 years](docs/timeline20251007_4k.png) ![timeline 1.1](docs/timeline20230630.png) You see that **many more details** were added. And something is off with the scale - explained later - since the **scale** (millimeter/year) in 2009 was not constant. ### Translations The language specific files have been separated from the program code (together with other information, data and list of colors) since version 3.4. While I put the translated string into an utf-8 encoded `.csv` file, the very process is not that straightforward. It starts with a proper translation (cloud APIs for Azure cloud and Googletranslate are only a start), continues with fontfiles that support this language and glyphs (January 2024 with CJK) and continues with font shaping engines like harfbuzz (May 2024) for complexer writing systems like Persian, Devanagari for Hindi, Khmer and Sinhala, among a few. Currently there are 475 text fields in total in a few languages. The print edition has 5cm extra left and right for the rollers at the end of the scroll. The reference size is 1308x210 mm but it can be scaled to any size at the print shop: | Language | print | names | reviewed | complete | latest | |-------------------------------------------------------------------------|:-----------------------------------------------------------:|:-----:|:--------:|:--------:|:----------:| | [English](https://timeline24.github.io/timeline_en.pdf) | [link](https://timeline24.github.io/timeline_en_print.pdf) | x | x | x | 2025-09-24 | | [Arabic (ุงูุนุฑุจูุฉ)](https://timeline24.github.io/timeline_ar.pdf) | [link](https://timeline24.github.io/timeline_ar_print.pdf) | x | | | 2024-07-25 | | [Armenian (ีีกีตีฅึีฅีถ)](https://timeline24.github.io/timeline_hy.pdf) | [link](https://timeline24.github.io/timeline_hy_print.pdf) | x | | | 2025-09-17 | | [Cebuano (Bisayรข)](https://timeline24.github.io/timeline_ceb.pdf) | [link](https://timeline24.github.io/timeline_ceb_print.pdf) | | | | 2025-09-17 | | [Chinese Cantonese (Simplified) (ๆฎ้่ฏ)](https://timeline24.github.io/timeline_yue.pdf) | [link](https://timeline24.github.io/timeline_yue_print.pdf) | x | | | 2024-06-16 | | [Chinese Mandarin (Simplified) (ๆฎ้่ฏ)](https://timeline24.github.io/timeline_zh.pdf) | [link](https://timeline24.github.io/timeline_zh_print.pdf) | x | | | 2024-06-14 | | [Estonian (eesti keel)](https://timeline24.github.io/timeline_et.pdf) | [link](https://timeline24.github.io/timeline_et_print.pdf) | x | | | 2025-05-03 | | [Finnish (Suomi)](https://timeline24.github.io/timeline_fi.pdf) | [link](https://timeline24.github.io/timeline_fi_print.pdf) | | | | 2024-06-14 | | [French (Franรงais)](https://timeline24.github.io/timeline_fr.pdf) | [link](https://timeline24.github.io/timeline_fr_print.pdf) | x | x | | 2025-09-24 | | [German (Deutsch)](https://timeline24.github.io/timeline_de.pdf) | [link](https://timeline24.github.io/timeline_de_print.pdf) | x | x | x | 2025-09-24 | | [Greek (ฮฮปฮปฮทฮฝฮนฮบฮฌ)](https://timeline24.github.io/timeline_el.pdf) | [link](https://timeline24.github.io/timeline_el_print.pdf) | x | | | 2025-09-17 | | [Hebrew (ืขึดืึฐืจึดืืช)](https://timeline24.github.io/timeline_he.pdf) | [link](https://timeline24.github.io/timeline_he_print.pdf) | | | | 2025-09-17 | | [Hindi (เคนเคฟเคจเฅเคฆเฅ)](https://timeline24.github.io/timeline_hi.pdf) | [link](https://timeline24.github.io/timeline_hi_print.pdf) | | | | 2025-09-17 | | [Igbo (รsแปฅฬsแปฅฬ รgbรฒ)](https://timeline24.github.io/timeline_ig.pdf) | [link](https://timeline24.github.io/timeline_ig_print.pdf) | | | | 2025-02-18 | | [Iloko (Ilocano)](https://timeline24.github.io/timeline_ilo.pdf) | [link](https://timeline24.github.io/timeline_ilo_print.pdf) | x | x | x | 2024-06-07 | | [Italian (Italiano)](https://timeline24.github.io/timeline_it.pdf) | [link](https://timeline24.github.io/timeline_it_print.pdf) | x | x | x | 2024-06-07 | | [Japanese (ๆฅๆฌ่ช)](https://timeline24.github.io/timeline_ja.pdf) | [link](https://timeline24.github.io/timeline_ja_print.pdf) | x | x | | 2024-06-11 | | [Kankana-ey](https://timeline24.github.io/timeline_kne.pdf) | [link](https://timeline24.github.io/timeline_kne_print.pdf) | x | x | x | 2024-06-07 | | [Khmer (แแแแแ)](https://timeline24.github.io/timeline_km.pdf) | [link](https://timeline24.github.io/timeline_km_print.pdf) | x | | | 2024-06-19 | | [Khmer (แแแแแ) with Arabic numerals](https://timeline24.github.io/timeline_kman.pdf) | [link](https://timeline24.github.io/timeline_kman_print.pdf) | x | | | 2024-06-24 | | [Kikongo](https://timeline24.github.io/timeline_kg.pdf) | [link](https://timeline24.github.io/timeline_kg_print.pdf) | x | | | 2025-09-17 | | [Korean (ํ๊ตญ์ธ)](https://timeline24.github.io/timeline_ko.pdf) | [link](https://timeline24.github.io/timeline_ko_print.pdf) | | | | 2024-06-16 | | [Malay (Bahasa Melayu)](https://timeline24.github.io/timeline_ms.pdf) | [link](https://timeline24.github.io/timeline_ms_print.pdf) | x | | | 2025-09-17 | | [Norwegian (Norsk)](https://timeline24.github.io/timeline_no.pdf) | [link](https://timeline24.github.io/timeline_no_print.pdf) | x | | | 2024-06-16 | | [Persian (ูุงุฑุณ)](https://timeline24.github.io/timeline_fa.pdf) | [link](https://timeline24.github.io/timeline_fa_print.pdf) | x | | | 2025-09-17 | | [Portugese (Portuguรชs)](https://timeline24.github.io/timeline_pt.pdf) | [link](https://timeline24.github.io/timeline_pt_print.pdf) | x | | | 2025-09-17 | | [Punjabi (เจชเฉฐเจเจพเจฌเฉ)](https://timeline24.github.io/timeline_pa.pdf) | [link](https://timeline24.github.io/timeline_pa_print.pdf) | | | | 2025-09-17 | | [Russian (ะัััะบะธะน)](https://timeline24.github.io/timeline_ru.pdf) | [link](https://timeline24.github.io/timeline_ru_print.pdf) | x | | | 2024-06-17 | | [Sinhala (เทเทเถเทเถฝ)](https://timeline24.github.io/timeline_si.pdf) | [link](https://timeline24.github.io/timeline_si_print.pdf) | | | | 2024-06-11 | | [Spanish (Espaรฑol)](https://timeline24.github.io/timeline_es.pdf) | [link](https://timeline24.github.io/timeline_es_print.pdf) | x | | | 2025-02-27 | | [Swahili (Kiswahili)](https://timeline24.github.io/timeline_sw.pdf) | [link](https://timeline24.github.io/timeline_sw_print.pdf) | | | | 2025-09-17 | | [Filipino (Tagalog)](https://timeline24.github.io/timeline_tl.pdf) | [link](https://timeline24.github.io/timeline_tl_print.pdf) | x | x | x | 2024-06-07 | | [Thai (เธเธฒเธฉเธฒเนเธเธข)](https://timeline24.github.io/timeline_th.pdf) | [link](https://timeline24.github.io/timeline_th_print.pdf) | | | | 2024-06-14 | | [Ukrainian (ัะบัะฐัะฝััะบะฐ)](https://timeline24.github.io/timeline_uk.pdf) | [link](https://timeline24.github.io/timeline_uk_print.pdf) | x | | | 2025-09-17 | | [Urdu (ุงูุฑุฏูู)](https://timeline24.github.io/timeline_ur.pdf) | [link](https://timeline24.github.io/timeline_ur_print.pdf) | | | | 2025-09-17 | | [Vietnamese (Tiแบฟng Viแปt)](https://timeline24.github.io/timeline_vi.pdf) | [link](https://timeline24.github.io/timeline_vi_print.pdf) | x | | x | 2025-02-20 | Support for languages using the CJK glyphs took some extra work, and I learned a lot about tofu and NO TOfu (noto) and related projects in January 2024. For Khmer, Sinhala and Arabic I finally needed a shape engine like [harfbuzz](https://github.com/harfbuzz/harfbuzz). Since it is not supported in reportlab, I switched to [fpdf2](https://py-pdf.github.io/fpdf2/index.html) with version 4.7 in July 2024. ## Reactivation 2023 After 14 (17) years it was finally time to translate the project to English and share with my friends. In the years since 2009 (2006) I learned a lot about programming languages, vector graphics and possible solutions using pandas, csv files and reportlab (instead of matplotlib). In a first stage I translated the old OpenOffice documents to English. Then I collected data into csv/tsv files for later automated processing and graph generation. This way the translation to another language is ""just"" the change of one import file. So far I translated the first page: ![timeline one 4050 - 1450 BCE](docs/timeline_4050-1450.png) This project started on here on Github on June 10th, 2023. My last day of work. ## Version history - [v0.1](https://github.com/kreier/timeline/releases/tag/v0.1) 2006/08/30 several large HTML files with [linked articles](https://kreier.github.io/timeline/history/2006/zeitleiste1.html) about the persons in this timeline. One version is [30,000 pixels](history/zeit2.html) wide! - [v1.0](https://github.com/kreier/timeline/releases/tag/v1.0) 2009/02/10 An [OpenOffice spreadsheet](https://github.com/kreier/timeline/blob/5ffa9bac5cb4ff3c2cdc362b63df161e0d909c9d/spreadsheet/Zeitleiste_3A4_20090210.ods) with 260, 340 and 218 columns to create the overview with a resolution of 5 or 10 years. See the [resulting pdf](https://github.com/kreier/timeline/blob/5ffa9bac5cb4ff3c2cdc362b63df161e0d909c9d/spreadsheet/Zeitleiste_3A4_20090211.pdf). It contains 63 persons, 8 time periods and 20 events. - [v2.0](https://github.com/kreier/timeline/releases/tag/v2.0) 2015/10/12 A __vector image__ as a LibreOffice odf to cover 6000 years on [one pdf](https://github.com/kreier/timeline/blob/5ffa9bac5cb4ff3c2cdc362b63df161e0d909c9d/spreadsheet/Zeitleiste_wide_20151213.pdf) and no restrictions in the representation of years. It was very cumbersome to edit and by December only the first __24 persons__ were indicated with their lifetime. And 2 time periods and 3 event dates. - [v1.1](https://github.com/kreier/timeline/releases/tag/v1.1) 2023/06/30 __Translation to English.__ For a broader audience and to get feedback on the planned vector version I translated the original OpenOffice Spreadsheet version to English. By June 30th the exported pdf from LibreOffice was finished with the same __63 persons__, 8 time periods and 20 event dates. - [v3.0](https://github.com/kreier/timeline/releases/tag/v3.0) 2023/10/22 __Vector document__ generated with [a python program](https://github.com/kreier/timeline/blob/main/python/6000.py) and reportlab. 24 persons, 44 kings and 9 periods. - [v3.1](https://github.com/kreier/timeline/releases/tag/v3.1) 2023/10/23 __Timebase changed to float__, font size adjusted for nicer overview. Conversion with [a program](https://github.com/kreier/timeline/blob/main/history/convert.py). 68 persons, 11 periods, 6 events. - [v3.2](https://github.com/kreier/timeline/releases/tag/v3.2) 2023/10/24 Text elements and __colors separated__ from key __events__ and __persons__. 96 persons, 17 periods, 6 events. First printout on A0. - [v3.3](https://github.com/kreier/timeline/releases/tag/v3.3) 2023/11/04 __First century__ and 6 ancient people. 110 people, 21 periods, 7 events. - [v3.4](https://github.com/kreier/timeline/releases/tag/v3.4) 2023/11/06 Removal of many hard-coded elements and descriptions from 6000.py to __8 seperate files__. Plus a __colors_normal.csv__ file for the colors and one __dictionary_en.tsv__ for each language with currently 164 entries. First translation to __German__ completed. - [v3.5](https://github.com/kreier/timeline/releases/tag/v3.5) 2023/11/22 First translation to __Vietnamese__ completed, minor refinements. - [v3.6](https://github.com/kreier/timeline/releases/tag/v3.6) 2023/12/28 Adjustments in the location of information to make it easier to compare. Improved Vietnamese translation. - [v4.0](https://github.com/kreier/timeline/releases/tag/v4.0) 2024/01/30 Languages extended to 10 languages with initial support for CJK (ไธญๅฝไบบ ๆฅๆฌ่ช ํ๊ตญ์ด) rendering. Translation support started for French, Iloko and Japanese. - [v4.1](https://github.com/kreier/timeline/releases/tag/v4.1) 2024/02/27 Included Sinhala (เทเทเถเทเถฝ) and refined __Iloko__ and __Japanese__ (ๆฅๆฌ่ช). - [v4.2](https://github.com/kreier/timeline/releases/tag/v4.2) 2024/03/09 Included the family of Terah and the image from __Daniel 2__ with the world powers from Daniel 7. And 6 small images as illustration. - [v4.3](https://github.com/kreier/timeline/releases/tag/v4.3) 2024/03/16 Convert dictionary files to __.csv__ format to be easier readable in a [Jupyter Notebook](db/timeline.ipynb). You can create the latest PDF in your language in [Google Colab](https://colab.research.google.com/drive/1G0z6jKIs_B_Md_y6Wen108Keo5WazalZ?usp=sharing) with just a browser. - [v4.4](https://github.com/kreier/timeline/releases/tag/v4.4) 2024/03/24 Include inventions and insights that enable modern society from the last centuries with pictures. Add some of the __Chinese dynasties__ to the oldest known historic date of 841 BC (Sima Qian) and beyond. - [v4.5](https://github.com/kreier/timeline/releases/tag/v4.5) 2024/04/13 Include the great tribulation in the time of the end, and a graph of the world population for the last 2000 years. It aligns with advancements in science, culture and society. - [v4.6](https://github.com/kreier/timeline/releases/tag/v4.6) 2024/05/31 Include more empires in Umayyad, Teotihuacan, Mongol, Inca and more. Added historic figures like Hammurabi, al-Khwarizimi, Genghis Khan and Dionysius Exiguus plus a few more smaller images - [v4.7](https://github.com/kreier/timeline/releases/tag/v4.7) 2024/07/25 Finally the rendering of RTL languages like Hebrew and Arabic are supported. The proper rendering of Arabic glyphs require a special font shape engine like [Harfbuzz](https://en.wikipedia.org/wiki/HarfBuzz) (also on [Github](https://github.com/harfbuzz/harfbuzz)) and my previous PDF generator [reportlab](https://www.reportlab.com/) has this not yet included. The pdf is now generated with [fpdf2](https://py-pdf.github.io/fpdf2/index.html). This project included text shaping [with version 2.7.5](https://py-pdf.github.io/fpdf2/TextShaping.html) in August 2023. This solved my problems with Khmer and Sinhala as well. - [v4.9](https://github.com/kreier/timeline/releases/tag/v4.9) 2024/09/15 Abraham's later wife Keturah is included into the image and the ancestry of the Midianites. Now the genealogy includes 6 nations with their name-giving father and illustrate the family relations. The extra space needed for Keturah and her 6 sons was provides by reorganizing the Daniel 2 image and the world population of the last 2000 years. And finally the life expectancy in Moses times was included with a graph to represent the health condition of people in his time. - [5.1](https://github.com/kreier/timeline/releases/tag/v5.1) The time period of 430 years was included as a graph. And some exaples from the Maya calender were included. - [5.2](https://github.com/kreier/timeline/releases/tag/v5.2) Time around last days reorganized, faded times for Daniels prophecies. - [5.3](https://github.com/kreier/timeline/releases/tag/v5.3) New Daniel 2 images, reorganize Ghenghis Khan and the last days - [5.9](https://github.com/kreier/timeline/releases/tag/v5.9) Extended family tree back to Noah, relate 20 nations in footnotes, add 4 Vietnamese Dynasties, Edo and Meiji period in Japan, Wulfila bible, first designed alphabet with a known creator, fresh NIRCam image of Pismis 24 by NASA with Webb telescope from September 11th, 2025. ### Scale challenges To compensate for limited printing area I created a border of 1cm around each page. The effective drawing area on A4 landscape in each tile is 277 millimeter. This resulted in _different time scales_ for each page with v1.0, since the covered timespan is not equal for each page. But this was one of the fundamental ideas of this project, to represent a *larger amount of time* with a *bigger amount of space* or length. Here are the values for comparison: | page | begin | end | timespan | width/mm | years/mm | resolution | columns | created | |------------------|-------|-------|----------|----------|----------|------------|---------|------------| | table 1 | -4050 | -1450 | 2600 | 277 | 9.39 | 10 | 260 | 2009-02-10 | | table 2 | -1550 | 150 | 1700 | 277 | 6.14 | 5 | 340 | 2009-02-10 | | table 3 | -130 | 2050 | 2180 | 277 | 7.87 | 10 | 218 | 2009-02-10 | | drawing odg | -4000 | 2000 | 6000 | 1250 | 4.8 | โ | โ | 2015-12-13 | | reportlab python | -4075 | 2075 | 6150 | 1188 | 5.18 | โ | โ | 2023-10-17 | | [Adams Chart](https://en.wikipedia.org/wiki/Adams_Synchronological_Chart_or_Map_of_History) | -4004 | 1900 | 5904 | 6900 | 0.86 | โ | โ | 1871-01-01 | See [scale.csv](spreadsheet/scale.csv) ### Decision on the dimensions for this project After the experience of 8 months with [reportlab](https://pypi.org/project/reportlab/) I decided in June 2024 to fix some scale parameters with the new rendering engine [fpdf2](https://pypi.org/project/fpdf2/). The original project from 2009 was to fit on three landscape A4 papers, but for v3.0 I decided to have four A4 papers width to be able to see more details in the first century and during the time of the northern and southern kingdom in Israel. That gives a height of 210 mm and 4 x 297 = 1188 mm. With 7mm border top and bottom for the scale and numbering the drawing area is 1188 x 196 mm for 6150 years: 4075 BCE to 2075 CE. Inside we leave 1 mm on top and bottom, so 194 mm are used for 46 rows of 10pt text (1 pt = 1/72 inch = 0.3528 mm). 10 pt is therefore 3.5mm and line height 194/46 = 4.217 mm = 12 pt. Why __46 rows__? For Adam to Joseph the lifespans overlap and create a descending shifted graph for 23 rows. A little space (maybe for Job) and adding Moses requires a minimum 25 rows. More are needed for the kings of Judah and Israel. There are 3 kings for the united kingdom, followed by 21 kings in the northern 10-tribe kingdom (some as short as 7 days like Zimri) and 20 kings in the southern kingdom of Judah. With the project in 2009 this resulted in 3+21+20 = 44 rows. In time I flipped the names for the kings to opposite sites, so I could overlap them with just 4 rows between them, reducing the requirement to just 29 lines, leaving 17 lines below for prophets, other dynasties, philosophers and kingdoms of Daniel's prophecy in chapter 2, 7 and 10. The scale in 2023 had 44.7 rows, but with some adjustment I increased it to 46 and can now directly reference the rows in the data file csv. Reflecting on larger solutions with more space, some are found below (for example the 7 meter long and 68 cm wide chart by Adams), while they contain a lot more information, in the end they ran out of space anyways. You can't include every important detail. And the large size is hard to use, or even to transport. The limitation to four A4 papers makes the scroll small enough to put in a backpack and bring with you. And it's still long enough that usually you use it as a scroll and open the part you're interested in. Many now use the digital version on their tablet or smartphone, which still serves the purpose of visualizing time and events. There is the temptation to include more details in smaller sizes, but many pdf viewers limit the maximum zoom level. And it is inconsistent with the experience of the print version. It's better to be inspired to search for more information in addition to the presented events. ## Create your own pdf file and fix mistakes on the fly - with just a browser in less than 60 seconds With a Jupyter Notebook you can download all required files and install all software in 2 steps in a virtual machine and then create a fresh pdf in the third step. Edit the downloaded files in your browser and repeat step 3 for an updated version: - [Jypyter Notebook in Google Colab with reportlab](https://colab.research.google.com/drive/1G0z6jKIs_B_Md_y6Wen108Keo5WazalZ?usp=sharing) - [Jupyter Notebook in Google Colab with fpdf2](https://colab.research.google.com/drive/1WbLz2Gz775j0bSFPHdQihAkub3wltAof?usp=sharing) ## Inspiration and other solutions The idea of a [timeline (link to Wikipedia)](https://en.wikipedia.org/wiki/Timeline) is neither unique nor new. One example would be Joseph Priestley's [""A New Chart of History""](https://en.wikipedia.org/wiki/A_New_Chart_of_History) published in 1769 (more than 250 years ago): ![A New Chart of History](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/A_New_Chart_of_History_color.jpg/1280px-A_New_Chart_of_History_color.jpg) Even more similar to my project is [Adams Synchronological Chart or Map of History](https://en.wikipedia.org/wiki/Adams_Synchronological_Chart_or_Map_of_History) from 1871 (more than 150 years ago). In wikimedia is [a scan of 40445x4309 pixel](https://commons.wikimedia.org/wiki/File:Adams_Synchronological_Chart,_1881.jpg) of this masterpiece. And there you would find a link to the 700 Megapixel JPEG 2000 scan file. ![Adams Chart](https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Adams_Synchronological_Chart%2C_1881.jpg/1280px-Adams_Synchronological_Chart%2C_1881.jpg) In 2008 I got ""Knaur's Zeittafel der Weltgeschichte - Den letzten 6000 Jahren auf der Spur"" with a total length of 7 meters. I'm far from having all these information included in my edition. Here are links to [two editions](https://www.amazon.de/-/en/Alex-Klubertanz/dp/3828908519/ref=monarch_sidesheet) at [amazon.de](https://www.amazon.de/-/en/dp/3829017057/ref=monarch_sidesheet). Here is [another example from amazon.de](https://www.amazon.de/Super-Jumbo-History-Timeline-Poster/dp/0721712002/ref=monarch_sidesheet), covering the last 5000 years in 1.2 meter like this project here. The map by Schofield & Sims: ![map by Schofield & Sims](https://m.media-amazon.com/images/I/A1QO0k+1wZL._SL1500_.jpg) It looks like Knaur's book is a translated and updated version of [Adams Synchronological Chart or Map of History](https://www.amazon.com/Adams-Synchronological-Chart-Map-History/dp/0890515131) - which is 23' long (7 meter) and 27"" tall (68 cm). The original is from 1871. ![Adams Map of History](https://raw.githubusercontent.com/kreier/timeline/main/docs/amazon_adams_map.jpg) The reformation made [a timeline for the 220 years](https://www.amazon.com/Timeline-of-the-Reformation-Poster/dp/B09DRPQN3V) 1480 - 1700 AD in a similar style. Another design attempt to pack a lot of information in a written horizontal way into a timeline that progresses from left to right is this [Texan Spiral semicircle project](https://www.amazon.com/Bible-Timeline-History-Chart-Chronological/dp/B0BMWW7WWP): ![Bible Timeline History Chart](https://raw.githubusercontent.com/kreier/timeline/main/docs/amazon_bible_history_cart.jpg) Time of 12 Prophets from 850 BCE to 400 BCE ![time of 12 prophets](docs/12prophets.jpg) ## Short history of this project - with just pictures A more detailled story is written in [history](history/). #### 2006 ![2006](history/leiste.png) #### 2009 ![2009](https://raw.githubusercontent.com/kreier/timeline/4.6/docs/zeitleiste2009full.png) #### 2015 ![2015](https://raw.githubusercontent.com/kreier/timeline/main/docs/zeitleiste2015.png) #### 2023 ![2023-1](https://raw.githubusercontent.com/kreier/timeline/main/docs/timeline20231023.png) ![2023-2](https://raw.githubusercontent.com/kreier/timeline/main/docs/timeline20231129.png) #### 2024 ![2024-1](https://raw.githubusercontent.com/kreier/timeline/main/docs/timeline20240309_4.2.png) ![2024-2](https://raw.githubusercontent.com/kreier/timeline/main/docs/timeline20240413_4.5.png) ![2024-3 timeline 4.6](https://raw.githubusercontent.com/kreier/timeline/main/docs/timeline20240516_4.6.png) ![2024-7 timeline 4.7](https://raw.githubusercontent.com/kreier/timeline/main/docs/timeline20240725_4.7.png) #### 2025 ![2025-01](https://raw.githubusercontent.com/kreier/timeline/refs/heads/main/docs/timeline20250101_5.1.png) ![2025-02](https://raw.githubusercontent.com/kreier/timeline/refs/heads/main/docs/timeline20250221_5.2.png) ![2025-05](https://raw.githubusercontent.com/kreier/timeline/refs/heads/main/docs/timeline20250506_5.5.png) ![2025-09](https://raw.githubusercontent.com/kreier/timeline/refs/heads/main/docs/timeline20250925_5.9.png) #### 2026 ![2026-01](https://raw.githubusercontent.com/kreier/timeline/refs/heads/main/docs/timeline20260117_6.01.png)"
https://github.com/timeline24/timeline24.github.io/blob/main/README.md,"# Repository for latest PDF versions of the timeline project [![GitHub release](https://img.shields.io/github/release/timeline24/timeline24.github.io.svg)](https://GitHub.com/timeline24/timeline24.github.io/releases/) [![MIT license](https://img.shields.io/github/license/timeline24/timeline24.github.io)](https://kreier.mit-license.org/) [![pages-build-deployment](https://github.com/timeline24/timeline24.github.io/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/timeline24/timeline24.github.io/actions/workflows/pages/pages-build-deployment) This website contains the latest PDFs for download, linked from the QR codes on the [timelines](https://github.com/kreier/timeline) itself. ![timeline 5.2](https://raw.githubusercontent.com/kreier/timeline/refs/heads/main/docs/timeline20250221_5.2.png) | language | print | version | last updated | |-------------------------------------------------------------------------|:-----------------------------------------------------------:|:-------:|:------------:| | [English](https://timeline24.github.io/timeline_en.pdf) | [link](https://timeline24.github.io/timeline_en_print.pdf) | 6.02 | 2026-02-12 | | [Arabic (ุงูุนุฑุจูุฉ)](https://timeline24.github.io/timeline_ar.pdf) | [link](https://timeline24.github.io/timeline_ar_print.pdf) | 6.02 | 2026-02-12 | | [Armenian (ีีกีตีฅึีฅีถ)](https://timeline24.github.io/timeline_hy.pdf) | [link](https://timeline24.github.io/timeline_hy_print.pdf) | 6.02 | 2026-02-12 | | [Cebuano (Bisayรข)](https://timeline24.github.io/timeline_ceb.pdf) | [link](https://timeline24.github.io/timeline_ceb_print.pdf) | 6.02 | 2026-02-12 | | [Chinese Cantonese (Simplified) [ไธญๆ็ฎไฝ๏ผๅนฟไธ่ฏ)]](https://timeline24.github.io/timeline_yue.pdf) | [link](https://timeline24.github.io/timeline_yue_print.pdf) | 6.02 | 2026-02-12 | | [Chinese Mandarin (Simplified) [ไธญๆ็ฎไฝ๏ผๆฎ้่ฏ)]](https://timeline24.github.io/timeline_zh.pdf) | [link](https://timeline24.github.io/timeline_zh_print.pdf) | 6.02 | 2026-02-12 | | [Dutch (Nederlands)](https://timeline24.github.io/timeline_nl.pdf) | [link](https://timeline24.github.io/timeline_nl_print.pdf) | 6.02 | 2026-02-12 | | [Estonian (eesti keel)](https://timeline24.github.io/timeline_et.pdf) | [link](https://timeline24.github.io/timeline_et_print.pdf) | 6.02 | 2026-02-12 | | [Finnish (Suomi)](https://timeline24.github.io/timeline_fi.pdf) | [link](https://timeline24.github.io/timeline_fi_print.pdf) | 6.02 | 2026-02-12 | | [French (Franรงais)](https://timeline24.github.io/timeline_fr.pdf) | [link](https://timeline24.github.io/timeline_fr_print.pdf) | 6.02 | 2026-02-12 | | [German (Deutsch)](https://timeline24.github.io/timeline_de.pdf) | [link](https://timeline24.github.io/timeline_de_print.pdf) | 6.02 | 2026-02-12 | | [Greek (ฮฮปฮปฮทฮฝฮนฮบฮฌ)](https://timeline24.github.io/timeline_el.pdf) | [link](https://timeline24.github.io/timeline_el_print.pdf) | 6.02 | 2026-02-12 | | [Hebrew (ืขึดืึฐืจึดืืช)](https://timeline24.github.io/timeline_he.pdf) | [link](https://timeline24.github.io/timeline_he_print.pdf) | 6.02 | 2026-02-12 | | [Hindi (เคนเคฟเคจเฅเคฆเฅ)](https://timeline24.github.io/timeline_hi.pdf) | [link](https://timeline24.github.io/timeline_hi_print.pdf) | 6.02 | 2026-02-12 | | [Igbo (รsแปฅฬsแปฅฬ รgbรฒ)](https://timeline24.github.io/timeline_ig.pdf) | [link](https://timeline24.github.io/timeline_ig_print.pdf) | 6.02 | 2026-02-12 | | [Iloko (Illocano)](https://timeline24.github.io/timeline_ilo.pdf) | [link](https://timeline24.github.io/timeline_ilo_print.pdf) | 6.02 | 2026-02-12 | | [Italian (Italiano)](https://timeline24.github.io/timeline_it.pdf) | [link](https://timeline24.github.io/timeline_it_print.pdf) | 6.02 | 2026-02-12 | | [Japanese (ๆฅๆฌ่ช)](https://timeline24.github.io/timeline_ja.pdf) | [link](https://timeline24.github.io/timeline_ja_print.pdf) | 6.02 | 2026-02-12 | | [Kankana-ey](https://timeline24.github.io/timeline_kne.pdf) | [link](https://timeline24.github.io/timeline_kne_print.pdf) | 6.02 | 2026-02-12 | | [Khmer (แแแแแ)](https://timeline24.github.io/timeline_km.pdf) | [link](https://timeline24.github.io/timeline_km_print.pdf) | 6.02 | 2026-02-12 | | [Khmer (แแแแแ) with arabic numerals](https://timeline24.github.io/timeline_kman.pdf) | [link](https://timeline24.github.io/timeline_kman_print.pdf) | 6.02 | 2026-02-12 | | [Kikongo](https://timeline24.github.io/timeline_kg.pdf) | [link](https://timeline24.github.io/timeline_kg_print.pdf) | 6.02 | 2026-02-12 | | [Korean (ํ๊ตญ์ธ)](https://timeline24.github.io/timeline_ko.pdf) | [link](https://timeline24.github.io/timeline_ko_print.pdf) | 6.02 | 2026-02-12 | | [Malay (Bahasa Melayu)](https://timeline24.github.io/timeline_ms.pdf) | [link](https://timeline24.github.io/timeline_ms_print.pdf) | 6.02 | 2026-02-12 | | [Norwegian (Norsk)](https://timeline24.github.io/timeline_no.pdf) | [link](https://timeline24.github.io/timeline_no_print.pdf) | 6.02 | 2026-02-12 | | [Persian or Farsi (ูุงุฑุณ)](https://timeline24.github.io/timeline_fa.pdf) | [link](https://timeline24.github.io/timeline_fa_print.pdf) | 6.02 | 2026-02-12 | | [Portugese (Portuguรชs)](https://timeline24.github.io/timeline_pt.pdf) | [link](https://timeline24.github.io/timeline_pt_print.pdf) | 6.02 | 2026-02-12 | | [Punjabi (เจชเฉฐเจเจพเจฌเฉ)](https://timeline24.github.io/timeline_pa.pdf) | [link](https://timeline24.github.io/timeline_pa_print.pdf) | 6.02 | 2026-02-12 | | [Russian (ะัััะบะธะน)](https://timeline24.github.io/timeline_ru.pdf) | [link](https://timeline24.github.io/timeline_ru_print.pdf) | 6.02 | 2026-02-12 | | [Sinhala (เทเทเถเทเถฝ)](https://timeline24.github.io/timeline_si.pdf) | [link](https://timeline24.github.io/timeline_si_print.pdf) | 6.02 | 2026-02-12 | | [Spanish (Espaรฑol)](https://timeline24.github.io/timeline_es.pdf) | [link](https://timeline24.github.io/timeline_es_print.pdf) | 6.02 | 2026-02-12 | | [Swahili (Kiswahili)](https://timeline24.github.io/timeline_sw.pdf) | [link](https://timeline24.github.io/timeline_sw_print.pdf) | 6.02 | 2026-02-12 | | [Tagalog (Filipino)](https://timeline24.github.io/timeline_tl.pdf) | [link](https://timeline24.github.io/timeline_tl_print.pdf) | 6.02 | 2026-02-12 | | [Thai (เธเธฒเธฉเธฒเนเธเธข)](https://timeline24.github.io/timeline_th.pdf) | [link](https://timeline24.github.io/timeline_th_print.pdf) | 6.02 | 2026-02-12 | | [Ukrainian (ัะบัะฐัะฝััะบะฐ)](https://timeline24.github.io/timeline_uk.pdf) | [link](https://timeline24.github.io/timeline_uk_print.pdf) | 6.02 | 2026-02-12 | | [Urdu (ุงูุฑุฏูู)](https://timeline24.github.io/timeline_ur.pdf) | [link](https://timeline24.github.io/timeline_ur_print.pdf) | 6.02 | 2026-02-12 | | [Vietnamese (Tiแบฟng Viแปt)](https://timeline24.github.io/timeline_vi.pdf) | [link](https://timeline24.github.io/timeline_vi_print.pdf) | 6.02 | 2026-02-12 | The digital edition is 1208x210mm in size or about four A4 papers in landscape. The print version has additional 5cm left and right for the print shop. It's easier to connect the end roll covers to the timeline. The standard dimensions for the print version are 1308x210 mm. But it can be scaled to any size with a ratio 6.228:1, since almost the entire content is vector graphics. Four digital editions on A0 will be slightly smaller with 1188x206.5 and have 7mm extra border above/below. ## Project repository The work on the timeline is done and documented at the repository [https://github.com/kreier/timeline](https://github.com/kreier/timeline). The idea for this project started with spreadsheets in 2009. I moved to vector graphics in 2015. Then from 2023 on it was finally generated with a python program and the __reportlab package__ to make the creation, translation and editing much faster and easier. We stopped using reportlab with version 4.6 in summer 2024 and moved to [fpdf2](https://py-pdf.github.io/fpdf2/index.html) with 4.7 to support complicated glyph composition for languages like Khmer, Sinhala and Arabic that requires a specific shape engine like [harfbuzz](https://github.com/harfbuzz/harfbuzz). ## Improvement - report mistakes If you spot a mistake, please add an issue at [https://github.com/kreier/timeline/issues](https://github.com/kreier/timeline/issues) ## Create your own PDF in a browser To greate your own version just using a browser you can try out this [Jupyter Notebook at Google Colab](https://colab.research.google.com/drive/1G0z6jKIs_B_Md_y6Wen108Keo5WazalZ?usp=sharing). Simply press __Runtime - Run all__. It requires less than 60 seconds. Since June 2024 there is also [a version 4.7 with fpdf2](https://colab.research.google.com/drive/1WbLz2Gz775j0bSFPHdQihAkub3wltAof?usp=sharing) to support RTL scripts, Khmer and Sinhala. - Jupyter notebook [in Google Colab with reportlab](https://colab.research.google.com/drive/1G0z6jKIs_B_Md_y6Wen108Keo5WazalZ?usp=sharing) - Jupyter notebook [in Google Colab with fpdf2](https://colab.research.google.com/drive/1WbLz2Gz775j0bSFPHdQihAkub3wltAof?usp=sharing) ## Edit your own edition in a browser To edit the files in the browser its best to have your own Github account. Fork the [timeline](https://github.com/kreier/timeline) repository and create a Codespace within the fork. Install the needed 3 libraries (reportlab, svglib and googletranslate) and the CSV extention to Visual Studio Code. You're good to go! Change everything you want - just using the browser. ## Translation Initially the timelines above are automatically translated with Google translate. Later each of the more than 560 strings has to be verified, and that takes time. But we made some progress: ![Progress translation](https://kreier.github.io/timeline/history/percentage_strings_checked_tag.svg)"
https://github.com/kreier/impact/blob/master/README.md,
https://github.com/kreier/python2018/blob/main/README.md,"# Python 2018 [![MIT license](https://img.shields.io/github/license/kreier/python2018?color=brightgreen)](http://opensource.org/licenses/MIT) ![GitHub Release](https://img.shields.io/github/v/release/kreier/python2018) [![Jekyll with GitHub Pages](https://github.com/kreier/python2018/actions/workflows/jekyll-gh-pages.yml/badge.svg)](https://github.com/kreier/python2018/actions/workflows/jekyll-gh-pages.yml) Just a documentation of my first steps in python from 2018 on. It started with the workshop during the *BeTogetherConverence* at AIS on *November 16, 2018*. ## January 2020 The first [T400](https://github.com/kreier/T400) robot is running with Micropython! ## December 2019 Now python runs on esp8266 and esp32 as well. With REPL you see the result immideately. It is also possible to compare the code in python and Arduino C accross devices. ### Prime numbers to 10000 Time in milliseconds. | unit | esp8266 | esp32 | esp32 | raspberry pi 4 | Xeon X5550 | |--------------|---------|-------|-------|----------------|-------------| | MHz | 40 | 40 | 240 | 1400 | 3060 | | milliseconds | 24746 | | 8012 | 215 | 16 | | ms in C | | | 2516 | | | ### Web server on esp8266 and esp32 Simple project, located in [micropython/webserver](micropython/webserver) and copied from [RandomNerdTutorials](https://randomnerdtutorials.com/esp32-esp8266-micropython-web-server/) it takes 10 minutes to create a local webserver: ![webserver](micropython/webserver/20191216.gif) ## December 2018 No need to install software, you can use python in a Jupyter notebook with graphical output. Here I used pyplot in [this basic example](https://github.com/kreier/python2018/blob/master/basics/first.ipynb). ## November 2018 My first [Hello World!](https://github.com/kreier/python2018/blob/master/basics/hello-world.py) and [calculating prime numbers](https://github.com/kreier/python2018/blob/master/basics/prime-numbers.py) worked well."
https://github.com/kreier/bilder/blob/main/README.md,"# Bilder ![GitHub License](https://img.shields.io/github/license/kreier/bilder) ![GitHub Release](https://img.shields.io/github/v/release/kreier/bilder) Support tool to organize and categorize my image collection. ## Rationale I store my images sorted by years, with a folder for each year. Inside these folders there are subfolders for each event. The name style of these subfolders is `MMDD_Description_of_the_Event`. The pictures of a visit to Shanghai on the first of August in 2024 would therefore be in the folder `/2024/0801_Shanghai/`. The goal for the `investigate.py` app is therefore to scan the folders with the years, and create a `.csv` file with colums for all folders, the number of subfolders, number of files, and total size of the folder. A later `investigate_events.py` will be more verbose about the events. Since the folder name structure is defined the events can be named (with removing the _ characters) and the correct month and day of the event. ## October 2024 In Shanghai I had several ideas, and made it actually work later in Saigon. The `csv` file was created with the intended informations. ## October 2025 Now in Phnom Penh three more requirements emerged: - Have it run automaically periodically (once a month) on the diskstation to have an updated overview automatically - Combine all the .csv files into one larger `.xlsx` file with Tabs for each year, and probably one ""overview"" tab - Check folder names to have `underscore_between_the_text` for compatibility, but have the csv file with a column just Text Each csv could there fore have date (4 digits), event and folder, files, subfolders While at it, the `/photo` should be read only, and be populated with copy/paste from `/sCloud/xchange/bilder` folder ## Diskstation DS216+ II Since my Diskstation DS215j was not easily accessed over the internet and 10,000 km away I started with a local NAS as Diskstation DS216+II with 8 GB RAM in 2017. By 2026 I had collected 71225 pictures (149.65 GByte): ![pictures overview](docs/2026-01-25_ds216.svg) Now let's organize them! ## iCloud Like the best camera is the one you have with you, the best pictures are the ones you can share. And in many cases that is your phone with you. In January 2026 I discovered that I can access my iCloud photo library with python. Now I can automate my image organizing project, if I ever find the time to write these scripts. Current count: 28,548 items ## Google Photos Since October 2013 I started using my second phone (Android) not just for teaching but also to take photos. Should also be consilidated with the Diskstation summary. The Dashboard shows more than 4000 photos."
https://github.com/kreier/prime/blob/main/README.md,"# Calculating prime numbers [![GitHub release](https://img.shields.io/github/release/kreier/prime.svg)](https://GitHub.com/kreier/prime/releases/) [![MIT license](https://img.shields.io/github/license/kreier/prime)](https://kreier.mit-license.org/) [![Deploy Jekyll with GitHub Pages](https://github.com/kreier/prime/actions/workflows/jekyll-gh-pages.yml/badge.svg)](https://github.com/kreier/prime/actions/workflows/jekyll-gh-pages.yml) This is just a simple benchmark tool to compare algorithms, programming languages and CPUs from microcomputers to workstations. I've been using this calculation since 1989. It is still usefull for microcontrollers like the T-Display with an esp32s2: ![T-Display with esp32s2](circuitpython/t-display.jpg) The code is only 14 lines short: ``` py import math, time # v2.0.2022 in Python last, found = 1000000, 4 # we start from 11, know already 2, 3, 5, 7 print(f""Calculating prime numbers to {last}."") start = time.monotonic() for number in range(11, last, 2): prime = True for divider in range(3, int(math.sqrt(number))+1, 2): if number % divider == 0: prime = False break if prime: found += 1 end = time.monotonic() print(f""This took: {(end - start)} seconds. I found {found} prime numbers."") ``` ## Increasing the speed - four parameters determine the runtime of the calculation The runtime depends on four variables. Multicore can be considered under algorithm and is represented in v4.0 and c6.0: - Used __Algorithm__ (e.g. 34x for v0.9 to v5.0 in Python) - Used __programming language__ (c. 16x vor v5.0 from Python to C) - __CPU__ running the algorithm (c. 2.1x for v5.0 Python from i5-2520M 3.2GHz to i3-10100 4.2 GHz) - __Used range__ to investigate (e.g. 23x longer for 10x larger range 100 million instead of 10 million in Python v5.0) ### Better and faster algorithms A faster way to calculate the prime numbers was already implemented 1991 in Omicron Basic on a Atari ST. By 2024 I collected 8 improvements to the algorithm. ![graph algorithm](docs/comparison_algorithms.png) - v0.8.1991 compare result of division to division with truncated decimal places - v0.9.1991 use only divisors until the squareroot of the investigated number - v1.0.1991 start with 11 in steps of 2 and use odd dividers from 3 on - v1.1.2000 store result of the division, then check for decimal places - v2.0.2022 use modulo operator for comparison - v3.0.2023 put check for prime into a function - v4.0.2023 write code to execute it in parallel - v5.0.2023 calculate the prime numbers to the square root of the largest number, use these prime numbers as divisors for the remaining numbers - v6.0.2024 make v5.0 in parallel without problems in the racing conditions ### Higher speed with other programming language The same algorithm compiled in C for the prime numbers to 1,000,000 need just 0.049 seconds while Python3 needs 2.26 seconds to interpret the code and give the answer on my M1 Macbook. ![graph language](docs/comparison_languages.png) With this simple example some 20x improvements can be seen. But the development does not stop, interpreters are getting faster and with special modules for special tasks a ""slow"" language might no longer be slow at all. While having the benefit of being easier to develop, prototype and maintain. ### Faster with a different CPU Interestingly the improvement in CPU performance for this specific task is not as large as the increase in the frequency these chips run. The range from 16MHz on the Atmel826P for the Arudino Uno to the 4200MHz for the i3-10100 brings a speed improvement of 262x. And 64bit instead of 8 bit can bring another 8x just from the data and instruction side. With long prediction pipelines the increase in IPC over the years is still significant. ![graph cpu](docs/comparison_cpus.png) ### Details to higher speed with a different programming language | language | prime numbers | factor | |--------------------:|--------------:|-------:| | C | 0.0498 s | 51 | | Java | 0.0663 s | 34 | | Python3 | 2.2611 s | 1 | | Swift | | | | Javascript | | | | Playgrounds (Swift) | 7.0413 s | 0.36 | And the code from fast to slow: #### C in 0.0498 seconds ``` c #include #include #include #include int main() { int last = 1000000; int found = 4; // we already know 2, 3, 5, 7 const int arraylength = (int)(last / log(last)); // printf(""%d"",arraylength); int primes[1000000] = {2, 3, 5, 7}; clock_t start, end; double cpu_time_used; printf(""Calculating prime numbers until %d\n"", last); start = clock(); for (int number = 11; number < last; number += 2) { int prime = 1; for (int divider = 3; divider < (int)(sqrt(number)) + 1; divider += 2) { if (number % divider == 0) { prime = 0; break; } } if (prime == 1) { primes[found] = number; found += 1; } } end = clock(); cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC; for (int i = 0; i < found - 1; i++) { printf(""%d, "",primes[i]); } printf(""\nFound %d prime numbers.\n"", found); printf(""This took %f seconds."",cpu_time_used); } ``` #### Java with OpenJDK 17.0.6 in 0.066340542 seconds ``` java class prime { public static void main(String[] args) { int last = 1000000; int found = 4; System.out.println(""Prime numbers to "" + last); System.out.print(""2, 3, 5, 7, ""); long start = System.nanoTime(); for(int number = 11; number < last; number = number + 2) { boolean prime = true; for(int divider = 3; divider 0: found += 1 end = time.perf_counter() print(f""This took: {(end - start)} seconds."") print(f""I found {found} prime numbers. For 10 million it should be 664,579."") ``` And finally: For the original 1 million it takes 0.702 seconds. Not so far from the 0.128 seconds in C (5.5x slower). Which makes we wonder: How fast would it be in Rust or in C in parallel? ## Even faster with the Sieve of Eratosthenes? This [algorithm](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) is known and documented for almost 2000 years. How much faster would it be than the brute force method above? Time to find out. One limitation could be the required memory for the primes. Let's say I want to know the primes until 2E32 or 4,294,967,295. With the previous algorithm I would need 32bit x 203,280,221 primes = 813,120,884 byte. That's 775 MByte. Using the Sieve of Eratosthenes I could only include the odd numbers (I know the only even prime number - two) and just use one bit to represent if a number is prime (1) or not (0). Then each byte gives 8 numbers, and we need 4,294,967,295 / 2 / 8 = 268,435,456 bute = 256 MByte. It is actually less RAM demanding! Later 2024 I will give it a try. Well, actually 2025: ``` c #include #include #include #include #define MAX 1000000 void sieve(bool primes[]) { for (int i = 2; i < MAX; i++) primes[i] = true; for (int i = 2; i <= sqrt(MAX); i++) { if (primes[i]) { for (int j = i * i; j < MAX; j += i) primes[j] = false; } } } int main() { bool primes[MAX] = {false}; clock_t start, end; double cpu_time_used; printf(""Calculating prime numbers until %d using Sieve of Eratosthenes...\n"", MAX); start = clock(); sieve(primes); end = clock(); cpu_time_used = ((double)(end - start)) / CLOCKS_PER_SEC; for (int i = 2; i < MAX; i++) { if (primes[i]) printf(""%d, "", i); } printf(""\nExecution Time: %f seconds.\n"", cpu_time_used); return 0; } ```"
https://github.com/ssis-aa/collaborative-code/blob/main/README.md,"# Unit 3: Collaborative Code [![Deploy Jekyll with GitHub Pages](https://github.com/ssis-aa/collaborative-code/actions/workflows/jekyll-gh-pages.yml/badge.svg)](https://github.com/ssis-aa/collaborative-code/actions/workflows/jekyll-gh-pages.yml) [![GitHub release](https://img.shields.io/github/release/ssis-aa/collaborative-code.svg)](https://GitHub.com/ssis-aa/collaborative-code/releases/) [![MIT license](https://img.shields.io/github/license/ssis-aa/collaborative-code)](https://ssis-aa.mit-license.org/) In [Advanced Automation](https://github.com/ssis-aa) at [SSIS](https://www.ssis.edu.vn/). With [its own website](https://sites.google.com/ssis.edu.vn/automation). ## Circle K In 2022/2023 we recreated the generative art displayed outside Circle K in Vietnam. Evan [made a video](https://youtu.be/zwtpcwmTg7Q) describing the process, and our four students wrote the code to recreate the pattern: ![art at Circle K](https://raw.githubusercontent.com/kreier/circle_k/main/result2.png) ## Collaborative Code Results can be found at https://github.com/ssis-aa/generative-art-collaboration2022. The final iteration from Day 6 looks like this: ![day 6](https://raw.githubusercontent.com/ssis-aa/generative-art-collaboration2022/main/docs/2022-12-23.png) And the code is [here on p5js.org](https://editor.p5js.org/mkreier/sketches/vy0dgv6Cp). Not sure what this was created with, but it still runs in p5js in February 2026 on version 1.5.0. Since January 2025 an updated framework with v2.0 started that broke some earlier workflows. February 2026 also introduced WebGPU."
https://github.com/hviovn/hello-world/blob/main/README.md,"# hello-world ![GitHub License](https://img.shields.io/github/license/hviovn/hello-world) ![GitHub Release](https://img.shields.io/github/v/release/hviovn/hello-world) My first start as AI agent on Github. ## Code example I could write something. But Java is most verbose, looks sophisticated to the uninvited :) Here you go: ```java public class HelloWorld { public static void main(String[] args) { System.out.println(""Hello, World!""); } } ``` ## Object oriented? Here is C++ ```cpp #include int main() { std::cout << ""Hello, World!"" << std::endl; return 0; } ``` No example for Java, you'll figure this out by yourself."
https://github.com/kreier/location24/blob/main/README.md,"# location24 Simple Android App to display the location based on GPS data. My old iPhone 7 (and 5S before that) had a simple GPS location app on it. That's how the user interface looks like: ![GPS info](docs/gps_data.jpg) No interrupting ads, just the plain information. I liked it to fast get the information of the height that I am at - on the Acatenango like in this example or when on a plane or hiking in general. It should be possible to create something similar in Kotlin for Android. That's at least the idea. I have a developer account for Android since 2015. Let's use it!"
https://github.com/kreier/hv.io.vn/blob/main/README.md,"# hv.io.vn ![GitHub License](https://img.shields.io/github/license/kreier/hv.io.vn) ![GitHub Release](https://img.shields.io/github/v/release/kreier/hv.io.vn) Managing local homelab projects in Vietnam. ## Projects I live in [Chung cฦฐ Hฦฐng Vฦฐแปฃng 1](https://maps.app.goo.gl/5ZPag2DvCcUSzM2d9) in Saigon, so the domain name hv.io.vn for my little projects made sense. Many services are only available inside the network, but some are also mapped to the internet. They are: - [llm.hv.io.vn](https://llm.hv.io.vn) Try out the Open WebUI on my machine. - [wp.hv.io.vn](https://wp.hv.io.vn) A wordpress blog hosted on my server. ## Local domains To ensure secure communication even inside the network it is best to encrypt it. But for pi4.home I can't get a certificate from LetsEncrypt, so I need to import the certificate myself."
https://github.com/kreier/ml/blob/main/README.md,"# ML - machine learning ![GitHub Release](https://img.shields.io/github/v/release/kreier/ml) ![GitHub commit activity](https://img.shields.io/github/commit-activity/y/kreier/ml) ![GitHub License](https://img.shields.io/github/license/kreier/ml) This is just a documentation of my learning progress starting 2018. From 2024 on I created a few subfolders: - [llama.cpp](./llama.cpp) - [ollama](./ollama) - [deepseek](./deepseek) ## 2018 - Start with Object Detection Inspired by object detection for cars with DarkNet (see this [TED talk from 2017](https://www.youtube.com/watch?v=Cgxsv1riJhI) by Joseph Redmon) and David's bachelor work at [HCMUTE](http://en.hcmute.edu.vn/) in connection with a car at the end of 2018 I started to learn more about machine learning. Posenet runs on TensorFlow.lite in a browser on WebGL even on a smartphone. We tested it in December 2018 in Seoul, Korea. In March 2019 I got TensorFlow.js running with my RX470 with 43 fps. ![Posenet the park](TensorFlow.js/posenet/2019-03_thepark.jpg) During 2019 NVIDIA announced the [Jetson Nano](https://en.wikipedia.org/wiki/Nvidia_Jetson) developer kit and with students from AISVN we tried to win one in a competition. Eventually we ordered a package. ![Jetson Nano car](https://kreier.github.io/jetson-car/pic/2019_jetson_car.jpg) Early 2020 some supply chains delay orders, but we finally have the hardware. Now it needs to be combined - and development stalls until 2024. ### Facemesh example ### Schedule for 2020 In [this article](https://towardsdatascience.com/from-a-complete-newbie-to-passing-the-tensorflow-developer-certificate-exam-d919e1e5a0f3) Harsheev Desai describes his journey to become a TensorFlow Developer with Certificate in 5 months. #### 1. Learn Python - [Python bootcamp at udemy](https://www.udemy.com/course/complete-python-bootcamp/) - [Coursera python](https://www.coursera.org/specializations/python#courses) - [List of 10 courses at medium.com](https://medium.com/better-programming/top-5-courses-to-learn-python-in-2018-best-of-lot-26644a99e7ec) #### 2. Learn Machine Learning Theory - [Coursera Machine Learning](https://www.coursera.org/learn/machine-learning/home/welcome) on Statistics, Calculus and Linear Algebra #### 3. Learn Data Science Libraries Some of these libraries are Pandas (data manipulation and analysis), Numpy (support for multi-dimensional arrays and matrices), Matplotlib (plotting) and Scikitlearn (creating ML models). - [Pandas videos](https://www.youtube.com/playlist?list=PLeo1K3hjS3uuASpe-1LjfG5f14Bnozjwy) - [NumPy videos](https://www.youtube.com/watch?v=QUT1VHiLmmI) or [freeCodeCamp](http://freecodecamp.org/) - [MatPlotLib videos](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfefDfXb9Yf0la1fPDKluPF) - [Scikitlearn at udemy](https://www.udemy.com/course/machinelearning/) or [3 hour video](https://www.youtube.com/watch?v=pqNCD_5r0IU) #### 4. Deep Learning Theory - [Coursera Deep Learning](https://www.coursera.org/specializations/deep-learning?#courses) - [Inner workings of DNN in practical implementations](https://medium.com/analytics-vidhya/what-i-learned-from-building-a-deep-neural-network-from-scratch-and-why-you-should-do-it-too-a2e6f422d3db) #### 5. TensorFlow Certificate - [Coursera TensorFlow in Practice](https://www.coursera.org/professional-certificates/tensorflow-in-practice#courses) One reason for tensorflow can be seen in this graph regarding popularity on [stackoverflow](https://stackoverflow.co/): More about the tensorflow certificate [here on medium](https://medium.com/@harshit_tyagi/google-certified-tensorflow-developer-learning-plan-tips-faqs-my-journey-9f88016048e3). It was [launched in March 2020](https://blog.tensorflow.org/2020/03/introducing-tensorflow-developer-certificate.html) but ceased to exist [by 2024](https://www.tensorflow.org/certificate). The data science hype, once reflected on platforms like [towardsdatascience](https://towardsdatascience.com/) and [medium.com](https://medium.com/) has subsided. The focus has shifted to innovations like transformers and ChatGPT, which have been the ""hot new thing"" since 2022. Nevertheless, I took the opportunity to learn Python, Pandas, NumPy, Matplotlib, Deep Learning, Machine Learning, and Neural Networks along the way. NumPy and Pandas have now surpassed tensorflow and pytorch on [stackoverflow](https://survey.stackoverflow.co/2024/). ## 2022 - Teach ML in [Advanced Automation](https://github.com/ssis-aa) at SSIS in Unit 5 As covered in a [SSIS Stories](https://www.ssis.edu.vn/student-life/post-details/~board/hs/post/robots-on-a-roll-automation-and-algorithms) in March 2022 we made great progress in creating our own Neural Network, Training it and then doing interference on them. See also [our website](https://sites.google.com/ssis.edu.vn/automation). If you think about possible learning experiences, we tried a few ones with our students: - __Create__ your own neural network, generate training data, __train__ your model (with loss and test) and then use the trained model (__inference__). It was part of the SSIS course _Advanced Automation_ [https://github.com/ssis-aa/machine-learning](https://github.com/ssis-aa/machine-learning) - __Image classification__: Select training data (for example of seagulls) and train a ML model in xcode on your Mac to properly identify your test set of images. It was part of the SSIS course App Development - Build your __own GPT__. A phantastic course by Andrej Karpathy with his [nanoGPT](https://github.com/karpathy/nanoGPT) model guides you in a [2-hour video](https://www.youtube.com/watch?v=kCc8FmEb1nY) to create endless Shakespeare. With Googles offerings inside a [Colab Jupyter notebook](https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing) you can train your model without a GPU just in the cloud for free. - Run your __local LLM__. With Meta providing the weights for their llama model with 8b, 70b and 405b parameter it is possible in 2024 to run a LLM on your local CPU or GPU. OF course there are some limitations in speed and VRAM size, but that's part of the learning. [Ollama](https://ollama.com/) is a good starting point. - Update your local LLM with RAG (Retrieval Augmented Generation) with links to your documents in `open-webui/backend/data/docs` ## 2024 - start with LLMs Andrej Karpathy offers a step-by-step guide to build your own Generative Pre-trained Transformer (GPT) starting with 1,000,000 characters from Shakespeare that you can train on your own GPU. Well, at least if it supports CUDA >7.0, otherwise the [triton compiler](https://github.com/triton-lang/triton) throws an error (like on my slightly older GTX 960): ``` sh torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised: RuntimeError: Found NVIDIA GeForce GTX 960 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2 ``` Let's see what I have and what CUDA Compute Capabilities (CC) these support: | GPU name | Cores | CC | at | architecture | RAM GB | |---------------|------:|:------------------:|:-----------:|--------------|-------:| | Quadro FX 580 | 32 | 1.1 | hp Z600 | [Tesla](https://en.wikipedia.org/wiki/Tesla_(microarchitecture)) (2006) | 0.5 | | GTX 650 | 384 | 3.0 | E3-1226 v3 | [Kepler](https://en.wikipedia.org/wiki/Kepler_(microarchitecture)) (2012) | 1 | | GT 750M | 384 | 3.0 | MBPr15 2014 | Kepler (2012) | 0.5 | | M1000M | 512 | 5.0 | Zbook 15 G3 | Kepler (2012) | 1 | | GTX 960 | 1024 | 5.2 | E5-2696 v3 | Maxwell (2014) | 2 | | Jetson Nano | 128 | 5.3 | | [Maxwell](https://en.wikipedia.org/wiki/Maxwell_(microarchitecture)) (2014) | 4 | | GTX 1060 | 1280 | 6.1 | i3-6100 | [Pascal](https://en.wikipedia.org/wiki/Pascal_(microarchitecture)) (2016) | 6 | | T4 | 2560 | 7.5 | Google Colab | Turing (2018) | 16 | | RTX 2080 Ti | 4352 | 7.5 | i5-7600K | [Turing](https://en.wikipedia.org/wiki/Turing_(microarchitecture)) (2018) | 11 | | RTX 3060 Ti | 4864 | 8.6 | i7-8700 | Ampere (2020) | 8 | | RTX 3070 Ti | 6144 | 8.6 | i3-10100 | [Ampere](https://en.wikipedia.org/wiki/Ampere_(microarchitecture)) (2020) | 8 | Only __two__ of 8 are supported by the Triton GPU compiler. How about a newer GPU? At least I can use the T4 in Google's colaboratory for free. The training takes one hour. And you get two hours for free. Ollama only needs CUDA Compute Capability 5.0 and can therefore run on 5 of my graphic cards. Plus the RX 6600 with ROCm and a hack. ### Triton Compatibility (supported hardware): - NVIDIA GPUs (Compute Capability 7.0+) - AMD GPUs (ROCm 5.2+) - Under development: CPUs My AMD RX 470, RX 580 and RX 6600 are too old to be [supported by ROCm](https://rocm.docs.amd.com/en/latest/compatibility/compatibility-matrix.html), even though the 6600 already uses [RNDA2](https://en.wikipedia.org/wiki/RDNA_2). The RX 6600 can be used if the llvm target is overwritten to be gfx1030 instead of [gfx1032](https://rocm.docs.amd.com/projects/install-on-windows/en/latest/reference/system-requirements.html). The ROCm installation needs 30 GB! In this regard it seems Nvidia has been ahead of the game for some time now with their proprietary [CUDA since 2007](https://en.wikipedia.org/wiki/CUDA). Support for the first Tesla GPUs with Compute Capability 1.1 was only dropped with CUDA SDK 7.0 in 2016. For the current CUDA SDK 12.0 (since 2022) a CC of 5.0 (Maxwell and newer since 2014) is required. That's true [for ollama](https://github.com/ollama/ollama/blob/main/docs/gpu.md), too. In 2024 that's 10 year old hardware. ### 2025 Legacy status for 5.0 [Maxwell](https://en.wikipedia.org/wiki/Maxwell_(microarchitecture)), 6.0 [Pascal](https://en.wikipedia.org/wiki/Pascal_(microarchitecture)) and 7.0 [Volta](https://en.wikipedia.org/wiki/Volta_(microarchitecture)) With the release of the [Blackwell](https://en.wikipedia.org/wiki/Blackwell_(microarchitecture)) GPUs of the [GeForce RTX 50 series](https://en.wikipedia.org/wiki/GeForce_RTX_50_series) early 2025 a new version of the SDK was released with version [CUDA 12.8](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html). Under **1.5.1 Deprecated Architectures** it states: Architecture support for Maxwell, Pascal, and Volta is considered feature-complete and will be frozen in an upcoming release. Found on [phoronix.com 2025-01-24](https://www.phoronix.com/news/Maxwe--Pascal-Volta-Legacy-Near). ![Deprecated Architectures](pic/2025-01-24_cuda12.8.png) It looks like [Turing](https://en.wikipedia.org/wiki/Turing_(microarchitecture)) is still new enough to receive more updates and features with Compute Capability 7.5 since the new Ray-Tracing (RT) cores are included. This is found in [GeForce 16 series](https://en.wikipedia.org/wiki/GeForce_16_series) and [GeForce 20 series](https://en.wikipedia.org/wiki/GeForce_RTX_20_series). Another rationale could be the GSP (GPU System Processor) that is supported since driver 510 and integrated in the 20 series onward, while initially only used for enterprise solutions. ## Inference on local hardware ### Early 2023: MacBook Pro M1 with 8GB RAM In early 2023 I ran a 8b parameter model with a 4 bit quantization on my MacBook Pro at SSIS. It was impressive to see what's possible with just 8GB of RAM on a laptop! ### Early 2024: Workstation with E5-2696v3 18C/36T and 128 GB ECC RAM It became obvious that you need more RAM for larger models, so I built a new workstation with 128 GB RAM and a 18-core E5-2696 v3 CPU in early 2024. Well, it became another learning experience: ![performance](pic/llm_cpu_gpu_tokens.png) Turns out that the token creation rate is inversely proportional to the size of the model! Or the time to create a token for the answer (TG) is proportional to the RAM speed. A large model might fit into your RAM or VRAM, but the larger the model, the slower an answer will be. The above graph has quantization int4 to fp16, yet the speed for TG is not related to the number of parameters or speed of the GPU, but the model size in RAM - at least for TG. Not a new insight, [on llama.cpp](https://github.com/ggerganov/llama.cpp/discussions/4167) there are conversations and graphs related to this topic and Apple hardware. No wonder I get only 0.2 tokens/s for the larger 70b parameter if only using DDR3 ECC RAM. And that 4-bit quantized models are almost as precise as the full fp16 ones was tested in a paper 2023-02-28 ([The case for 4-bit precision: k-bit Inference Scaling Laws](https://arxiv.org/pdf/2212.09720)). With a quarter the size you could fit a model with 4x the parameters in RAM, or get the same model to work 4x faster. Since RAM size and RAM speed are both expensive. ![PP and TG for Apple hardware](https://raw.githubusercontent.com/kreier/benchmark/refs/heads/main/llm/text_generation_vs_bandwidth_apple_silicon.png) I found 20 tokens/s and faster to be a usable speed to use an LLM, and looking at the graph you see what hardware you will need. CPUs are out of the question. Both RX 6600 and RTX 3060 Ti have 8GB of RAM. I got the RX 6600 for $130 and the RTX 3060 Ti for $200. To get the same tokens/s that I have with 8b models, but for a 70b model I would need a RTX 6000 Ada with 48 GB of RAM for $6000. And even that is by far not enough for a 405b model. Yet the possible accuracy would be nice: ![accuracy](pic/accuracy_llms.png) Measurements above are done by Meta. ### Correlation Model Size and TG token generation - October 2024 After some test runs with ollama in October 2024, reading documentation and the results of other people running tests it seems like there is a simple relationship for the token generation speed $T$ from the RAM bandwidth $B$ in GB/s and the model size $M$ in RAM in GB. I found an almost linear fit with a factor of 1.1, here simplified to 1: This approximated linear relation can be seen in the Apple Silicon graph in the last paragraph, but it seems to be not linear above 400 GB/s. My experiments show an almost linear relationship, if you convert token/s back to time per token: ![time per token](https://kreier.github.io/ml/pic/time_per_token.png) What's with the M CPUs from Apple? [Anandtech tested the memory bandwidth](https://www.anandtech.com/show/17024/apple-m1-max-performance-review/2) for the Ultra CPU and found that the CPU can't use all the memory bandwidth (M1 128bit wide, M2 Pro 256 bit wide, M4 Max 512 bit wide, M2 Ultra 1024 bit wide). Maybe the reason is that the 8 LPDDR5 128bit controller have to move the data across the chip to the GPU in some instances. Here is a die picture just from the M1 Max chip, see how much area is used just for the memory controllers: <!-- --> The two M1 Max chips that are connected with some 10000 traces on the 2.5D chip packaging interposer for 2.5 TB/s bandwidth. This should be enough for the ""just"" 0.8 TB/s memory bandwidth, but maybe it's not always as aligned as wanted, or a better driver would improve speed there. So that the GPU cores have their dedicated RAM segment to work on and little data has to be moved over the UltraFusion interface. [Anandtech wrote about](https://www.anandtech.com/show/17306/apple-announces-m1-ultra-combining-two-m1-maxes-for-even-more-performance) this technology in 2022. [Another test in 2023](https://macperformanceguide.com/MacPro2023-MemoryBandwidth.html) only saw 240 GB/s for the M2 Ultra - limit for the CPU? Anyway, here my findings for memory speed in a table: | CPU | Memory | GByte/s | x | GPU | Memory | GByte/s | |------------|--------------------|---------|---|---------------|--------------------|---------| | E3-1226 v3 | DDR3 1333 | 22 | | [Jetson Nano](https://www.techpowerup.com/gpu-specs/jetson-nano.c3643) | 4GB LPDDR4 64bit | 25 | | i7-8700 | DDR4 2666 | 35 | | [Quadro M1000M](https://www.techpowerup.com/gpu-specs/quadro-m1000m.c2739) | 2GB GDDR5 128bit | 80 | | i7-13700T | DDR4 3200 128bit | 43 | | [P106-100](https://www.techpowerup.com/gpu-specs/p106-100.c2980) | 6GB GDDR5 192bit | 192 | | Apple M1 | LPDDR4X 4266 | 66 | | [RTX 3070 Ti](https://www.techpowerup.com/gpu-specs/geforce-rtx-3070-ti.c3675) | 8 GB GDDR6X 256bit | 608 | | M3 Max | LPDDR5 6400 512bit | 409 | | [P100](https://www.techpowerup.com/gpu-specs/tesla-p100-pcie-16-gb.c2888) | 16 GB HBM2 4096bit | 732 | | M4 Max | LPDDR5X 8533 | 546 | | [RTX 6000 Ada](https://www.techpowerup.com/gpu-specs/rtx-6000-ada-generation.c3933) | 48 GB GDDR6 384bit | 960 | And while news to me, this very limit of the response time in LLMs is long known in the industry. And there are some novel ideas on how to circumvent the ""latency bottleneck"". ### Faster inference with speculative execution Just reading the process and analyzing my findings this approach seems obvious. For one token the entire model has to be loaded from the VRAM into the cache of the GPU and processed. But most of the time the GPU is just waiting for new data to arrive. If we had a good guess for the next token, we could process the extended prompt at the same time with no measurable increased time to generate a token, but we would have 2 tokens generated! Here are some papers about this: - [Accelerating Large Language Model Decoding with Speculative Sampling](https://arxiv.org/pdf/2302.01318), paper by DeepMind, 2023/02/02 - [Cascade Speculative Drafting for Even Faster LLM Inference](https://arxiv.org/pdf/2312.11462), [Ziyi Chen](https://openreview.net/profile?id=~Ziyi_Chen8) at University of Illinois, 2024/02/27 - [Speculative Decoding โ Make LLM Inference Faster](https://medium.com/ai-science/speculative-decoding-make-llm-inference-faster-c004501af120) Improve LLM inference speed by 2โ3X without degrading any accuracy, Luv Bansal on medium.com, 2024/04/08 - [Beyond the Speculative Game: A Survey of Speculative Execution in Large Language Models](https://arxiv.org/pdf/2404.14897), *Beijing Institute of Technology*, China, 2024/04/23 - [Async/parallel speculative execution with llama.cpp](https://github.com/ggerganov/llama.cpp/discussions/6853), okuvshvnov, 2024/04/24 - [SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices](https://www.together.ai/blog/specexec), article on together.ai, 2024-06-18 The above papers indicate that 2x or even 3x would be possible. I think you need very good conditions to achive that result - but from a probablility standpoint. One factor is that the speculation of further token takes up a considerable amount of time, and you want it to be fast (and small). On the other hand you want to have a high success rate. I played around with some parameters in a [Google Sheet](https://docs.google.com/spreadsheets/d/1SNf6ulzuzFyCcL6kMPn3qZZKFgRWvbiTxRUIxrRnBsk/edit?usp=sharing) and set the success rate to 90% and made the speculative model 20x faster/smaller. In this case the large model produces a token every 100ms, and the speculative model every 5 ms. Here is the result: I can't get to 2x with these values. I would need a much smaller model that is 50x smaller/faster than the large model to hit 2.37x. ### Early 2025: Multi GPU machine for fast Inference After learning in October 2024 that I not only need a lot of RAM, but it also needs to be fast - preferably VRAM - I frankensteined a damaged EVGA Z170 mainboard together with a cheap i3-6100 CPU and four graphics cards (plus one integrated) for a penta-GPU server: ### Summer 2025: Training with unsloth and Triton on Ampere GPU on dedicated server The machine is a i7-8700 with a RTX 3060 Ti. With only 8GB VRAM we are limited to smaller models, but with [unsloth.ai](https://unsloth.ai/) we can offload many layers and make better use of the system RAM. ## Improved performance of LLMs in just 1.5 years With the open source model Deepseek R1 published early 2025 the gap between closed source and open source models became narrower again. [epoch.ai](https://epoch.ai/) has some interactive graphs, for example the [following one](https://epoch.ai/data/ai-benchmarking-dashboard) for the [GPQA](https://github.com/idavidrein/gpqa) Diamond questions. ![Benchmarks 2023 - 2025](pic/2025-01_benchmarks.svg) The article [How Far Behind Are Open Models?](https://epoch.ai/blog/open-models-report) explores this topic further in detail, for example in benchmarks like [GPQA](https://huggingface.co/papers/2311.12022), It seems that the use of GPUs with AlexNet in 2014 changed the speed of development (and willingness to deploy resources) significantly (from [notable AI models](https://epoch.ai/data/notable-ai-models)): ![notable AI models](pic/2025-02_notable_ai_models.svg) For comparison my experience, taken from my [benchmark repository](https://kreier.github.io/benchmark/). FLOPS only $10^9$ to $10^{14}$, equal to $10^{16}$ to $10^{21}$ when running for 115 days (4 months). ![my GFLOPS experience](https://kreier.github.io/benchmark/docs/GFLOPS_time.svg) Combined: ![my GFLOPS experience](https://kreier.github.io/ml/pic/2025-02_notable_ai_models_combined.svg) ## Slow LLM server in a container Let's hope this Mermaid diagram is shown on the webpage: ```mermaid graph TD subgraph Hardware [Physical Layer] A[HP EliteDesk 800 G4 Mini i5-8500T - RAM - NVMe] end subgraph Hypervisor [Virtualization Layer] B[Proxmox VE] end subgraph VM [Virtual Machine] C[Ubuntu 24.04.3 LTS] subgraph Runtime [Container Engine] D[Docker / Docker Compose] subgraph Containers [Application Layer] E1[Traefik] E2[WordPress] E3[Ollama] E4[Open WebUI] E5[Grafana] E6[Home Assistant] end end end A --> B B --> C C --> D D --> E1 D --> E2 D --> E3 D --> E4 D --> E5 D --> E6 style A fill:#f9f,stroke:#333,stroke-width:2px style B fill:#bbf,stroke:#333,stroke-width:2px style C fill:#dfd,stroke:#333,stroke-width:2px style D fill:#ffd,stroke:#333,stroke-width:2px ``` ## Lessons learned so far - 2023/03/05 Larger models are better, you need more RAM. More **expensive**. - 2024/07/10 Faster GPUs generate the tokens faster. Faster means more **expensive**. - 2024/07/20 You need newer GPUs. At least [Maxwell](https://en.wikipedia.org/wiki/Maxwell_(microarchitecture)) ([CUDA](https://en.wikipedia.org/wiki/CUDA) Compute Capability 5.0) for inference with ollama. You need at least [Volta](https://en.wikipedia.org/wiki/Volta_(microarchitecture)) (Cuda CC 7.0) to run the Triniton compiler if you build your own nanoGPT. The newer, the more **expensive**. - 2024/10/05 It's actually the memory speed. Faster GPUs in general also have faster memory access. Only for the first PP (prompt processing) stage you need raw GPU power, after that in TG (token generation) or EV (evaluation) it is mainly RAM bandwidth. And again, faster RAM is more **expensive**. - 2024/11/10 Finally a reason to have more VRAM for the GPU and really fast memory. For smartphones: To use AI you need more memory. Flagships in Android had a lot of RAM compared to Apples offerings, but no convincing use case. With AI its capacity and speed! And in a way Apple was prepared for years with how the M1 was designed. Now all phones have 8 GB RAM. - 2024/11/25 Speculative execution could speed up things. - 2025/02/20 I've been using quantized models for years now. But there are different type of layers that react differently to quantization, and are unique in their dimension. More in the [Visual Guide to Quantization](https://www.maartengrootendorst.com/blog/quantization/) from Maarten Grootendorst. Including GPTQ and GGUF. - 2025/05/01 [MoE](https://en.wikipedia.org/wiki/Mixture_of_experts) will speed up things! Since only a fraction of the model needs to be processed with the context, the speedup could be in the range of the number of experts. [Llama 4 Scout](https://ai.meta.com/blog/llama-4-multimodal-intelligence/) has 16 experts, only 17B active parameters of the 109B total parameters are active at one given time. That's 6.4x. Unfortunately the whole model needs to be in VRAM - [65.6GB for Q4_K_XL from unsloth](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF). My quad-gpu server has only 24 GB VRAM. And Llama 4 Maverick with 128 experts would even need [243GB with Q4_K_XL (4.5bit)](https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF). BF16: 801GB. At least theoretically 23x faster. Selective loading to VRAM from SSD? [math](chatgpt/moe-math.md). And one day later [IBM releases Granite 4.0](https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek) - combining [MoE](https://www.ibm.com/think/topics/mixture-of-experts) with Mamba (6S) and other details! ## History - __October 2018__ Successful installed darknet on ubuntu, object detection works for stills. Don't have a webcam, and the video does not work yet. - __December 2018__ TensorFlow.lite in a browser on my iPhone 7 runs at 6 fps, demonstrated in Seoul - __March 2019__ posenet runs in the browser with new RX470 with 43 fps - __December 2019__ On [hackster.io](https://hackster.io) starts a new competition [AI at the Edge Challenge](https://www.hackster.io/contests/NVIDIA) where you can win a Jetson Nano. I apply and eventually just buy one from [arrow](https://www.arrow.com/) - __February 2020__ The Jetson car is purchased, Wifi module and 7"" display as well. Needs completion - without students due to COVID-19 - __July 2024__ Reactivated the [https://kreier.github.io/jetson-car/](https://kreier.github.io/jetson-car/) project. The hardware is from 2019 (NVIDIA) but the software is still Ubuntu 18.04 LTS. Updates brake simple things like `make` and `gcc`. - __August 2024__ Started to work on [https://kreier.github.io/nano-gpt/](https://kreier.github.io/nano-gpt/) to learn more about LLMs, following Andrej Karpathy's project [https://github.com/karpathy/nanogpt](https://github.com/karpathy/nanogpt) - __December 2024__ Local Proxmox server with i7-8700 and RTX 3060 Ti running [llama3.1:8b](https://ollama.com/library/llama3.1) in [ollama](https://ollama.com/) over [open-webui](https://openwebui.com/) and [tailscale](https://tailscale.com/) - __January 2025__ Compiled [llama.cpp](https://github.com/ggml-org/llama.cpp) on some of [my machines](https://github.com/kreier/ml/tree/main/llama.cpp). Later included support to download from huggingface, and CUDA support. - __February 2025__ Finished the multi-GPU LLM machine. Now needs more software models to run on, and Grafana visualization of the utilization. - __January 2026__ The multi-GPU LLM machine is finally working. Down to just 3 GPUs with a total of 22 GB VRAM it is ok for [translategemma 27b](https://ollama.com/library/translategemma) and [glm-4.7-flash 30B](https://ollama.com/library/glm-4.7-flash) over Open WebUI"
https://github.com/kreier/swagger/blob/main/README.md,"# Swagger UI with Flask ![GitHub License](https://img.shields.io/github/license/kreier/swagger) ![GitHub Release](https://img.shields.io/github/v/release/kreier/swagger) Test of Swagger UI with Flask, mirrored to Github. This API test framework was part of a conversation with Hendrik in Danang in November 2024. One day I will get it to work. Read more at: - [Mockoon](https://github.com/mockoon/mockoon) - [Swagger UI](https://github.com/swagger-api/swagger-ui) - [REST - Representational State Transfer](https://en.wikipedia.org/wiki/REST) with [URI](https://en.wikipedia.org/wiki/URI), [HTTP](https://en.wikipedia.org/wiki/HTTP), and [HTML](https://en.wikipedia.org/wiki/HTML) for the web."
https://github.com/kreier/picow/blob/main/README.md,"# Raspberry Pico W - rp2040 with WiFi ![GitHub License](https://img.shields.io/github/license/kreier/picow) ![GitHub Release](https://img.shields.io/github/v/release/kreier/picow) [![pages-build-deployment](https://github.com/kreier/picow/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/picow/actions/workflows/pages/pages-build-deployment) Code for the Raspberry Pi Pico W we're using in Advanced Automation at SSIS You can visit us also at [kreier.github.io/picow](https://kreier.github.io/picow/) ## Software The root folder contains the `code.py`, the apps are in the `app` folder and required libraries are copied into the `lib` folder."
https://github.com/kreier/igshcmc/blob/main/README.md,# igshcmc Test ground for my igshcmc.de domain.
https://github.com/kreier/tl/blob/main/README.md,"# Timeline on the web - tl ![GitHub License](https://img.shields.io/github/license/kreier/tl) ![GitHub Release](https://img.shields.io/github/v/release/kreier/tl) [![pages-build-deployment](https://github.com/kreier/tl/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/tl/actions/workflows/pages/pages-build-deployment) Interactive website version of my timeline project. The latest edition looks like this: ![latest edition](docs/pic/latest.png) ## Current timeline pdf It looks like this: ![timeline example](https://raw.githubusercontent.com/kreier/timeline/refs/heads/main/docs/timeline20260117_6.01.png) ## History With vibe-coding I got a scalable version working, but pixelated and a far cry from my imagination. But it worked: ![2026-01-19](docs/pic/2026-01-19_proof_of_concept.png)"
https://github.com/kreier/statistics-diary/blob/main/README.md,"# Statistics for my Diary, Blog and Projects ![GitHub Release](https://img.shields.io/github/v/release/kreier/statistics-diary) ![GitHub License](https://img.shields.io/github/license/kreier/statistics-diary) [![Update Version](https://github.com/kreier/statistics-diary/actions/workflows/update.yml/badge.svg)](https://github.com/kreier/statistics-diary/actions/workflows/update.yml) This [repository](https://github.com/kreier/statistics-diary) creates statistics and visual representations of the frequency of entries into my diary and pages for projects, travel and my blog. Version: v2026.02.26.47 ## Short summary - Documents or pages: 143 - Amount of words: 1,432,423 - Required reading time: 15 hours 4 minutes - Images: 132 ## Categories and locations 1. Obsidian and Quartz **Diary** at [diary.saiht.de](https://diary.saiht.de) has 1,023,452 words that would require 13 hours to read. In total some 83 markdown files. 312 of 18,923 days are documented 2. Wordpress **Blog** at [saiht.de/blog](https://saiht.de/blog) with 104 articles and 42,324 words 3. **Legacy website** of saiht.de at [saiht.de/legacy](https://saiht.de/legacy) with 64 pages, 13,124 words 4. Older projects at **subdomains**, listed at [saiht.de/x](https://saiht.de/x) with 20 subdomains, 35 pages, 1,234 words 5. **GitHub** projects with their website: 170 projects, with the main websites containing 23,234 words ## Clickable Graph ![graph 2025](docs/2025-12-18_GitHub_example.png) ## Table on Categories and Locations | Category | Pages | Words | Time to read | Images | |-------------------|------:|-------|-------------:|:------:| | 1) Diary | 92 | 1731 | 2h10 | 52 | | 2) Wordpress Blog | 80 | 947 | 0h50 | 16 | | 3) Legacy Website | 56 | 18 | 1h10 | 5 | | 4) Subdomains | 15 | 72 | 2h10 | 47 | | 5) Github | 170 | 444 | 1h10 | 32 | | All | 1342 | 1342 | 11h20 | 245 | ## (1) Details on Obsidian and Quartz | Category | Markdown files | Files | Folders | Size (Bytes) | Images | Words | |-------------|---------------:|------:|--------:|-------------:|:------:|----------:| | Blog ๐ฅ | 512 | 1731 | 76 | 162,437,617 | 52 | 845,601 | | Diary ๐ฉ | 32 | 947 | 35 | 49,929,432 | 16 | 16,452 | | Projects ๐ฆ | 18 | 18 | 0 | 946,419 | 5 | 84,215 | | Travel ๐จ | 72 | 72 | 6 | 17,622,758 | 47 | 154,875 | | Websites ๐ฆ | 444 | 444 | 29 | 21,701,977 | 32 | 20,154 | | All | 1342 | 1342 | 20 | 89,448,124 | 245 | 1,425,754 | ## (5) Details on 156 Github Projects, sorted by Category I ordered my repositories into the following categories: - Mathematics - Robotics - School - Physics - Automation - Curiosity Metrics I'm interested in: title (repository name), created, size, main language, files, folders, commits. See the github subfolder: [kreier.github.io/statistics-diary/github](https://kreier.github.io/statistics-diary/github/) ### Robotics - T400 - link, 23 words - T500 - link, 24 words ## Procedure, Examples and inspiration Some progress was made with Obsidian, and in time I will copy a lot of information to this markdown diary and repository. While doing so I might add some translation of existing German documentations there. Further I want to include my Wordpress blog, subdomains and legacy websites. ## 2025 - Diary: 20 - Projects: 5 - Blog: 3 - Travel: 2 ## 2024 - Highlights with links? - Only one? - Calculated score? ## Layered Last processed: 2025/12/18 - 18,339 days - Diary: 513 - Projects: 16 - Blog: 38 - Travel: 32 ## By month in Diary/Travel/Projects/Blog Maximum value: - Diary: 31 - January 1997 ๐ฉ - Projects: 15 - March 2006 ๐ฆ - Travel: 28 - August 2024 ๐จ - Blog: 5 - October 2009 ๐ฅ Table created by Python (GitHub has 4 shades plus white, but this can be tweaked once we have answers): | | xxx0 | xxx1 | xxx2 | xxx3 | xxx4 | xxx5 | xxx6 | xxx7 | xxx8 | xxx9 | xxx10 | |------|:--------:|:---------:|:----------:|:---------:|:--------:|:---------:|:---------:|:--------:|:---------:|:--------:|:---------:| | 202x | 8/6/0/1 | 12/1/4/4 | 10/7/4/9 | 13/8/5/5 | 6/8/4/7 | 8/1/5/6 | | | | | | | 201x | 3/0/1/13 | 20/2/3/12 | 10/7/5/5 | 2/7/3/12 | 2/2/1/3 | 7/7/0/8 | 0/11/0/5 | 0/10/5/3 | 19/10/0/9 | 10/2/4/9 | 20/10/2/6 | | 200x | 1/5/4/6 | 10/5/4/2 | 8/7/4/10 | 13/2/3/6 | 4/10/1/7 | 9/2/3/0 | 17/0/3/4 | 7/8/0/9 | 7/7/4/2 | 8/10/3/4 | 3/1/2/13 | | 199x | 0/9/1/6 | 18/4/4/4 | 10/12/2/2 | 2/4/2/5 | 4/10/4/9 | 4/5/1/6 | 14/6/5/0 | 8/0/3/9 | 6/12/2/3 | 1/6/5/3 | 13/10/4/3 | | 198x | 1/6/0/10 | 0/7/1/11 | 10/11/1/13 | 11/7/4/11 | 4/6/3/5 | 13/2/5/11 | 1/11/1/13 | 5/8/3/7 | 11/6/4/10 | 5/9/0/0 | 6/11/1/2 | | 197x | | | | | | 0/9/1/6 | 3/2/0/1 | 9/3/2/13 | 7/10/2/10 | 17/1/5/6 | 4/8/5/9 | Data stored in `.csv`-files. How to parse, how to generate? ## History The documents are located at three locations: - **Quartz** at [https://kreier.github.io/quartz/](https://kreier.github.io/quartz/) - **Obsidian** at [https://saiht.de/obsidian](https://saiht.de/obsidian) or diary.saiht.de - **Wordpress** at [https://saiht.de/blog](https://saiht.de/blog) ### Obsidian I use the [Novel word count](https://www.obsidianstats.com/plugins/novel-word-count) Community plugin to determine the size of the whole vault - 21.12.2025 13.263 words, 50 minutes read with the [Novel word count](https://www.obsidianstats.com/plugins/novel-word-count) Community plugin | date | Blog | Diary | Projects | Travel | Websites | md files | Total words | Total time | |:----------:|:----:|:-----:|:--------:|:------:|:--------:|:--------:|:-----------:|:----------:| | 2025-12-21 | 541 | 4759 | 2830 | 1714 | 1563 | 36 | 13,263 | 0h51 | | 2026-01-19 | 1408 | 27580 | 4366 | 2216 | 1820 | 92 | 39,787 | 2h30 | ### (2) Wordpress - 21.12.2025 93 posts, more statistics follows ## One box per day - 18,000 boxes? How would it look if you get a colored box for each day of your life? Well, let's have a look, just use GitHub contributions as example for the last 8 years: ![2025](docs/2025.png) ![2024](docs/2024.png) ![2023](docs/2023.png) ![2022](docs/2022.png) ![2021](docs/2021.png) ![2020](docs/2020.png) ![2019](docs/2019.png) ![2018](docs/2018.png) To calculate: Each box is 10x10 pixel with 3 pixel whitespace between them. This results in a height of 7x10 + 6*3 = 88 pixel per year and a width of (52+1+1)*10 + 53*3 = 699 pixel. ## Better looking if closer together? I combined above screenshots into one picture where the results are closer together. An inspiration? ![2018-2025](docs/2025-2018.png) ## 19000 days till 10/10/2027 On this day I will have lived 19000 days on earth, and the graduation from SDW will be 17 years ago. How would an overview of all these days look like? Here is a preliminary visual: ![19000](docs/19000.png) ## Or maybe Statistics for 21639 days ![21639 days](https://kreier.github.io/quartz/Projects/GitHub/files_github/2026-01-02_21639.png) ## Workflow Ultimately we only want the summary numbers for 4 metrics: pages, words, time-to-read and images. This is collected from 5 places: 1) **Diary** - Obsidian vault, rendered for the web with Quartz, containing ๐ฉ Diary, ๐จ Travel, ๐ฆ Projects and another ๐ฅ Blog 2) **Blog** or Wordpress - using PHP and MariaDB on [saiht.de/blog](https://saiht.de/blog/) ๐ฅ Wordpress Blog 3) **Legacy** - historic pages from saiht.de on [saiht.de/legacy](https://saiht.de/legacy/) ๐ฆ Projects 4) **Subdomains** of saiht.de - the 10 smaller projects, see [saiht.de/x](https://saiht.de/x/) ๐ฆ 5) **GitHub** - all of them have a Github Page, the metrics are taken from the webpage ๐ฆ ### Static data - sources 2 to 5 Only from time to time I will update the following values: - /data/details_wordpress.csv with all articles written ๐ฅ - /data/details_legacy.csv with all the articles written ๐ฆ - /data/details_subdomain.csv with all the articles written ๐ฆ - /data/details_github.csv with all the repositories and their main README.md of content ๐ฆGithub: xx_name_xx created The update program is `/python/update_details.py`. It parses above 4 files and updates the `/data/summary.csv`. Each static data file can be updated with a respective `/data/update_xx.py` for the 4 sources. For the clickable graphics I need a date, title and link. Condensed to `/data/data_graph_wordpress.csv` and the 3 other files. ### Automatic run Each push and successful run from quartz will trigger `python/update_statistics.py`. The Github Action will check out all data. All static data from above will have been processed already. No need to parse them again. But I need a copy of Obsidian and parse it: - **Blog**, read the frontmatter entry for the date in `date`. It's a second source for ๐ฅ Blog - **Diary**, parse 1975.md to 2026.md for DD.MM.YYYY and count the day if it is bold, for ๐ฉ Diary - **Projects**, maybe one day a copy of each README for each Github project? But that's two locations to keep updated ๐ฆ Projects - **Travel**, the frontmatter has two entries `created` for when the holiday started and `updated` when it ended. Can it be parsed? Full color for start, dimmed between: ๐จ Travel - **Websites** should be treated as projects, and be counted there too. so ๐ฆ Projects For the clickable `STAT_GRAPHS` I need to know each day and number of contributions for the 4 categories. And the tooltip could include a link to the article of the day in Blog, Diary, Travel or Project. ### Parts to update in README.md With some HTML markers and regular expressions parts of the README.md are prepared to be updated by the update python program. The following labels are in there: - STAT_SUMMARY - STAT_CATEGORY_LOCATIONS - STAT_GRAPHS (last 10 years?) - STAT_DETAILS_OBSIDIAN - STAT_GITHUB (include categories) ### Updated files in this repository Obviously the results should be written back to the repository. We need the file names for the Github Action `github/workflows/update.yml` that should receive a push `git add data/iteration.json data/version.txt`: - data/iteration.json - data/version.txt - README.md"
https://github.com/kreier/logo/blob/main/README.md,"# Logos for projects and websites ![GitHub License](https://img.shields.io/github/license/kreier/logo) ![GitHub Release](https://img.shields.io/github/v/release/kreier/logo) Collect ideas for vector logos as AppIcon and for my webpages [kreier.org](https://kreier.org) and [saiht.de](https://saiht.de). ## Update 2026 The [Google Play icon design specifications](https://developer.android.com/distribute/google-play/resources/icon-design-specifications) give some insight on ratios, colors and shapes. The Total asset size is defined as 512x512 pixel, where the product icon keylines fit into a 75% centered part of 384x384 pixel: For my reference size of 1024x1024 this equals 768 pixels. Above the icons for saiht.de and kreier.org have been updated. The reference color for saiht.de is `#105060`, for kreier.org it is `#324167`. ## Logo for kreier.org This one was created 2019, with background `#324167`, RGB values of R:50, G:65, B:103 or CMYK values of C:0.51, M:0.37, Y:0, K:0.6.: ## Logos for the Google Play Store The design specifications can be found on the developer side for Android: - [Google Play icon design specifications](https://developer.android.com/distribute/google-play/resources/icon-design-specifications) The regular icon will be 512x512 32-bit PNG in sRGB. For my two apps I created them: ### Beschleunigungssensor Developed in December 2015 and finally applying for my first app I also used a free material icon, changes some colors and created this app icon: ### Wificar23 This project from 2024 let's a robot car controlled by a esp8266 be directed with a smartphone giving the instructions. ## Logo for saiht.de Since 1999 several icons and logos have been used: ### Ideas 2018 ### Ideas 2025 ## Wificar24 It was planned to finally have a working app in the Google Playstore. Yet time was not sufficient, too many projects. Here my logo idea:"
https://github.com/vex-ssis/2026/blob/main/README.md,"# 2026 Push Back [![MIT license](https://img.shields.io/github/license/vex-ssis/2026)](https://vex-ssis.mit-license.org/) ![GitHub Release](https://img.shields.io/github/v/release/vex-ssis/2026) [![Github Pages](https://github.com/vex-ssis/2026/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/vex-ssis/2026/actions/workflows/pages/pages-build-deployment) SSIS Robotics in the ""Push Back"" VEX competition 2025-2026 ## Scrimmage 2025/10/11 This year 23 teams visited SSIS to [kick of the new season](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-25-0562.html#general-info) and learn from one another. Once more unbeatable: LSTS MAKO MANIACS with 7 wins and 0 losses or ties. Best SSIS team: 1599X SSIS Hawks. ## Vietnam Road to National: Southern Qualification Season 25-26 - 2025/11/22-23 Time for southern teams to qualify for the National Championship in February 2026. While looking forward to this first Signature event, it is a tough competition between the 37 teams on the [Vietnam Road to National: Southern Qualification Season 25-26](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-25-1400.html#agenda). Qualified for the National Chamionship are: - 23457S BRICK Lab SUPER 5-0-0 11 / 50 / 128 - 62024N Panda Robotics 4-1-0 11 / 40 / 143 - 50922T LSTS MAKO MANIACS 4-2-0 11 / 40 / 102 - 28176N Overwatch 5-1-0 10 / 35 / 186 - 1599N SSIS Big Pink Pegasus It was an [eventful](https://www.youtube.com/live/fuf7YvmOIrU) weekend. The teamwork is on full display, the robots are getting more sophisticated and the notebooks improve their quality, too. Team [20226H](https://www.robotevents.com/teams/V5RC/20226H) (NGS Hogrider) from the [HanoiโAmsterdam High School for the Gifted](https://en.wikipedia.org/wiki/Hanoi%E2%80%93Amsterdam_High_School) really improved their gameplay and design in just a few weeks. Their robot design has 6 motors for 4 omniwheels and 2 traction wheels 3.25"" diameter to be more agile. Per calculation of the gears this should result in 360 rpm on the wheels. It resulted in the **INNOVATE Award** for this team! Almost unbeatable again: [50922T LSTS MAKO MANIACS](https://www.robotevents.com/teams/V5RC/50922T) with the **Excellence Award**, **Tournament Champion** and **Skills Champion**. Congratulations! Their robot is also driven by six 11W motors, but has only 4 omniwheels 3.25 inch. Their secret? **460 rpm** on the wheels, they are really fast! Being pushed from the side is not a question, they are out of their way too fast. Another omniwheel in the center is used for odometry. As I learned there are more ways to qualify for VEX Worlds. For example there are the [Online Challenges](https://challenges.robotevents.com/). It was highlighted at VEX Nationals last season, and team 36070M won a spot at VEX World 2025 as [Team 11](https://challenges.robotevents.com/user/144229) in 2025 Challenges > [STEM Advocacy Challenge - High School](https://challenges.robotevents.com/challenge/287/stem-advocacy-challenge/entry) > [Empowering Cao Bang through Robotics](https://challenges.robotevents.com/challenge/287/stem-advocacy-challenge/entry/14761) with a [PDF file](https://challenges.robotevents.com/uploads/0025238_original.pdf) (39 pages) or a [website](https://sites.google.com/view/team-11-36070m/home). And then there are other challenges like [IECF](https://en.wikipedia.org/wiki/International_Science_and_Engineering_Fair) challenge that teams from Vietnam can participate in. ## V5RC HS Vietnam National Championship: Push Back - 2026/01/10 - 11 This event is hosted by VREC, here is [the link on RobotEvents.com](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-25-3807.html) and held in Hanoi at [Alphaschool](https://alphaschool.edu.vn/en/) SmartCity [Hแป thแปng Giรกo dแปฅc Alpha, Lรด A26 KฤT Geleximco](https://maps.app.goo.gl/ZQzNAPwcfTtCpw777), Lรช Trแปng Tแบฅn, Nam An Khรกnh, Hoรi ฤแปฉc. **23 Teams** from Vietnam went there. Great result for SSIS, team 1599N Pink Pegasus (with website: [pinkpegasus.org](https://pinkpegasus.org/) and [Instagram](https://www.instagram.com/reel/DTf49GCDgBA/?utm_source=ig_web_copy_link&igsh=NTc4MTIwNjQ2YQ==)) won the Excellence Awart (with a proud [coach](https://www.facebook.com/frankhua.media/posts/pfbid0a1psYyTKeBcwx5TGnXLyZtRjymW7Rec9KALEkMFMGQ7ac19E7eKbaBCKAyBiooKRl)) and qualifies for VEX Worlds in St. Louis in April 2026. Other winners: - Exellence Award: **1599N** SSIS Big Pink Pegasus - Tournament Champions: **86669A** EDS_Bunreal (Hung Yen) - Tournament Champions: **62595A** EDS _ Phomidable - Design Award: **50922T** LSTS MAKO MANIACS ## Vietnam Signature: New Yearโs Mayhem - High School V5RC: Push Back 2026/02/06 - 8 The [first signature event in Vietnam](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-25-0160.html#general-info)! Happening in February 2026, open for 70 HS teams across Asia! And 50% is given to teams outside of Vietnam. By November 2025 we have already [signups from 7 countries](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-25-0160.html#teams), including China, Taiwan, Macau, Indonesia, Thailand, Singapore and Kazakhstan! ## Virtual Skills Standings On November 22nd, 2025, there are 329 entries from different teams. 8 team from Vietnam are in there, and again it is LSTS MAKO MANIACS who's taking the lead: | Rank | Score | Stop Time | Team Number | Team Name | Organization | |------|-------|-----------|-------------|-----------------------|------------------------------------------| | 9 | 90 | 0 | 50922T | LSTS MAKO MANIACS | Lawrence S.Ting School | | 10 | 90 | 0 | 50922S | LSTS VERTEX | Lawrence S.Ting School | | 66 | 53 | 0 | 1599N | SSIS Big Pink Pegasus | Saigon South International School (SSIS) | | 78 | 50 | 2 | 23457H | BL SAI GON CHEETAH | BRICK lab Robotics | | 182 | 24 | 24 | 23457S | BRICK Lab SUPER | BRICK lab Robotics | | 197 | 23 | 0 | 23457B | BRICK Lab Robotics | BRICK Lab Robotics Club | | 284 | 4 | 18 | 19882U | UNIS Hanoi V5 | UNIS Hanoi | | 297 | 2 | 48 | 88527F | VenomWizor | Trฦฐแปng THPT FPT Tรขy Hร Nแปi | ## Available spots at Worlds The year 2025 saw another increase in interest for VEX V5 in Vietnam. How is 2026? We'll see. There were [7 spots at V5RC](https://kb.roboticseducation.org/hc/en-us/articles/5474199602071-Qualifying-Criteria-for-VEX-Robotics-Competition-Events) for Vietnam in 2025, so 2026: | Season | VIQRC (ES) | VIQRC (MS) | V5RC (MS) | V5RC (HS) | SSIS | |---------------------|:----------:|:----------:|:---------:|:---------:|:----:| | 2018 In The Zone | - | - | - | 1 | 1 - [76209G](https://www.robotevents.com/teams/V5RC/76209G) | | 2019 Turning Point | - | - | - | 1 | 1 - [76209X](https://www.robotevents.com/teams/V5RC/76209X) | | 2020 Tower Takeover | - | - | - | Covid19 | 1 - [76209G](https://www.robotevents.com/teams/V5RC/76209G) | | 2021 Change-Up | Covid19 | Covid19 | Covid19 | Covid19 | - | | 2022 Tipping Point | Covid19 | Covid19 | Covid19 | Covid19 | - | | 2023 Spin Up | [6](https://en.vietnamplus.vn/vietnam-to-send-20-teams-to-vex-robotics-world-championship-2023-post247574.vnp) | [13](https://baogialai.com.vn/hoc-sinh-gia-lai-tiec-nuoi-dung-buoc-o-vong-loai-giai-vo-dich-the-gioi-vex-robotics-2023-post236206.html) | 1 | 1 | [2](https://sites.google.com/ssis.edu.vn/vex) - [76209M](https://www.robotevents.com/teams/V5RC/76209M) & [76209R](https://www.robotevents.com/teams/V5RC/76209R) | | 2024 Over Under | 3 | 5 | 1 | 3 | 0 | | 2025 High Stakes | 3 | 5 | 3 | 4 + 2 | 1 - [1599V](https://www.robotevents.com/teams/V5RC/1599V) | | 2026 Push Back | 3 | 3 | 1 | 3 | ? | Will the Vietnam Banana Farmers is return to Dallas once again?"
https://github.com/kreier/calendar/blob/main/README.md,"# Calendar [![pages-build-deployment](https://github.com/kreier/calendar/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/calendar/actions/workflows/pages/pages-build-deployment) [![GitHub release](https://img.shields.io/github/release/kreier/calendar.svg)](https://GitHub.com/kreier/calendar/releases/) [![MIT license](https://img.shields.io/github/license/kreier/calendar)](https://kreier.mit-license.org/) Create A4 landscape calendars to organize my life. ## Data in the /vacation and /events folder Inside the respective folders are the required files to be found. Each year has its own `.csv` file. For example the `vacation/2024.csv` for the 2024 dates. ## Program in the /python folder The program is written in the `create.py` file and executed as `python create.py 2024` to create the 2024 calendar. ## Software used: [fpdf2](https://py-pdf.github.io/fpdf2/index.html) For some time I used to work with reportlab and it suited my needs very well. But in summer 2024 I discovered limitations with regards to font shaping (like for Khmer and Sinhala) and the support for RTL languages. The implementation in fpdf2 worked, so I switched the python pdf generator package. ## Dimensions An A4 paper in landscape is 297 x 210 mm. Given 5 mm border the calendar with 31 lines for days, one more line for month and some 2 lines for the year on top have a remaining area of 287 mm width and 200 mm height. Each month would therefore get 287/12 = 23.9mm = 67.8pt width. If weekends get a different color then the days don't need to be labeled. As for the line height, we would need 31 + 1 + 2 = 34 lines. Each has a height of 200/34 = 5.89 mm. One point is 0.3515 mm, this line height is 17.1 points."
https://github.com/kreier/thesis08/blob/main/README.md,"# Diplomarbeit 2008 - my thesis from 2008 ![GitHub Release](https://img.shields.io/github/v/release/kreier/thesis08) ![GitHub License](https://img.shields.io/github/license/kreier/thesis08) This is a recreation of the **diploma thesis** in **physics** from at the _Humboldt Universitรคt zu Berlin_ in 2008. ## Diplom 2008 Die LaTeX Originaldatei ist leider verlorengegangen. Aber da ich die [gerenderte PDF von 2008](2008/20080124.pdf) noch habe, konnte ich daraus eine Kopie erstellen. Es ist auch auf [https://people.physik.hu-berlin.de/~kreier/thesis/20080124.pdf](https://people.physik.hu-berlin.de/~kreier/thesis/20080124.pdf) gehostet. ## Thesis 2008 Surprisingly the English edition of the TEX file is still available. But it was never finished. Well, in 2025, 17 years later, I finally completed this work. ## Diplomarbeit 2025 Eine neue Version wurde unter Linux gerendert. Vielleicht kann ich es sogar mit GitHub Actions automatisieren, das wรคre einen Versuch wert. Aber zuerst muss ich die ursprรผngliche `.TEX`โDatei neu erstellen und sie dann an die neue Umgebung des Jahres 2025 anpassen, in der **utfโ8** nativ unterstรผtzt wird und sogar **subscript** in LaTeX keiner speziellen Definition mehr bedarf. Lies [hier mehr](Diplomarbeit/). ## Diploma thesis 2025 This time I finished the translation to English of all 68 pages. But first I have to recreate the original `.TEX` file for the German version and then adjust it for the new environment of 2025 where **utf-8** is natively supported, and even **subscript** needs no specific definition in LaTeX. Read [more here](Diplomarbeit/) ## ArXiv It was an idea from long ago, and now I finally uploaded my diploma thesis to ArXiv - Diplomarbeit 2008 doi:whatever - Thesis 2008 doi:english one"
https://github.com/kreier/tripitaka/blob/main/README.md,"# Tripitaka [![GitHub release](https://img.shields.io/github/release/kreier/tripitaka.svg)](https://GitHub.com/kreier/tripitaka/releases/) [![MIT license](https://img.shields.io/github/license/kreier/tripitaka)](https://kreier.mit-license.org/) [![pages-build-deployment](https://github.com/kreier/tripitaka/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/tripitaka/actions/workflows/pages/pages-build-deployment) I want to get some statistics on the text of the Tripitaka and probably make it searchable for phrases. And compare the results to the Bible. Here the short result: The three baskets have 2782 books and 5273 chapters that could be printed on 7013 pages. The Bible has 66 books with 1189 chapters that in the kjv could be printed on 1062 pages. The Tripitaka is therefore roughly 6.6x as large. There are a few more pages with details: - [Tripitaka](tripitaka) - [German - de](tripitaka/de) - [English - en](tripitaka/en) - [Pali - pli](tripitaka/pli) - [Bible](bible) - [King James Version - kjv](bible/kjv) ## The Pali version by the [The Vipassana Research Institute (VRI)](https://www.vridhamma.org/Tipitaka-Project) The structure of the Tripitaka is more diverse and not as uniform as in the bible. A parsing run over the 7288 json files from the [Pali edition](https://github.com/suttacentral/bilara-data) resulted in the following statistics: - 2,782 books - 42x - 5,273 chapters - 4.4x - 99,567 verses - 3.2x - 481,994 sentences - 13.8x kjv - 3,007,818 words - 3.8x kjv - 22,439,824 characters or letters - 6.9x kjv - 7,013 pages if printed 80x50 per page (Consolas 11pt on A4 with 17/19mm border - 31.4 MByte as text file, 6.6x kjv) In detail for the three Baskets this results in : - Vinaya Piแนญaka has 412 books with 450,529 words on 1039 pages, [4.7 MByte textfile](https://raw.githubusercontent.com/kreier/tripitaka/main/python/tripitaka_vinaya.txt) - Sutta Piแนญaka has 2289 books with 1,692,792 words on 3872 pages, [17.2 MByte textfile](https://raw.githubusercontent.com/kreier/tripitaka/main/python/tripitaka_sutta.txt) - Abhidhamma Piแนญaka has 81 books with 864,497 words on 2102 pages, [9.5 MByte textfile](https://raw.githubusercontent.com/kreier/tripitaka/main/python/tripitaka_abhidhamma.txt) | | books | chapters | verses | sentences | words | characters | pages | size | |-------------------|:-----:|:--------:|:------:|:---------:|:---------:|:----------:|:-----:|:----------:| | Vinaya Piแนญaka | 412 | 8 | 4,259 | 73,833 | 450,529 | 3,363,421 | 1,039 | 4.7 MByte | | Abhidhamma Piแนญaka | 81 | 1021 | 42,558 | 118,211 | 864,497 | 6,884,073 | 2,102 | 9.5 MByte | | Sutta Pitaka | 2289 | 4244 | 52,750 | 289,950 | 1,692,792 | 12,192,330 | 3,872 | 17.2 MByte | | sum | 2782 | 5273 | 99,567 | 481,994 | 3,007,818 | 22,439,824 | 7,013 | 31.4 MByte | Combined thats 31.4 MByte and roughly 7x larger than the KJV project, for comparison below. This version is stored in 7288 json files in 192 folders and has 22 million characters counted. More details further down below. Another size comparison source: [The Vipassana Research Institute (VRI)](https://www.vridhamma.org/Tipitaka-Project) in India states that the Tripitaka makes up 24 million characters. My count is 22 million charagers, for the KJV it was 3.2 million. So the order of magnitude seems correct. ## For comparison the Bible in the King James version - 66 books (5.2 MByte in 66 JSON files, from [Arul John](https://github.com/aruljohn/Bible-kjv)) - 1,189 chapters - 31,102 verses - 35,049 sentences - 790,573 words - 3,223,201 characters - 1062 pages if printed 80x50 per page (Consolas 11pt on A4 with 17/19mm border - [4.3 MByte as text file](https://raw.githubusercontent.com/kreier/tripitaka/main/python/kjv.txt)) And a little private remark: I always wanted to be able to say that I read the entire bible. How long would that take? Some [92 hours](https://github.com/kreier/kinhthanh/blob/main/data/size_audio_en.csv) on average in English. By 2020 I only had the audio files for [827 of the 1189 chapters](https://github.com/kreier/kinhthanh/blob/main/data/size_audio_en_2020.csv) (60 hours). In 2023 I had all files ready, and started listening on June 6th and was [finished 143 days later on October 6th, 2023](https://github.com/kreier/study/blob/main/markdown/progress.txt). Now let's follow up with German and Vietnamese. ## Tripitaka size in tablets at the Kuthodaw Pagoda ![Size based on pages in the Kuthodaw Pagoda](docs/size_kuthodaw.png) The above graph was created based on the used tablets used for the baskets in the [largest book of the world with 729 tablets](https://en.wikipedia.org/wiki/Tripi%E1%B9%ADaka_tablets_at_Kuthodaw_Pagoda) in Mandalay. It assumes that the content of each of the tablets is roughly the same. - Vinaya Piแนญaka 111 tablets - Sutta Pitaka - 410 tablets (for DN, MN, SN (65), AN(78), KN(169)) - Abhidhamma Piแนญaka - 208 tablets A python script run will hopefully give some further insight into the size of the Tipitaka similar to the KJV above from 2024/05/01. More details on the three baskets of the Tipitaka: ## [Vinaya Piแนญaka](https://en.wikipedia.org/wiki/Vinaya_Pi%E1%B9%ADaka) (_Basket of Discipline_) - [Suttavibhaแนga](https://en.wikipedia.org/wiki/Suttavibhanga): [Pฤแนญimokkha](https://en.wikipedia.org/wiki/P%C4%81%E1%B9%ADimokkha) and commentary - Mahฤvibhaแนga: 227 rules for fully ordained monks ([bhikkhus](https://en.wikipedia.org/wiki/Bhikkhu)) - Bhikkhunฤซvibhaแนga: 311 (348 Dharmaguptaka, 364 Mulasarvastivada) rules for nuns ([bhikkhuแนฤซs](https://en.wikipedia.org/wiki/Bhikkhun%C4%AB)) - [Khandhaka](https://en.wikipedia.org/wiki/Khandhaka) 22 chapters on various topics - [Parivฤra](https://en.wikipedia.org/wiki/Pariv%C4%81ra) 19 chapters with analyses of rules from various points of view ## [Sutta Pitaka](https://en.wikipedia.org/wiki/Sutta_Pi%E1%B9%ADaka) - 5 Nikฤyas - 34 + 152/222 + 2854/7762 + 169/186 + (15/18 books) suttras ### [Dฤซgha Nikฤya](https://en.wikipedia.org/wiki/D%C4%ABgha_Nik%C4%81ya) (""Collection of Long Discourses"") - 34 suttras - Silakkhandha-vagga โ _The Division Concerning Morality_ (suttas 1-13) - Maha-vagga โ _The Great Division_ (suttas 14-23) - Patika-vagga โ _The Patika Division_ (suttas 24-34) ### [Majjhima Nikฤya](https://en.wikipedia.org/wiki/Majjhima_Nik%C4%81ya) (""Collection of Middle-length Discourses"") - 152 or 222 suttras - 222 sลซtras (Sarvฤstivฤda school) - 152 suttas in the Pฤli Majjhima Nikฤya, the version I analyzed ### [Saแนyutta Nikฤya](https://en.wikipedia.org/wiki/Sa%E1%B9%83yutta_Nik%C4%81ya) (""Connected Discourses"" or ""Kindred Sayings"") - 2854 to 7762 suttras - Burmese edition: 2854 suttras - Pali Text Society edition: 2889 suttras - Bhikkhu Bodhi in his translation: 2904 - Rupert Gethin: 6696 suttras - Sinhalese edition: 7656 suttras - Bodhi commentaries: 7762 suttras - The suttas/sลซtras are grouped into five vargas/vaggas, or sections. Each varga/vagga is further divided into samyuttas/saแนyuktas, or chapters: - Sagatha-vagga (SN1-11) - Nidana-vagga (SN12-21) - Khandha-vagga (SN22-34) - Salayatana-vagga (SN35-44) - Maha-vagga - SN 45 the Noble Eightfold Path - SN 46 the Seven Factors of Enlightenment - SN 47 the Four Establishment of Mindfulness - SN 48 the Faculties - SN 49 the Four Right Striving - SN 50 the Five Powers - SN 51-55 - SN 56 the Truths ### [Aแนguttara Nikฤya](https://en.wikipedia.org/wiki/A%E1%B9%85guttara_Nik%C4%81ya) (aแนguttaranikฤya; lit. 'Increased-by-One Collection', also translated ""Gradual Collection"" or ""Numerical Discourses"") - 11 nipatos, 186 or 169 or thousands os suttras - Ekakanipฤto (The Book of Ones) 20 suttras? - Dukanipฤto (The Book of Twos) 19 - Tikanipฤto (The Book of Threes) 18 - Catukkanipฤto (The Book of Fours) 28 - Paรฑcakanipฤto (The Book of Fives) 29 - Chakkanipฤto (The Book of Sixes) 13 - Sattakanipฤto (The Book of Sevens) 11 - Aแนญแนญhakanipฤto (The Book of Eights) 11 - Navakanipฤto (The Book of Nines) 10 - Dasakanipฤto (The Book of Tens) 23 - Ekฤdasako nipฤto (The Book of Elevens) 4 ### [Khuddaka Nikฤya](https://en.wikipedia.org/wiki/Khuddaka_Nik%C4%81ya) (lit. 'Minor Collection') - 15 to 18 books - [Khuddakapatha](https://en.wikipedia.org/wiki/Khuddakap%C4%81%E1%B9%ADha) (Pali for ""short passages"") - 9 discourses - [Dhammapada](https://en.wikipedia.org/wiki/Dhammapada) - 423 verses in 26 chapters, most widely read - [Udana](https://en.wikipedia.org/wiki/Ud%C4%81na) - 8 chapters, 80 utterances - [Itivuttaka](https://en.wikipedia.org/wiki/Itivuttaka) - 112 short teachings - [Sutta Nipata](https://en.wikipedia.org/wiki/Sutta_Nipata) - 5 sections, 70 suttas - Uraga Vagga (""The Chapter on the Serpent"") - 12 suttas - Cลซla Vagga (""The Minor Chapter"") - 14 suttas - Mahฤ Vagga (""The Great Chapter"") - 12 suttas - Atthaka Vagga ""The Chapter of Octads"" - 16 suttas - Parayana Vagga (""The Chapter on the Way Beyond"") - 16 suttas - [Vimanavatthu](https://en.wikipedia.org/wiki/Vim%C4%81navatthu) - 83 short stories - [Petavatthu](https://en.wikipedia.org/wiki/Petavatthu) - 51 verses, hungry ghost realm? - [Theragatha](https://en.wikipedia.org/wiki/Theragatha) (Verses of the Elder Monks) - 264 poems, 21 chapters, 1279 verses (claim: 1360) - [Therigatha](https://en.wikipedia.org/wiki/Ther%C4%ABg%C4%81th%C4%81) (Verses of the Elder Nuns) - 73 poems, 16 chapters, 494 verses - [Jataka](https://en.wikipedia.org/wiki/Jataka_tales) - 550 fables that should teach virtues, but taken literal - [Niddesa](https://en.wikipedia.org/wiki/Niddesa) - two commentaries by Sariputta: Maha Niddesa on the Atthaka Vagga, Cula Niddesa on the Parayana Vagga and Khaggavisana Sutta - [Patisambhidamagga](https://en.wikipedia.org/wiki/Pa%E1%B9%ADisambhid%C4%81magga) - 30 chapters, the first is about knowledge - [Apadana](https://en.wikipedia.org/wiki/Apad%C4%81na) - 589-603 poems - [Buddhavamsa](https://en.wikipedia.org/wiki/Buddhava%E1%B9%83sa) (also known as the Chronicle of Buddhas) - 29 chapters - 24/28 Buddhas that preceded Gautama several billion years ago, some while riding on an elephant, being 26 meters large and having a stupa 307 km high ([Anomadassi](https://en.wikipedia.org/wiki/Anomadassi)) and living 100,000 years ([Tissa](https://en.wikipedia.org/wiki/Tissa_Buddha)) and having 6.8 million disciples ([Vipassฤซ](https://en.wikipedia.org/wiki/Vipassฤซ)) - [Cariyapitaka](https://en.wikipedia.org/wiki/Cariy%C4%81pi%E1%B9%ADaka) - 35 stories, spanning 356 to 371 verses - [Nettipakarana or Netti](https://en.wikipedia.org/wiki/Nettipakara%E1%B9%87a) (included in Burmese and Sinhalese editions, but not in Thai edition) - 2 divisions, 3 subsections, with 16 hฤras, 5 naya and 18 mลซlapadas, repeated in second subsection, expanded in third - [Petakopadesa](https://en.wikipedia.org/wiki/Pe%E1%B9%ADakopadesa) (included in Burmese and Sinhalese editions, but not in Thai edition) - 8 sections - [Milindapaรฑha](https://en.wikipedia.org/wiki/Milinda_Panha) (lit. 'Questions of Milinda', included in Burmese edition, but not in Sinhalese and Thai editions) - 2 volumes? ## [Abhidhamma Piแนญaka](https://en.wikipedia.org/wiki/Abhidhamma_Pi%E1%B9%ADaka) (_Basket of Higher Doctrine_) - 7 books - [Dhammasaแนgaแนฤซ](https://en.wikipedia.org/wiki/Dhammasa%E1%B9%85ga%E1%B9%87%C4%AB) (-saแนgaแนi or -saแนgaแนฤซ) - [Vibhaแนga](https://en.wikipedia.org/wiki/Vibha%E1%B9%85ga) (vibhaแนga) - [Dhฤtukathฤ](https://en.wikipedia.org/wiki/Dh%C4%81tukath%C4%81) (dhฤtukathฤ) - [Puggalapaรฑรฑatti](https://en.wikipedia.org/wiki/Puggalapa%C3%B1%C3%B1atti) (-paรฑรฑatti) - [Kathฤvatthu](https://en.wikipedia.org/wiki/Kath%C4%81vatthu) (kathฤ-) - [Yamaka](https://en.wikipedia.org/wiki/Yamaka) - [Paแนญแนญhฤna](https://en.wikipedia.org/wiki/Pa%E1%B9%AD%E1%B9%ADh%C4%81na) (paแนญแนญhฤna) - 24 types of conditional relations (the Buddhist belief that causality โ not a Creator deity โ is the basis of existence) on some 1000 pages ## Size of the 3 baskets and their main 16 Collections I use the Pali text to estimate the pages needed to print the complete text 80x50 characters per page (Consolas 11pt on A4 with 17/19mm border) on **7009 pages**, in detail: | Basket | [Vinaya Piแนญaka](https://en.wikipedia.org/wiki/Vinaya_Pi%E1%B9%ADaka) | [Sutta Pitaka](https://en.wikipedia.org/wiki/Sutta_Pi%E1%B9%ADaka) - 5 Nikฤyas | [Abhidhamma Piแนญaka](https://en.wikipedia.org/wiki/Abhidhamma_Pi%E1%B9%ADaka) | |-----------|------------------------|--------------------------|----------------------------------| | Content | (Basket of Discipline) | (Basket of Discourse) | (Basket of Higher Doctrine) | | Pages | 1031 | 3872 | 2106 | | Including | bu, bi, kd, pvr | dn, mn, sn, an, kn | ds, vb, dt, pp, lv, ya, patthana | ![Size of Tripitaka based on pages](docs/size_tripitaka.png) # More details in comparison | code | name | pages | content | |----------|---------------------|-------|----------------------------------------------------------------------------------------------------| | bu | [Bhikkhupฤtimokkha](https://en.wikipedia.org/wiki/P%C4%81%E1%B9%ADimokkha) | 309 | 227 rules for monks (bhikkhus) in the [Pฤแนญimokkha](https://en.wikipedia.org/wiki/P%C4%81%E1%B9%ADimokkha), [Suttavibhaแนga](https://en.wikipedia.org/wiki/Suttavibha%E1%B9%85ga) (โrule analysisโ) | | bi | Bhikkhunฤซpฤtimokkha | 108 | 311 rules for nuns (bhikkhuแนฤซs) | | kd | [Khandhaka](https://en.wikipedia.org/wiki/Khandhaka) | 452 | 22 chapters on various topics | | pvr | [Parivฤra](https://en.wikipedia.org/wiki/Pariv%C4%81ra) | 162 | 19 chapters with analyses of rules from various points of view | | ds | [Dhammasaแนgaแนฤซ](https://en.wikipedia.org/wiki/Dhammasa%E1%B9%85ga%E1%B9%87%C4%AB) | 124 | lit. 'Collection of Dhammas' | | vb | [Vibhaแนga](https://en.wikipedia.org/wiki/Vibha%E1%B9%85ga) | 200 | 18 chapters: aggregate, sense bases, elements, truth, faculties, dependent origination and more | | dt | [Dhฤtukathฤ](https://en.wikipedia.org/wiki/Dh%C4%81tukath%C4%81) | 40 | ""Discourse on Elements"" in the form of questions and answers, grouped into 14 chapters | | pp | [Puggalapaรฑรฑatti](https://en.wikipedia.org/wiki/Puggalapa%C3%B1%C3%B1atti) | 35 | Classifications of persons, which are arranged numerically, from 1-fold to 10-fold. | | kv | [Kathฤvatthu](https://en.wikipedia.org/wiki/Kath%C4%81vatthu) | 188 | ""Points of Controversy"", documents over 200 points of contention. | | ya | [Yamaka](https://en.wikipedia.org/wiki/Yamaka) | 446 | เคฏเคฎเค; Pali for ""pairs"", text on applied logic and analysis | | patthana | [Paแนญแนญhฤna](https://en.wikipedia.org/wiki/Pa%E1%B9%AD%E1%B9%ADh%C4%81na) | 1073 | 24 types of conditional relations, causality is the basis for existence | | dn | [Dฤซgha Nikฤya](https://en.wikipedia.org/wiki/D%C4%ABgha_Nik%C4%81ya) | 312 | ""Collection of Long Discourses"" - 34 suttras | | mn | [Majjhima Nikฤya](https://en.wikipedia.org/wiki/Majjhima_Nik%C4%81ya) | 573 | ""Collection of Middle-length Discourses"" - 152 or 222 suttras | | sn | [Saแนyutta Nikฤya](https://en.wikipedia.org/wiki/Sa%E1%B9%83yutta_Nik%C4%81ya) | 620 | ""Connected Discourses"" or ""Kindred Sayings"" - 2854 to 7762 suttras | | an | [Aแนguttara Nikฤya](https://en.wikipedia.org/wiki/A%E1%B9%85guttara_Nik%C4%81ya) | 709 | lit. 'Increased-by-One Collection', also translated ""Gradual Collection"" or ""Numerical Discourses"" | | kn | [Khuddaka Nikฤya](https://en.wikipedia.org/wiki/Khuddaka_Nik%C4%81ya) | 1658 | lit. 'Minor Collection' - 15 to 18 books, incl. [Dhammapada](https://en.wikipedia.org/wiki/Dhammapada) and [Buddhavamsa](https://en.wikipedia.org/wiki/Buddhava%E1%B9%83sa) (also known as the Chronicle of Buddhas) | | sum | number of pages: | 7009 | with text 80x50 characters per A4 page (Consolas 11pt, 17/19mm border) | ## King-James-Bible Since I have the complete bible in well organized and structured 66 JSON files available it was a question of a few hours to get some statistics out of it. Let's start with a visualization of the size of the 66 books - some smaller ones are not labeled: ![pie chart kjv](docs/size_kjv.png) We can now break down each book into the number of chapteres, verses, sentences, words, characters and pages needed in a print: | book | chapters | verses | sentences | words | letters | pages | |-----------------|----------|--------|-----------|--------|---------|-------| | Genesis | 50 | 1,533 | 1,716 | 38,290 | 151,857 | 50 | | Exodus | 40 | 1,213 | 1,288 | 32,695 | 131,775 | 43 | | Leviticus | 27 | 859 | 872 | 24,546 | 98,922 | 33 | | Numbers | 36 | 1,288 | 1,349 | 32,928 | 137,901 | 45 | | Deuteronomy | 34 | 959 | 999 | 28,387 | 114,018 | 37 | | Joshua | 24 | 658 | 699 | 18,862 | 78,372 | 26 | | Judges | 21 | 618 | 753 | 18,985 | 76,851 | 25 | | Ruth | 4 | 85 | 114 | 2,577 | 10,000 | 4 | | 1 Samuel | 31 | 810 | 1,065 | 25,066 | 100,211 | 33 | | 2 Samuel | 24 | 695 | 915 | 20,620 | 82,497 | 27 | | 1 Kings | 22 | 816 | 951 | 24,538 | 98,713 | 32 | | 2 Kings | 25 | 719 | 943 | 23,538 | 93,631 | 31 | | 1 Chronicles | 29 | 942 | 1,054 | 20,383 | 86,625 | 29 | | 2 Chronicles | 36 | 822 | 934 | 26,093 | 109,303 | 35 | | Ezra | 10 | 280 | 294 | 7,445 | 31,705 | 11 | | Nehemiah | 13 | 406 | 466 | 10,489 | 44,705 | 14 | | Esther | 10 | 167 | 205 | 5,645 | 23,748 | 8 | | Job | 42 | 1,070 | 1,230 | 18,149 | 73,266 | 24 | | Psalms | 150 | 2,461 | 2,664 | 42,727 | 173,959 | 58 | | Proverbs | 31 | 915 | 946 | 15,046 | 62,676 | 21 | | Ecclesiastes | 12 | 222 | 242 | 5,588 | 21,972 | 7 | | Song of Solomon | 8 | 117 | 134 | 2,666 | 10,548 | 4 | | Isaiah | 66 | 1,292 | 1,474 | 37,086 | 150,992 | 50 | | Jeremiah | 52 | 1,364 | 1,564 | 42,720 | 174,386 | 57 | | Lamentations | 5 | 154 | 166 | 3,421 | 14,173 | 4 | | Ezekiel | 48 | 1,273 | 1,364 | 39,423 | 160,049 | 53 | | Daniel | 12 | 357 | 384 | 11,605 | 48,438 | 16 | | Hosea | 14 | 197 | 215 | 5,178 | 21,122 | 7 | | Joel | 3 | 73 | 78 | 2,035 | 8,359 | 2 | | Amos | 9 | 146 | 173 | 4,220 | 16,989 | 6 | | Obadiah | 1 | 21 | 25 | 674 | 2,823 | 1 | | Jonah | 4 | 48 | 62 | 1,321 | 5,087 | 1 | | Micah | 7 | 105 | 124 | 3,155 | 12,719 | 5 | | Nahum | 3 | 47 | 56 | 1,286 | 5,423 | 1 | | Habakkuk | 3 | 56 | 71 | 1,484 | 6,217 | 2 | | Zephaniah | 3 | 53 | 55 | 1,620 | 6,643 | 3 | | Haggai | 2 | 38 | 46 | 1,130 | 4,400 | 1 | | Zechariah | 14 | 211 | 239 | 6,445 | 25,549 | 8 | | Malachi | 4 | 55 | 87 | 1,782 | 7,125 | 3 | | Matthew | 28 | 1,071 | 1,221 | 23,717 | 96,656 | 32 | | Mark | 16 | 678 | 777 | 15,192 | 61,338 | 20 | | Luke | 24 | 1,151 | 1,310 | 25,999 | 104,336 | 35 | | John | 21 | 879 | 1,034 | 19,146 | 75,533 | 25 | | Acts | 28 | 1,007 | 1,099 | 24,277 | 101,726 | 33 | | Romans | 16 | 433 | 536 | 9,454 | 39,320 | 13 | | 1 Corinthians | 16 | 437 | 528 | 9,474 | 37,943 | 13 | | 2 Corinthians | 13 | 257 | 287 | 6,089 | 24,982 | 8 | | Galatians | 6 | 149 | 162 | 3,092 | 12,652 | 4 | | Ephesians | 6 | 155 | 158 | 3,030 | 12,832 | 5 | | Philippians | 4 | 104 | 111 | 2,185 | 9,031 | 3 | | Colossians | 4 | 95 | 100 | 1,983 | 8,422 | 2 | | 1 Thessalonians | 5 | 89 | 92 | 1,837 | 7,543 | 3 | | 2 Thessalonians | 3 | 47 | 49 | 1,024 | 4,277 | 1 | | 1 Timothy | 6 | 113 | 119 | 2,251 | 10,068 | 3 | | 2 Timothy | 4 | 83 | 89 | 1,667 | 7,246 | 3 | | Titus | 3 | 46 | 52 | 898 | 4,067 | 1 | | Philemon | 1 | 25 | 26 | 430 | 1,817 | 1 | | Hebrews | 13 | 303 | 319 | 6,915 | 29,336 | 9 | | James | 5 | 108 | 134 | 2,307 | 9,433 | 3 | | 1 Peter | 5 | 105 | 116 | 2,478 | 10,589 | 4 | | 2 Peter | 3 | 61 | 66 | 1,557 | 6,940 | 2 | | 1 John | 5 | 105 | 126 | 2,519 | 9,848 | 3 | | 2 John | 1 | 13 | 17 | 298 | 1,204 | 1 | | 3 John | 1 | 14 | 18 | 294 | 1,250 | 0 | | Jude | 1 | 25 | 27 | 609 | 2,812 | 1 | | Revelation | 22 | 404 | 460 | 12,003 | 48,251 | 16 | | sum | 1,189 | 31,102 | 35,049 | 790,573 | 3,223,201 | 1061 | ## Pali edition of the Tripitaka ![pie chart tripitaka](docs/size_kuthodaw.png) We can now break down each basket into the number of chapteres, verses, sentences, words, characters and pages needed in a print: | | json | folders | books | chapters | verses | sentences | words | characters | pages | html fix | size | |-------------------|:----:|:-------:|:-----:|:--------:|:------:|:---------:|:---------:|:----------:|:-----:|:--------:|:----------:| | Vinaya Piแนญaka | 422 | 18 | 412 | 8 | 4,259 | 73,833 | 450,529 | 3,363,421 | 1,039 | 0 | 4.7 MByte | | Abhidhamma Piแนญaka | 1102 | 64 | 81 | 1021 | 42,558 | 118,211 | 864,497 | 6,884,073 | 2,102 | 1816 | 9.5 MByte | | Sutta Pitaka | 5749 | 110 | 2289 | 4244 | 52,750 | 289,950 | 1,692,792 | 12,192,330 | 3,872 | 331 | 17.2 MByte | | sum | 7273 | 192 | 2782 | 5273 | 99,567 | 481,994 | 3,007,818 | 22,439,824 | 7,013 | 2147 | 31.4 MByte | I had to remove thousands of ` ` and ` ` tags in the json files. Now even more details: ### Vinaya Piแนญaka (_Basket of Discipline_) - [Suttavibhaแนga](https://en.wikipedia.org/wiki/Suttavibha%E1%B9%85ga) (Pali for ""rule analysis"") - 347 JSON files, 2.8 MByte - [Pฤแนญimokkha](https://en.wikipedia.org/wiki/P%C4%81%E1%B9%ADimokkha) 227 rules for monks (bhikkhus) and 311 for nuns (bhikkhuแนฤซs) - Bhikkhupฤtimokkha __bu__ 225 verses, 754 lines, 75 kByte (total 222 JSON) - Mahฤvibhaแนga - Adhikaraแนasamatha __bu-vb-as__ 5 verses, 33 lines, 2 kByte - 7 subfolder __bu-vb__ ay(2), np(30), pc(92), pd(4), pj(4), sk(75), ss(13) - total 220 JSON files, 2 MByte - Bhikkhunฤซpฤtimokkhapฤแธทi __bi__ 333 verses, 947 lines, 100 kByte (total 127 JSON) - Bhikkhunivibhaแนga - Adhikaraแนasamatha __bi-vb-as__ 5 verses, 33 lines, 2 kByte - 6 Subfolder __bi-vb__ np(12), pc(94), pd(2), pj(5), sk(2), ss(10) - total 125 JSON files, 595 kByte - [Khandhaka](https://en.wikipedia.org/wiki/Khandhaka) __kd__ 22 chapters, 22 JSON files, 2.9 MByte - Mahavagga has 10 chapters - Cullavagga has 12 chapters - [Parivฤra](https://en.wikipedia.org/wiki/Pariv%C4%81ra) __pvr__ (19 or 21 chapters) - 12784 lines, 2475 verses, 51 JSON files, 1.1 MByte - 1.1.0 to 1.1.332 - 2212 lines, 332 verses - 1.2.0 to 1.16.4 - 1184 lines, 329 verses - 2.1.0 to 2.1.186 - 1401 lines, 186 verses - 2.2.0 to 2.16.6 - 923 lines, 224 verses - 3.0 to 3.76 - 295 lines, 76 verses - 4.0 to 21.87 - 6769 lines, 1328 verses | Vinaya Piแนญaka | json | folders | books | chapters | verses | sentences | words | characters | pages | bytes | |---------------|:----:|:-------:|:-----:|:--------:|:------:|:---------:|:-------:|:----------:|:-----:|:---------:| | bu | 222 | 8 | 228 | 0 | 729 | 22,738 | 136,465 | 978,831 | 309 | 1,369,715 | | bi | 127 | 7 | 141 | 0 | 593 | 8,198 | 42,881 | 326,823 | 108 | 456,266 | | kd | 22 | 1 | 22 | 0 | 462 | 29,866 | 206,774 | 1,532,105 | 452 | 2,068,895 | | pvr | 51 | 1 | 21 | 30 | 2,475 | 13,031 | 64,409 | 525,662 | 162 | 741,603 | ### Sutra Pitaka - 5 Nikฤyas - 34 + 152/222 + 2854/7762 + 169/186 + (15/18 books) suttras - Dฤซgha Nikฤya (""Collection of Long Discourses"") - 34 suttras - Majjhima Nikฤya (""Collection of Middle-length Discourses"") - 152 or 222 suttras - Saแนyutta Nikฤya (""Connected Discourses"" or ""Kindred Sayings"") - 2854 to 7762 suttras - Aแนguttara Nikฤya (aแนguttaranikฤya; lit. 'Increased-by-One Collection', also translated ""Gradual Collection"" or ""Numerical Discourses"") - 11 nipatos, 186 or 169 or thousands os suttras - Khuddaka Nikฤya (lit. 'Minor Collection') - 15 to 18 books ### Abhidhamma Piแนญaka (_Basket of Higher Doctrine_) - 7 books - Dhammasaแนgaแนฤซ (-saแนgaแนi or -saแนgaแนฤซ) - Vibhaแนga (vibhaแนga) - Dhฤtukathฤ (dhฤtukathฤ) - Puggalapaรฑรฑatti (-paรฑรฑatti) - Kathฤvatthu (kathฤ-) - Yamaka - [Paแนญแนญhฤna](https://en.wikipedia.org/wiki/Pa%E1%B9%AD%E1%B9%ADh%C4%81na) (paแนญแนญhฤna) 24 types of conditional relations (the Buddhist belief that causality โ not a Creator deity โ is the basis of existence) on some 1000 pages | Abhidhamma Piแนญaka | json | folders | books | chapters | verses | sentences | words | characters | pages | html fix | bytes | |-------------------|:----:|:-------:|:-----:|:--------:|:------:|:---------:|:-------:|:----------:|:-----:|:--------:|:---------:| | ds | 21 | 3 | 2 | 19 | 2,158 | 8,671 | 53,641 | 405,137 | 124 | 328 | 578,026 | | dt | 19 | 3 | 2 | 17 | 643 | 3,131 | 17,945 | 131,336 | 40 | 0 | 177,070 | | kv | 219 | 24 | 23 | 196 | 2,519 | 19,640 | 85,076 | 616,259 | 188 | 0 | 877,996 | | patthana | 728 | 25 | 24 | 704 | 20,221 | 47,896 | 429,338 | 3,534,375 | 1,073 | 1,488 | 4,830,994 | | pp | 20 | 3 | 2 | 18 | 550 | 1,863 | 15,120 | 112,387 | 35 | 0 | 154,532 | | vb | 18 | 1 | 18 | 0 | 3,258 | 13,012 | 84,217 | 645,914 | 200 | 0 | 912,905 | | ya | 77 | 11 | 10 | 67 | 13,209 | 23,998 | 179,160 | 1,438,665 | 446 | 0 | 1,951,786 | ## Sources Similar projects have been done with the bible and having all 1189 chapters in JSON files, like [this one from Arul John](https://github.com/aruljohn/Bible-kjv) of the King James version. ## Tripitaka sources - [tripitaka.online](https://tripitaka.online/) only in Sinhala - [suttacentral](https://suttacentral.net/?lang=en) by [Bhante Sujato](https://en.wikipedia.org/wiki/Bhante_Sujato) in English, [Pali from VRI](https://discourse.suttacentral.net/t/what-is-the-difference-between-the-pali-text-of-the-vri-and-that-of-the-mahasa-giti/2667) - [theravada.vn](https://theravada.vn/tipitaka-english/) Vietnamese site with 541 English, 2722 Roman and 2034 Vietnamese suttras"
https://github.com/kreier/communicationspeed/blob/main/README.md,"# Communication speed ![GitHub License](https://img.shields.io/github/license/kreier/communicationspeed) ![GitHub Release](https://img.shields.io/github/v/release/kreier/communicationspeed) Most common to human communication is to **speak** and **listen** to words. Many use this form of communication even in asynchronous media like WhatsApp. But you can also **write** your message as text and **read** it silently. What are the *differences in speed*, advantages and disadvantages? ![speed comparison](docs/speed_comparison.svg) - 228 wpm reading ([source](https://books.google.com.kh/books?id=cEFKjwEACAAJ&q=ultimate+study+method&redir_esc=y)) - 160 wpm listening ([audiobook recommendation](https://en.wikipedia.org/wiki/Words_per_minute), result of [IOVS study](https://iovs.arvojournals.org/article.aspx?articleid=2166061) 2012) - 142 wpm speaking (reading the entire Bible in English, calculation below) - 80+ wpm typing on a keyboard (advanced typist: according to ASAP - American Society of Administrative Professionals) - 71 wpm typing on a keyboard (my speed) - 40 wpm typing on a keyboard (general population [according to ASAP](https://www.asaporg.com/efficiency-skills/average-words-per-minute-typing-how-fast-is-fast-enough) 2023) - 36 wpm typing on a smartphone (again: [HCI conference](https://userinterfaces.aalto.fi/typing37k/) 2019, Aalto university), up to 42 wpm with autocorrect - 20 wpm Morse code - 13 wpm handwriting Short conclusion: Handwriting is very slow! And sending an audio message (160) is 4x faster than typing it on the smartphone (36). But reading (228) a message is 42% faster than listening (160) to the same message. And searching for specific information inside a message is magnitudes faster. For important messages with referencable information the combination writing/reading seems more efficient and less error prone. It might also help to order thoughts and to be concise. ## Speaking and listening Over the course of 92.5 hours (5552 minutes) listening to all words written in the bible with 31077 verses, 42032 sentences, 789,071 words and 3,380,746 letters in English {from [kreier.github.io/tripitaka/bible/](https://kreier.github.io/tripitaka/bible/)) I determined an average speed of: ![average wpm](docs/wpm_speaking.png) ## Writing - [typing on a keyboard](type/) You can test yourself on pages like [Monkeytype](https://monkeytype.com/), [Typeracer](https://play.typeracer.com/) or [Nitrotype](https://www.nitrotype.com/). My average speed is 72 wpm, about 50% of the speaking and listening speed. My journey with mechanical keyboards began 1988 - see [project here on github](https://kreier.github.io/keyboard/). And the paper from the Aalto university found that Autocorrect actually can help improve your typing speed, as well as using two fingers: ## Reading silently Here I need to have a test. But several test have been conducted already, and according to Wikipedia: [words per minute](https://en.wikipedia.org/wiki/Words_per_minute) in English the speed is about 228 wpm. And for Latin-based languages that equivalent to 1000 characters per minute. ## History This project is lingering in my mind for some time. Now put some numbers and facts to this question. ### 2000 Handwriting German with fountain pen I started to write a lot again when starting to study at the Humboldt University. After a few weeks my hand hurt because of the ball pens I was using. Soon I moved to a fountain pen and the stress on my palm and wrist was gone. At the same time I started to take notes for public talks at congregation meetings. ### 2003-2004, 2007-2008 Writing in Russian While in Russia I continued to take notes by hand and writing with a fountain pen. ### 2016 Handwriting in English and Vietnamese Moving to Vietnam I continued to take notes in meetings by hand, now in English. Sometimes I even started in Vietnamese. ### 2019 Handwriting on the iPad in English with Nebo The [Apple Pencil](https://en.wikipedia.org/wiki/Apple_Pencil) was introduced 2015 with the iPad Pro. But until 2018 I used my iPad Air 2. Only the Pro iPads and newer iPads from 2018 started supporting the digital Pen. I tried a six-generation iPad but the gap between pen and display left me disappointed. So I got a 10.5 iPad Pro and started taking notes with the pen. This lasted 2018 until the International Convention in Berlin. I used Nebo with text detection. ### 2019 Move to typing Having a physical keyboard connected to the iPad Pro from time to time I started to take notes by typing. Very fast I realized how much faster I was. Only 6 years later I put some numbers to this observation: 13 wpm vs. 70 wpm - about 5x as fast! ### 2025 Voice to text It's long working with the cloud, in part on-device and with ChatGPT now offers translation, too. Maybe I should really automate this process. I started to use voice-to-text quite frequently in combination with Google translate. It's faster than typing the English sentence, and then Google can translate it to Vietnamese. With a little training the error rate in understanding my English get's very low."
https://github.com/kreier/saiht-parser/blob/main/README.md,"# Parser for saiht.de ![GitHub License](https://img.shields.io/github/license/kreier/saiht-blog) ![GitHub Release](https://img.shields.io/github/v/release/kreier/saiht-blog) Framework to generate the saiht.de/travel and saiht.de/projects structure in English and German. See more [following this link](./html/). ## Structure This affects the content of the folder `/blog/` of `https://saiht.de`. The content is found in the `html` directory of this repository. ### Guiding principles - Each event is inside a folder by the structure `/YYYY/MM/DD` including all images, text files, PDF documents, `csv` data or else - The text content is written in `README.md` and/or `LIESMICH.md` inside the same folder - English is preferred and used by the `parse_md.py` program to create an `index.html` file in the same folder - Additionally there is an article created in a folder `/en/YYYY-MM-DD_title_of_the_event_-_English_or_German_-_here/` with `index.html` and links to the images with `../../YYYY/MM/DD/image.jpg` relative links - Each page has a link to the next and previous article. Articles in the `/YYYY/MM/DD` folders link to articles inside this folder, articles in the `/de/ ` or `/en/` folder link to respective articles in their respective folders. - A share button links to the language-specific link - A fourth article is created with an `index.html` at '/YYYY/MM/DD/title_of_the_event_in_lowercase/` folder - Three overview sites are created: `/blog/index.html`, `/blog/de/index.html` and `/blog/en/index.html` with an overview of how many articles in total in the respective language are available. Below is a list of all the articles, sorted by date and separated by year in their respective language and folder - Logfiles of the compilation are held in the `/log` folder as `log/YYYY-MM-DD_log.txt` with version, number of conversions, etc. ### Example Let's say I visit the botanic garden in Nairobi on February 29th, 2000. All images for this post are located in `/2000/02/29` folder, for example the `garden.jpg` and the `banner.jpg`. The German article would be written in `LIESMICH.md` while the English would be in `README.md`. From this content, a file `index.html` is created, preferable in English. If not present, the German article will be used for the `index.html`. The first line of the markdown files contains the title, so there is `# Visit to the Botanic Garden in Nairobi on February 29th, 2000 - no leap day!` in the `README.md` and `# Besuch im Botanischen Garten von Nairobi am 29. Februar 2000 - kein Schalttag!` in `LIESMICH.md`. There will be 4 `index.html` generated, and the locations are: - 2000/02/29/ - 2000/02/29/visit_to_the_botanic_garden_in_nairobi_on_february_29th_2000_-_no_leap_day/ - en/2000-02-29_visit_to_the_botanic_garden_in_nairobi_on_february_29th_2000_-_no_leap_day/ - de/2000-02-29_besuch_im_botanischen_garten_von_nairobi_am_29_februar_2000_-_kein_schalttag/ The comma, dot and exclamation mark are removed for the folder names, and all uppercase letters are changed to lowercase. The spaces are replaced by an underscore character. This should at least work for German and English. Vietnamese and Russian are on my todo list. ## History ### 1999 Static websites The website [saiht.de](https://saiht.de) exist since the end of 1999. And it is a special task to keep it updated. I tried some database founded approaches like wordpress, but exporting data and articles to a new platform was always a little hassle, and it does not work offline. In the end, I just want some static webpages that work online and offline in a structured manner. ### 2007 Some automatic generated parts with JavaScript The image on the right side of the start page of the legacy site from saiht.de (see [saiht.de/legacy](https://saiht.de/legacy) changes daily with JavaScript. Also the ""Spruch des Tages"" (quote of the day) changes randomly with Javascript. ### 2008 WordPress with PHP and MySQL I started with a script language and database approach with Wordpress in 2008. But one day all data was lost by my hosting provider Evanzo, and I had not done an update of the database. The static websites from 1999 I could easily copy with ftp and FileZilla. But the images, blog entries, and database? It's still not a simple ""Drag-and-Drop"" in 2025. ### 2018 GitHub and Markdown I signed up for Github in 2018, and with it got familiar with MarkDown. Soon we used it in class for LaTeX formulas and Jupyter notebook documents, and I liked the plain text approach of storing data. By 2020 I had sufficiently good looking websites with Github pages to meet my needs by translating Markdown files. But as a backbone? This will take time ### 2025 Maybe the blog part with Markdown parsing to HTML In early October 2025 I still thought about parsing saiht.de/blog from Markdown files to index.html files. That's why this repository was created as saiht-blog. But then I got Quartz working with Obsidian and had it creating static html files from my Markdown notes, created with Obsidian. And I got a copy of my old Wordpress notes on hofkoh.de and blog.saiht.de imported to the new saiht.de/blog Wordpress installation. For that reason the landing page for saiht.de will be static, and only saiht.de/travel and saiht.de/projects will be created by parsing Markdown files in this repository. ### 2026 Parsing works Will describe it in 2026. ## Inconsistency in UI frameworks and design By now I have five different look and feels for my saiht.de website: 1. The original frame design from 1999 under [saiht.de/legacy](https://saiht.de/legacy) 2. A responsive HTML5 website for the landing page [saiht.de](https://saiht.de) as well as the two folders [saiht.de/travel](https://saiht.de/travel) and [saiht.de/projects](https://saiht.de/projects) 3. Wordpress with currently the theme Twenty-Twenty Five for the blog under [saiht.de/blog](https://saiht.de/blog) 4. Quartz resembling Obsidian for my diary and other notes under [saiht.de/obsidian](https://saiht.de/obsidian) or [diary.saiht.de](https://diary.saiht.de) 5. All kind of UI styles in the subdomains, see the overview at [saiht.de/x](https://saiht.de/x/)"
https://github.com/kreier/solarmeter/blob/main/README.md,"# Solarmeter [![GitHub release](https://img.shields.io/github/release/kreier/solarmeter.svg)](https://GitHub.com/kreier/solarmeter/releases/) [![MIT license](https://img.shields.io/github/license/kreier/solarmeter)](https://kreier.mit-license.org/) [![pages-build-deployment](https://github.com/kreier/solarmeter/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/solarmeter/actions/workflows/pages/pages-build-deployment) This project continuously measures the output power of a solar cell and a wind generator on the roof of building A. The data is collected in Ho Chi Minh City 2020 and part of an EE (extended essay) in IB Physics at the AISVN. More pictures and descriptions here: https://sites.google.com/ais.edu.vn/solar This is how our outdoor setup with one 500W wind generator and a 60W solar panel looks like. Two smaller panels for ESP32 power and hybrid generator are not shown. ![Setup roof](pic/2020-06-23_roof.jpg) The electronics part in the room below looks like this: ![Setup June 2020](pic/2020-06-12_setup.jpg) And this is a sample data collection from one of the first days: ![data June 11th](pic/2020-06-11_datacollection.png) ## Setup The initial setup from December 2019 requires a Laptop with Vernier software to measure just one data point. The circuit looks like this: ![load circuit for the solar panel and voltage measurement](pic/setup_2020-01-16.jpg) This is the circuit diagram from June 5th, 2020 (last day of school): ![Setup June 2020](pic/20200605_circuit.png) ## Materials We take an ESP32 for measuring and transmitting the data over Wifi. Power will be provided from the solar cell, and have a backup LiPo battery with a JST-PH 2.0 connector. I ordered some setup materials: - [Solar panel 12V 3W 145x145mm](https://www.thegioiic.com/products/tam-nang-luong-mat-troi-3w-12v) enough for ESP32? - [Solar panel 12V 1.5W 115x85mm](https://www.thegioiic.com/products/tam-nang-luong-mat-troi-1-5w-12v) I guess that's what Tom uses - [Solar panel 5V .25W 45x45mm](https://www.thegioiic.com/products/tam-nang-luong-mat-troi-0-25w-5v) small and cheap - sufficient? Without step down converter? - [Step down to 5V](https://www.thegioiic.com/products/mach-giam-ap-usb-ra-5v3a) - [ESP32 with display, USB-C](https://www.lazada.vn/products/i325250821.html) 222000 VND - $ 9.40 with 1.14"" display - TTGO T-Koala with USB-C and battery JST 2.0 interface, red power LED, green to control and blue LiPo charge - Battery 1000 mAh for backup during the night ## Software ``` c // Solar- and windmeter at AISVN v0.10 // 2020/06/17 // // pin: 32, 33, 34, 35, 14, 26, 27, 12, 13 // value: solar, battery, currentA, currentB, load, wind, temp, solar2, LiPo // // submit: solar, battery, current, power, load, wind, temp, solar2, LiPo, bootCount // 0, 1, 2, 3, 4, 5, 6, 7, 8, #include #include #include // WiFi credentials in separate file #include RTC_DATA_ATTR int bootCount = 0; static RTC_NOINIT_ATTR int reg_b; // place in RTC slow memory so available after deepsleep // Replace with your SSID and Password + uncomment // const char* ssid = ""REPLACE_WITH_YOUR_SSID""; // const char* password = ""REPLACE_WITH_YOUR_PASSWORD""; // Replace with your unique IFTTT URL resource + uncomment // const char* resource = ""/trigger/data/with/key/value""; // Maker Webhooks IFTTT const char* server = ""maker.ifttt.com""; // Time to sleep uint64_t uS_TO_S_FACTOR = 1000000; // Conversion factor for micro seconds to seconds // sleep for 2 minutes = 120 seconds uint64_t TIME_TO_SLEEP = 120; // 32, 33, 34, 35, 14, 26, 27, 12, 13 // solar, battery, currentA, currentB, load, wind, temp, solar2, LiPo int voltage[9] = {0, 0, 0, 0, 0, 0, 0, 0, 0}; // all voltages in millivolt int pins[9] = {32, 33, 34, 35, 14, 26, 27, 12, 13}; // solar, battery, curA, curB, load, wind, temp, solar2, LiPo int ledPin = 5; void setup() { pinMode(ledPin, OUTPUT); digitalWrite(ledPin, HIGH); Serial.begin(115200); // determine cause of reset esp_reset_reason_t reason = esp_reset_reason(); Serial.print(""reason "");Serial.println(reason); // get reg_b if reset not from deep sleep if ((reason != ESP_RST_DEEPSLEEP)) { reg_b = READ_PERI_REG(SENS_SAR_READ_CTRL2_REG); Serial.println(""Reading reg b.....""); } Serial.print(""reg b: ""); printf(""%"" PRIu64 ""\n"", reg_b); delay(50); digitalWrite(ledPin, LOW); bootCount++; delay(1000); measureVoltages(); digitalWrite(ledPin, HIGH); initWifi(); makeIFTTTRequest(); digitalWrite(ledPin, LOW); // enable timer deep sleep esp_sleep_enable_timer_wakeup(TIME_TO_SLEEP * uS_TO_S_FACTOR); Serial.println(""Going to sleep now""); // start deep sleep for 120 seconds (2 minutes) esp_deep_sleep_start(); } void loop() { // sleeping so wont get here } // Establish a Wi-Fi connection with your router void initWifi() { Serial.print(""Connecting to: ""); Serial.print(ssid); WiFi.begin(ssid, password); int timeout = 10 * 4; // 10 seconds while(WiFi.status() != WL_CONNECTED && (timeout-- > 0)) { delay(250); Serial.print("".""); } Serial.println(""""); if(WiFi.status() != WL_CONNECTED) { Serial.println(""Failed to connect, going back to sleep""); } Serial.print(""WiFi connected in: ""); Serial.print(millis()); Serial.print("", IP address: ""); Serial.println(WiFi.localIP()); } // Make an HTTP request to the IFTTT web service void makeIFTTTRequest() { Serial.print(""Connecting to ""); Serial.print(server); WiFiClient client; int retries = 5; while(!!!client.connect(server, 80) && (retries-- > 0)) { Serial.print("".""); } Serial.println(); if(!!!client.connected()) { Serial.println(""Failed to connect...""); } Serial.print(""Request resource: ""); Serial.println(resource); String jsonObject = String(""{\""value1\"":\"""") + voltage[0]/1000.0 + ""|||"" + voltage[1]/1000.0 + ""|||"" + voltage[2]/1000.0 + ""\"",\""value2\"":\"""" + voltage[3]/1000.0 + ""|||"" + voltage[4]/1000.0 + ""|||"" + voltage[5]/1000.0 + ""\"",\""value3\"":\"""" + voltage[6]/10.0 + ""|||"" + voltage[7]/1000.0 + ""|||"" + voltage[8]/1000.0 + ""|||"" + bootCount + ""\""}""; client.println(String(""POST "") + resource + "" HTTP/1.1""); client.println(String(""Host: "") + server); client.println(""Connection: close\r\nContent-Type: application/json""); client.print(""Content-Length: ""); client.println(jsonObject.length()); client.println(); client.println(jsonObject); int timeout = 5 * 10; // 5 seconds while(!!!client.available() && (timeout-- > 0)){ delay(100); } if(!!!client.available()) { Serial.println(""No response...""); } while(client.available()){ Serial.write(client.read()); } Serial.println(""\nclosing connection""); client.stop(); } void measureVoltages() { WRITE_PERI_REG(SENS_SAR_READ_CTRL2_REG, reg_b); // only needed after deep sleep SET_PERI_REG_MASK(SENS_SAR_READ_CTRL2_REG, SENS_SAR2_DATA_INV); Serial.print("" ** Voltages measured: ""); for(int i = 0; i < 9; i++) { // multisample 100x to reduce noise - 9.5 microseconds x 100 = 1ms per voltage voltage[i] = 0; for(int multi = 0; multi < 100; multi++) { voltage[i] += analogRead( pins[i] ); } voltage[i] = voltage[i] / 100; Serial.print(voltage[i]); Serial.print("" ""); } // conversion to voltage prior to voltage divider // pin: 32, 33, 34, 35, 14, 26, 27, 12, 13 // value: solar, battery, currentA, currentB, load, wind, temp, solar2, LiPo // // submit: solar, battery, current, power, load, wind, temp, solar2, LiPo, bootCount // 0, 1, 2, 3, 4, 5, 6, 7, 8, voltage[0] = int((4096 - voltage[0]) * 7.52 - 1000); // pin32 solar voltage divider 10k : 1.2 k Ohm 1:1 if(voltage[0] < 0) voltage[0] = 0; voltage[1] = int((4096 - voltage[1]) * 7.52 - 1000); // pin33 battery voltage divider 10k : 1.2 k Ohm 1:1 voltage[2] = int((voltage[3] - voltage[2]) * 5.79); // voltage difference pin35 - pin34 x 8.4 is corrent (x0.804) voltage[3] = int(voltage[2] * voltage[0] / 1000); voltage[4] = int((4096 - voltage[4]) * 7.52 - 1000); // pin14 load voltage divider 10k : 1.2 k Ohm 1:1 if(voltage[4] < 0) voltage[4] = 0; voltage[5] = int((4096 - voltage[5]) * 7.52 - 1000); // pin26 wind voltage divider 10k : 1.2 k Ohm 1:1 if(voltage[5] < 0) voltage[5] = 0; voltage[6] = int((voltage[6]) * 0.804 + 129); // pin27 temp not connected yet voltage[7] = int((voltage[7]) * 4.583 + 735); // pin12 Solar2 voltage divider 4.7k : 1k if(voltage[7] 2019/12/03 Interview with Tom about his EE project about renewable energy in Vietnam. As for an EE (extended essay in the IB international baccalaureate) in physics an experiment should be included. And we can investigate the wind and solar power here in Nha Be on the roof of the 5th floor of the school building. To collect data I created a new Google account as aisvn.data for emails and communication (MQTT, IFTTT). > 2019/12/08 The website [sites.google.com/ais.edu.vn/solar](https://sites.google.com/ais.edu.vn/solar) is created. The measured data from the last 36 hours is displayed in an interactive graph. > 2019/12/14 I created a jupyter notebook with the first informations. The document can be found [here](https://colab.research.google.com/drive/1SWBxNhv9skyehvX9P8T1SB_Elqk8s_KK?usp=sharing). A copy is included in software. > 2019/12/17 For about an hour during assigned study we tried to measure the characteristics of a 12 Volt 6 Watt solar panel that the school provided. The values are measured with the [Vernier voltage probe](https://www.vernier.com/product/voltage-probe/) and the [current probe](https://www.vernier.com/product/current-probe/). Unfortunately the voltage probe has a maximum voltage range of 10 Volt, while the solar panel provides up to 16 Volt without any load. __Solution 1:__ A voltage divider made of two 1 kiloOhm resistor divided the output by 2 and moved it into the voltage limit of the probe. A successful reading now indicated the second problem: Without any load the output voltage is almost constant, since it mainly derives from the band gap in the semiconductor. This is well illustrated in this [graph from wikipedia](https://commons.wikimedia.org/wiki/File:Actual_output_in_volts,_amps,_and_wattage_from_a_100_Watt_Solar_module_in_August.jpg): Note that only the current increases during daytime. Since the power is a product of voltage and current, the power increases as well. __Solution 2:__ A [MPPT](https://en.wikipedia.org/wiki/Maximum_power_point_tracking) (Maximum Power Point Tracking) involves a lot electronics that is well beyond the scope of IB physics. We chose to use a fixed load somewhere in the middle of the power curve. By measuring the voltage we would automatically measure the current and therefore the power. First we had to estimate the correct resistance for the load. With the parameters of 12V and 6W one can calculate a current of I=500mA from __P=VI__ and then apply Ohm's law as __R=U/I__ which results in a resitance of R=12/0.5=24 Ohm. Another way is the direct way of __R=Uยฒ/P=12ยฒ/6=24 ฮฉ__. Half the power would be achieved with ca. 50 Ohm and 100 Ohm creates 25% of the maximum power on the load. Since we had plenty 1 kOhm resistors we soldered 9 of them in parallel and added 2 series of two 1 kOhm resistors from the voltage divider as well. The circuid diagram looks like this: ![load circuit for the solar panel and voltage measurement](pic/setup_2020-01-16.jpg) > 2020/02/27 The hybrid wind solar power generator arrives - despite the corona virus outbreak in China. Declarations with customs and DHL took some time, but it's now here. Other parts will be ordered locally. And this controller has the __MPPT__ we mentioned in January included! > 2020/03/18 I finally create a Github repository to document this project. The ESP32 were delivered some weeks ago. Now I got the LiPo batteries as well. Connector for the feather-style boards: __JST PH 2pin__ for reference! Purcheased at [ICDAYROI](https://icdayroi.com/) in Thแปง ฤแปฉc. > 2020/03/20 The ADC of the ESP32 is not very linear. But we want to use it to measure the voltage of the solar pannel under different load situations. There might be a compensation function. The procedure and measurement was done by [Fernando Koyanagi](https://www.fernandok.com/) from Florianรณpolis in Brazil and published in [instructables](https://www.instructables.com/id/Professionals-Know-This/). ![ADC reading](pic/adc_esp32.jpg) For the future design of April 2020 the voltage is measured by the ESP32 and the value transfered to a database in the internet every 5 minutes. This gives 288 data points per day. An article at [randomnerdtutorials](https://randomnerdtutorials.com/esp32-adc-analog-read-arduino-ide/) explains the setup and programming very well; ![Setup of ESP32](pic/analog_input_esp32.jpg) Additionally there are 4 digital switches for different loads planned. The ESP32 is activating them prior to the measurement and can combine the swithces for 16 different load values. The setup now looks like this: ![adjustable load setup ESP32](pic/setup_2020-03-20.jpg) With the 4 switches we can create 16 datapoints, that the ESP32 can read in 12 bit. Every 5 minutes we create therefore 24 byte of data. Over a day this accumulates to 6912 byte and in a year all data collected is 2.5 MByte. ### TTGO T-Display > 2020/04/01 The ordered TTGO ESP32 mainboard is pretty good! I ordered it mainly for the included LiPo charger, but it as 2 extra buttons (GPIO0 and GPIO 35) to the reset button. And a [1.14 Inch display](http://www.lcdwiki.com/1.14inch_IPS_Module) IPS [ST7789V](https://www.newhavendisplay.com/appnotes/datasheets/LCDs/ST7789V.pdf) with 135x240 pixel. And there are 13 GPIO pins left to use for 4 switches and one voltmeter under different load conditions. ![Pin layout TTGO T-Display V1.0](pic/TTGO_pin.jpg) To program the display and some voltages, example code can be found at [https://github.com/Xinyuan-LilyGO/TTGO-T-Display](https://github.com/Xinyuan-LilyGO/TTGO-T-Display) > 2020/04/07 A second TTGO ESP32 arrived and is set to be programmed: ![Two ESP32 TTGO](pic/ttgo.jpg) Without programming TTGO installed some software on the module. On the 135x240 display you get 22x30 characters with a 6x8 font. That's almost as much as my first ZX81 with 32x24. You can scan for nearby 2.4GHz networks, check the power supply and go into sleep mode. The last one is of interest for our project and the power consumption with these standard settings will be tested next. ### Power consumption T-Display ![TTGO-T-Display modes](pic/ttgo_disp1.jpg) > 2020/04/28 With an external power supply we can check the power consumption of the TTGO. The values over USB were rather high, but it has a 3.7 LiPo battery connector and the power consumption there is significantly lower, most likely because the 5V to 3.3V step-down converter is not needed. Here are the values for 3.7 Volt over battery: - Power on, start up and screen on: 68 mA - WiFi scan for nearby hotspots: 108 mA - Sleep, waiting for interrupt from key pressed: 0.35 mA With a 1000 mAh battery and the given voltage we can calculate the power consumption and projected runtime: - Screen on: 252 mW, runtime 14 hours 42 minutes - WiFi on: 399 mW, runtime 9 hours 15 minutes - Hibernate: __1.3 mW__, runtime 2857 hours - or __119 days__ > 2020/05/07 School is back open since May 4th, students are back since May 5th - and now we got the solar panel and the battery! Time to find a place on the roof in Nha Be and control software to collect and transmit data. ![Solar panel](pic/2020-05-07_solar.jpg) > 2020/05/08 The wind generator arrived just one day later! Looked at location on top of the roof, 6th floor in Nha Be. Empty room for equipment is there, rain proved, and space for the 5 wired from solar and wind to the control unit. Maybe next week start first test setup? ![Wind generator](pic/2020-05-08_wind.jpg) Data: __JLS-500__ with 24V and 500 W > 2020/05/14 The TTGO can be programmed with MicroPython and [devbis](https://github.com/devbis) created both a [slow python driver](https://github.com/devbis/st7789py_mpy/) for the display ST7789 as well as a [fast C variant](https://github.com/devbis/st7789_mpy). Further description of this module [here](https://sites.google.com/site/jmaathuis/arduino/lilygo-ttgo-t-display-esp32). And the tft driver from Loboris is working as well, details in [this instuctable from February 2020](https://www.instructables.com/id/TTGO-color-Display-With-Micropython-TTGO-T-display/). Original data at [LilyGo github](https://github.com/Xinyuan-LilyGO/TTGO-T-Display). > 2020/05/15 We installed the 60W solar module on the roof of our school AISVN and connected MPPT controller and __24Ah__ battery. Now charging over the weekend, then connect my 60W motorcycle lamp to drain the battery every night ... ![solar installation 2020/05/15](pic/2020-05-15_solar.jpg) The stand for the 600W wind generator will be welded in the next week. > 2020/05/17 First successful setup with WEMOS LoLin32 board, 2000 mAh battery and two 1kOhm voltage divider for input on pin 34. Voltage measurement every 2 minutes, upload via __IFTTT__ and webhooks to google sheet, then deep sleep. Setup: ![Little solar setup](pic/2020-05-16_setup.jpg) Code: ``` c // Solarmeter first attempt (all Serial.print removed), inspired by // https://randomnerdtutorials.com/esp32-esp8266-publish-sensor-readings-to-google-sheets/ #include #include const char* ssid = ""REPLACE_WITH_YOUR_SSID""; const char* password = ""REPLACE_WITH_YOUR_PASSWORD""; const char* resource = ""/trigger/value/with/key/create-one""; const char* server = ""maker.ifttt.com""; uint64_t uS_TO_S_FACTOR = 1000000; // Conversion factor for micro seconds to seconds uint64_t TIME_TO_SLEEP = 120; int adcValue = 0; void setup() { delay(1000); initWifi(); makeIFTTTRequest(); esp_sleep_enable_timer_wakeup(TIME_TO_SLEEP * uS_TO_S_FACTOR); esp_deep_sleep_start(); // start deep sleep for 120 seconds (2 minutes) } void loop() { // sleeping so wont get here } void initWifi() { // Establish a Wi-Fi connection with your router WiFi.begin(ssid, password); int timeout = 10 * 4; // 10 seconds while(WiFi.status() != WL_CONNECTED && (timeout-- > 0)) { delay(250); } } void makeIFTTTRequest() { // Make an HTTP request to the IFTTT web service WiFiClient client; int retries = 5; // raw and converted voltage reading adcValue = analogRead( 34 ); String jsonObject = String(""{\""value1\"":\"""") + adcValue + ""\"",\""value2\"":\"""" + (adcValue * 2.4) + ""\"",\""value3\"":\"""" + millis() + ""\""}""; client.println(String(""POST "") + resource + "" HTTP/1.1""); client.println(String(""Host: "") + server); client.println(""Connection: close\r\nContent-Type: application/json""); client.print(""Content-Length: ""); client.println(jsonObject.length()); client.println(); client.println(jsonObject); int timeout = 5 * 10; // 5 seconds while(!!!client.available() && (timeout-- > 0)){ delay(100); } client.stop(); } ``` And for the first day in Phy My Hung (May 17th, 2020) we got this graph: ![Voltage output during the day](data/2020-05-17_voltage.jpg) Power measurements with the WEMOS LoLin32 lite: - On 40 mA, regardless of LED on pin 22, 148 mW - WiFi 116 mA fluctuating (DHCP, http request), 430 mW, full cycle < 1 second (0.7 s average) - Sleep 0.06 mA, __0.22 mW__ - runtime with 1000 mAh battery: 16666 hours, or __694 days__ Power measurements with LilyGo TTGO T-Koala with WROVER-B and USB-C - On 35.8 mA, power LED is always on, 133 mW - WiFi 100 mA (spikes in oscilloscope, DHCP, http request), 370 mW, full cycle 2020/05/18 Here is the graph: ![Voltage output during the second day](data/2020-05-18_voltage.jpg) > 2020/05/19 With a load of 3 kOhm we get almost the free floating voltage of the solar cell. At 7 Volt the test circuit only consumes 2.3 mA or 16 mW - while having a maximum power of 2000 mW - this is 0.8% of what it should be able to deliver. Thats the output over the day: ![Voltage output during the third day](data/2020-05-19_voltage.jpg) ![Voltage output during the 4th day](data/2020-05-20_voltage.jpg) > 2020/05/21 We installed the second ESP32 next to our MPPT Solar controller and measure for the beginning the voltage of the solar panel and the battery. Observations: The MPPT does not apply for the solar panel, it is directly connected to the battery and looses therefore a lot of energy. Secondly: The floating limit for our battery was set too low at 13.8 Volt, so it was never really charged since installation on May 15th. New limit is 14.7 Volt floating and overvoltage limit 14.8 Volt. Third - the lower voltage limit was set too low at 10.8 Volt, it is adjusted now at 11.0 Volt. The load was reduced from 120 W to 60 W. Let's see if the weekend brings an improvement. Here is the data from the first day (second half of May 21st, 2020): ![values and voltage battery from first day](pic/2020-05-21_nhabe.jpg) ### Peak voltage and power output of 6 Volt 2 Watt solar panel > 2020/05/25 I combined several measurements from May 18th to May 24th with different loads on the 6 Volt 2 Watt solar panel that was placed in Phu My Hung to an overview from 5:00 AM tp 7:00 PM: ![voltage in phu my hung](pic/May2020_6V_2W_panel.jpg) ![power in phu my hung](pic/May2020_power.jpg) ### Results from first week at AISVN > 2020/05/28 We start with a 60 Watt drain resistor that switches on after sunset (6:00 PM) for a programmed time of 4 hours. Unfortunately it drains the battery in 3.5 hours. ![May 21st](aisvn/data/2020-05-21_all.jpg) ![May 22nd](aisvn/data/2020-05-22_all.jpg) Rainy Saturday, battery charged very little, drained after 1.5 hours. ![May 23rd](aisvn/data/2020-05-23_all.jpg) ![May 24th](aisvn/data/2020-05-24_all.jpg) Switch from a 60 Watt load to a 5 Watt load for 4 hours after sunset. ![May 25th](aisvn/data/2020-05-25_all.jpg) Battery fully charged, controller disconnects solar panel during the day. Load now on for 7 hours after sunset. ![May 26th](aisvn/data/2020-05-26_all.jpg) Battery drained again with 60 Watt load from 11:00 AM to 5:00 PM. Then installed new MPPT solar charger. ![May 27th](aisvn/data/2020-05-27_all.jpg) With MPPT higher solar voltage for charging - for increased efficiency. Compare May 28th to May 25th. ![May 28th](aisvn/data/2020-05-28_all.jpg) ![May 29th](aisvn/data/2020-05-29_all.jpg) Graduation for Seniors 2020 started 3:00 PM after the thunderstorm 1:00 PM - solar panel went off. ![May 30th](aisvn/data/2020-05-30_all.jpg) ![May 31th](aisvn/data/2020-05-31_all.jpg) ### Measure the power - resistor for current in line > 2020/06/01 We put a 0.1 Ohm resistor in series with the positive wire of the solar panel to determine the current from the voltage drop. Even in the case of 3 Ampere this accounts only to 0.3 Volt and less than a Watt of heat loss. ![circuit diagram](pic/2020-06-01_powerbox.jpg) > 2020/06/02 The powerbox was finished. The total resistance is closer to 0.122 Ohm. The voltage drop reading has therefore to be multiplied by 8.2 to get the current reading for the solar panel input. That's the finished box: ![finished box](pic/2020-06-02_powerbox.jpeg) > 2020/06/05 The T-Koala has some direct pins, for example for the battery - it's easier to connect to them to determine the voltage of the LiPo. Picture and pinout: ![T-Koala from TTGO](pic/T-Koala.jpg) And I finished the soldering of the board with several voltage dividers and two LEDs to lower the voltage into the measurable range of the ESP32 to see the voltage difference over the 0.1 Ohm resistor in line with the solar panel. ![board v0.1](pic/2020-06-05_board.jpg) And I installed it after sunset to get the first measurements. It's installed parallel to the other ESP32 that operated just with 2 voltage dividers for the last 2 weeks - which will cause weired values because of wrong reference levels - and pin26 of the ESP. ![Setup Friday](pic/2020-06-05_setup.jpg) > 2020/06/08 After a weekend of measurement the system is working and delivered the first measured current data - and some strange voltage behaviour once the load switched on. ![Data Saturday](pic/2020-06-06_solar.jpg) The power box and MPPT controller measured and displayed their data effectively. ![power box and mppt controller](pic/2020-06-08_solar.jpg) And the final stage for the wind generator and the output measurement was in place: ![wind generator setup](pic/2020-06-08_wind.jpg) > 2020/06/09 The mainboard with the TTGO T-Koala ESP32 microcomputer got the rectifying circuit for the 3 phase AC from the wind generator on top. The 6 1N4007 diodes are accompanied by a 100 ยตF capacitor and a 10 kOhm load to smooth some of the voltage. An blue LED with 10 kOhm is parallel as well. And below is the voltage divider with 1k : 10k as input voltage to pin 26. In the middle the 100k : 100k voltage divider between GND and battery voltage can be seen as input for pin 13. ![board top](pic/2020-06-09_board-top.jpg) Bottom left are two green diodes that lower the positive voltage of the solar panel prior and after the 0.12 Ohm shunt in line with the positive line. Since positive is connected to 3.3V, the input voltage is 1.1 Volt or higher, if the solar panel provides current. Voltages are measured at pin 34 and 35 and are connected to the negative battery pin with 10 kOhm resistors (the two blue ones) for some 1.2 mA current. Above the battery pin are the three voltage dividers 1 k : 10 K for solar panel (pin 32), the battery (33) and the load (14). Since all are connected on the positive pin, the voltage is measured against 3.3V and connected to the negative pin with the 10 kOhm resistor. On the right corner is the small circuit for the second solar cell to charge the LiPo battery of the ESP32. It got its own 4.7k : 1k voltage divider connected to pin 12 and has a step down converter with USB output and a USB-C cable to the connector. The 5V pin of the board can't be used. ![board top](pic/2020-06-09_board-bottom.jpg) Shortly after 2:00 PM we installed the board, connected the wires and wind generator - and got our first measurement! The rainstorm from 4:00 PM to 5:00 PM provided some constant energy creation. ![first wind June 9th](pic/2020-06-09_wind-solar.jpg) You can see the less noisy signal due to 100x multisampling. As soon as the 20W load lamp switches on the voltage of the battery drops, bust for some time the solar panel can provide the 1.6 Ampere needed, so the voltage stays constant. The clouds at 2:00 PM already indicated the coming storm - and the solar panel virtually started to produce any usable energy. Sunset is indicated at 6:20 PM. > 2020/06/11 The LiPo battery of the T-Koala would be drained within 2 weeks - on a project with renewable energy! Unfortunately we can't connect the microcontroller to the big 24 Ah battery, because the solar controller has no common ground, but the positive poles connected. Relative to the negative pole of the battery we get therefore either the full battery voltage during the night or negative voltages (-8 Volt) during the day. Not easy to fit into the 0-3.3 Volt range of the ESP32. Therefore we added a second small solar panel and measure this voltage as well. Here is a collection of our data: ![data June 11th](pic/2020-06-11_datacollection.png) So far we measure the voltages: - solar panel - wind generator - 12V battery - load - secondary solar panel - LiPo battery to power the ESP32 The dump resistor is not yet connected. Additionally we measure the __current__ from the solar panel. Pin assignment: ``` c // 32, 33, 34, 35, 14, 26, 27, 12, 13 // solar, battery, currentA, currentB, load, wind, dump, solar2, LiPo int voltage[9] = {0, 0, 0, 0, 0, 0, 0, 0, 0}; // all voltages in millivolt int pins[9] = {32, 33, 34, 35, 14, 26, 27, 12, 13}; // solar, battery, curA, curB, load, wind, dump, solar2, LiPo ``` > 2020/06/12 I combined the mentioned solar panel from yesterday (1 Watt) with a third solar panel to support the hybrid wind station, since the wind generator only seldomly actually charges the battery, the voltage is usually too low. And the small solar panel needs until 9:00 PM to have the LiPo battery recharged from one night of measurement. ![Two additional solar panels](pic/2020-06-12_solar2.jpg) > 2020/06/16 The effect of 100x multi-sampling can easily be seen in this voltage measurement of the LiPo battery for the ESP32. Just compare before (20 mV noise) and after (2 mV noise). Since one measurement is 9.5 ยตs the 100x multisample takes only a millisecond. ![multisample benefit](pic/2020-06-15_multisample.png) > 2020/06/18 The second box passed the prove of concept: I'm able to switch up to 1.5 Ampere with a 2SD613 transistor and a 150 Ohm resistor connected to an output of the ESP32. And the output stays active even in deep sleep with the right software. And the measured data make sense, a draft software script is uploaded as [SolarAISVN2.ino](software/SolarAISVN2.ino) in the software folder. Most of the box inner is ready as well, only the PCB needs to be finished: ![Second box with ESP32](pic/2020-06-18_box.jpg)"
https://github.com/kreier/promised-seed/blob/main/README.md,"# The Promised Seed ![GitHub Release](https://img.shields.io/github/v/release/kreier/promised-seed) ![GitHub License](https://img.shields.io/github/license/kreier/promised-seed) Visualizing the lineage of Jesus, starting with Adam and connecting families and prophecies. ## Motivation For people of Israel 2000 years ago it was of big importance to trace their family back in a genealogy. This was important to have a part in inherited land, or enjoy certain privileges. For example, after the exile in Babylon the families of _Habaiah_, _Hakkoz_, and _Barzillai_ who could not find their genealogical records. (Ezra 2:61-63, Nehemiah 7:63-65) Because they could not prove their lineage, they were excluded from the priesthood and forbidden to eat the sacred food until a priest could determine their status using the Urim and Thummim. Of even greater importance was the lineage of the promised Messiah. He needed to be a son of Abraham, Judah and David. Therefore both Matthew and Luke include a geneaology of Jesus Christ. But if you look at them, you will find some differences. The more details one unveils, the more interesting and connected to world history this lineage becomes. Hence this project to condense and visualize some findings of this study. But first we have to think about size: ## Size consideration In many digital documents you can zoom in 600%, with Affinity even more. But my goal was a possible printout, and this generates tangable constrains. I tested font sizes and consider 10 pt still to be good readable. The standard line distance is then 12 pt. So how many lines or rows are necessary? ### Account of Luke in 12 pt The account of Luke lists 75 individuals. If we put each father in one line, we need 75 lines with the height of 12 points. | from - to | Luke | Matthew | maternal | legal | TPS1 | TPS2 | |--------------------|:----:|:-------:|:--------:|:-----:|:----:|:----:| | Adam - Noah | 10 | | 10 | 10 | 10 | 10 | | Noah - Abraham | 10 | | 10 | 10 | 10 | 10 | | Abraham - David | 13 | 13 | 13 | 13 | 13 | 38 | | David - Exile | 20 | 14 | 19 | 17 | 21 | 34 | | Exile - Zerubbabel | 2 | 2 | 3 | 3 | | | | Zerubbabel - Jesus | 20 | 11 | 20 | 11 | 11 | 20 | | sum | 75 | 40 | 75 | 64 | 65 | 112 | Matthew only begins with Abraham and describes the paternal or legal side of Jesus lineage. It includes many kings of Judah and has in total 40 persons. The account of Luke starts with Adan and has therefore 20 more names. From Zerubbabel the lineage is significantly longer (20 instead of 11 individuals) and concludes after 75 generations. Another project includes many more extra lines for other children and relatives. This requires an estimated 112 lines for all the information. One point is 0.3528 millimeter large. 12 points equals 4.23 millimeter and 75 lines require 317.52 millimeter. A4 portrait has a height of 297 mm, A3 has 420 mm. ### Extra space for parent - children lines I want some extra lines connecting parents to their childen, and 12 pt line height is too cramped. I decided to increase the line height to 14 pt. The results can be found in this table: | number of lines | 10 pt | 12 pt | 14 pt | 16 pt | |:-----------------:|:------:|:------:|:------:|:------:| | 1 | 3.53 | 4.23 | 4.94 | 5.64 | | 66 | 232.85 | 279.42 | 325.99 | 372.56 | | 75 | 264.60 | 317.52 | 370.44 | 423.36 | | 85 | 299.88 | 359.86 | 419.83 | 479.81 | | 112 | 395.14 | 474.16 | 553.19 | 632.22 | | 1 pt | 0.3528 | 0.3528 | 0.3528 | 0.3528 | ## History of this ""The Promised Seed"" repository The motivation came from my old [timeline project](https://github.com/kreier/timeline) here on GitHub, that actually started with some curated HTML files in 2006. Over time it grew to a detailed chart of human history for the last 6000 years. From paper versions, html, OpenOffice spreadsheets, OpenOffice vector drawings to finally a Python program generated PDF of 1208x210 mm (or four A4 papers in landscape). About the same time others started a related project, but focused on the lineage of Jesus and historic events related to ""the promised seed"". Their project has the size of 864x1118 mm (34x44 inch) and was created 2002-2005. Its final version looks like this: I had heard about this project since 2023, and in 2025 I got a digital copy. But it is not intended to be shared online. Therefore there is only a rather fuzzy image embedded in this repository. So I thought about creating a similar document. The authorship was one consideration. The size was another consideration. The size of 864x1118 is very close to the size of A0 (841 x 1189 mm) and usually the largest size for a print shop. Still some parts are not easy to read. Could I create a smaller version that still would be readable? I certainly had to leave out some information of the original document. And I would have to check out the information for myself. Both as a study project, and to import the references in the dictionary files to help later in translations. A broad assumption: If I organize the data better, and leave out both timeline aspects (contemporary part and kings/prophets northern and southern kingdom) I might reduce the needed area to A1. Now reducing the information in the right column and leave out most of first and second generation children of the 12 tribes, getting another 50% and down to A2. Now split some information into two pages (like the two legends, some other large family side tree) and I'm at two A3 papers. Let's check: ## Is it possible to have the family history of Jesus on one A3 portrait page? The vertical size of portrait A3 is 420 millimeters (297 mm wide). Since my timeline project is 210 millimeters high and can have 46 horizontal text lines in text size 10pt (12 pt line height, see [here for the calculation](https://github.com/kreier/timeline?tab=readme-ov-file#decision-on-the-dimensions-for-this-project)) this A3 paper can have up to 92 lines. But how many do we need? The project above has 10 lines Adam-Moses, then 10 lines to Abraham, and 11 (4) lines to Judah. A large block follows with 27 (9) lines to Jesse, the father of David. Then 9 (1) lines to Solomon, 25 (20) to Zerrubbabel and finally 20 (11) lines to Jesus. So a total of 10+10+11+27+9+25+20=112 lines that would not fit, but also 10+10+ 4+ 9+1+20+11=65 that would fit. It's promising!"
https://github.com/vex-ssis/2025/blob/main/README.md,"# 2025 High Stakes [![MIT license](https://img.shields.io/github/license/vex-ssis/2025)](https://vex-ssis.mit-license.org/) ![GitHub Release](https://img.shields.io/github/v/release/vex-ssis/2025) [![Deploy Jekyll with GitHub Pages dependencies preinstalled](https://github.com/vex-ssis/2025/actions/workflows/jekyll-gh-pages.yml/badge.svg)](https://github.com/vex-ssis/2025/actions/workflows/jekyll-gh-pages.yml) SSIS Robotics in the ""High Stakes"" VEX competition 2024-2025 ## SSIS VEX Robotics Scrimmage 2024/10/05 For the event [SSIS VEX High Stakes Scrimmage Season 24-25](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-7374.html#general-info) more than 20 teams signed up, and a few visited without a licence number to have more than 30 teams compete and learn at this scrimmage! All teams shared their knowledge and the students, organizers and supporters embraced this spirit. Here is a [short article](https://www.ssis.edu.vn/student-life/post-details/~board/hs/post/ssis-hosts-vietnams-first-vex-robotics-scrimmage-of-the-year) of this event on the website of SSIS. ## SSIS Qualifiers 2024/11/16 Labeled as [SSIS VEX Qualifying Tournament Season 24-25](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-7852.html#general-info) it were not only SSIS teams on this November weekend - 37 showed up, and Panda robotics coming out as Tournament Champions. Yet SSIS was strong with 8 teams. Highest place is [#4 for 1599V in skills](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-7852.html#results-) and [#2 for 1599R SSIS Christopher Columbus](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-7852.html#results-) with 6-0-0 a total of 6 wins! - 1599R #2 6-0-0 and #6 with 50 skill points 40/10 - 1599N #8 5-1-0 and #11 with 39 skill points 31/8 - 1599Z #13 4-2-0 and #19 with 21 skill points 13/8 - 1599V #15 3-3-0 and #4 with 54 skill points 39/15 - 1599C #16 3-2-1 and #12 with 34 skill points 26/8 - 1299E #30 1-4-1 and #30 with 0 skill points (2 attempts with programming) - 1599D #32 1-4-1 and #32 with 0 skill points (1 attempt driving) - 1599W #35 0-5-1 of 37 teams ## Formosa 2024/12/06 Team 1599V got the Amaze Award at their visit to TAS. [This event](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-5817.html#teams) was visited 1599D, 1599N, 1599R and 1599V. [Post on Instagram](https://www.instagram.com/p/DDpXs7Xywe2/?img_index=1). 1599R made it to place 8. ## VEX V5 High Stakes Vietnam Tournament 2024/12/22 It is the [first event in the northern region](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-9248.html#general-info) for this season (after the [scrimmage on November 10th](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-8703.html#general-info) with 7 teams), and 26 teams joined the competition. SSIS was not a part this time - they are quite busy with their own scrimmages and qualifiers! A day before the National competition the [World Skills Standing](https://www.robotevents.com/robot-competitions/vex-robotics-competition/standings/skills) has 5399 teams with entries. 29 teams are from Vietnam, with team 50922T LSTS MAKO MANIACS having 94 points and rank 139 in the world. The Vietnamese list has also 4 teams from SSIS with their respective position: | #vn | #world | score | number | team name | |:---:|:------:|:-----:|:------:|--------------------------------| | 8 | 1100 | 54 | 1599V | SSIS Vietnamese Banana Farmers | | 13 | 1866 | 39 | 1599N | SSIS Black Vulture | | 15 | 2208 | 34 | 1599C | SSIS CoCoa | | 21 | 3416 | 21 | 1599Z | SSIS Titans | Currently the highest scores worldwide are 131, 127 and 122 points in HS. ## Southern Regional V5RC Championships 2025/02/09 On [this event](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-7853.html#general-info) a new record high of 46 teams compeated. Follow on [the life stream](https://www.youtube.com/watch?v=s_9mHTQSZFg) for the qualification and [steam of the final day](https://www.youtube.com/watch?v=pXdurRYY6mk)! Vietnam has 4 HS and 3 MS spot at VEX Worlds in Dallas 2025, and 4 of them are awarded on February 9th: ![image from finals2](docs/2025-02-09_finals2.jpg) - MS Exellence award: [62024N](https://www.robotevents.com/teams/V5RC/62024N) Panda Robot (currently #1 VN and 43/2617 with a score of 92 in [World Skills Standings](https://www.robotevents.com/robot-competitions/vex-robotics-competition/standings/skills?search=&event_region=&country=253&grade_level=Middle+School)) - MS Tournament champion: [23457V BRICK LAB 01](https://www.robotevents.com/teams/V5RC/23457V) (#7 VN and 704/2617 in World Skills) - HS Exellence award: [50922T](https://www.robotevents.com/teams/V5RC/50922T) LSTS MAKO MANIACS (currently #1 VN and 35/5666 with a score of 109 in [World Skills Standings HS](https://www.robotevents.com/robot-competitions/vex-robotics-competition/standings/skills?search=&event_region=&country=253&grade_level=High+School)) - HS Tournament champion: [23457H BL SAI GON CHEETAH](https://www.robotevents.com/teams/V5RC/23457H) with robot **BRICK LAB 01** (#13 VN and 1524/5666 in World Skills) Skills award to [50922T](https://www.robotevents.com/teams/V5RC/50922T) LSTS MAKO MANIACS, Design award to [1599V](https://www.robotevents.com/teams/V5RC/1599V) SSIS Vietnamese Banana Farmers, Judges award to [86669A](https://www.robotevents.com/teams/V5RC/86669A) EDS_Bunreal, Innovate award to [37456H](https://www.robotevents.com/teams/V5RC/37456H) PENN BรNH ร, Sportsmanships award to [36732A](https://www.robotevents.com/teams/V5RC/36732A) Vietnam Australia School Sunrise. ## VEX Robotics Vietnam National Championship 2025: V5 High Stakes - Skills only 2025/03/02 And another [event in the north](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-9244.html#general-info), with 27 teams attending. SSIS will send 3 teams: - 1599N SSIS Black Vulture, rank 21 with 39 points (36/3) - 1599R SSIS Christopher Columbus, rank 20 with 40 points (40/0) - 1599V SSIS Vietnamese Banana Farmers, rank 10 with 70 (39 driving/31 programming) points And we got the remaining 3 spots to represent Vietnam at VEX World 2025 in Dallas: - Excellence Award: [36070N](https://www.robotevents.com/teams/V5RC/36070N) Green Ams Robotics Team 1 from Hanoi Amsterdam High School for the Gifted (also Tournament Champion) - Tournament Champions [36070X](https://www.robotevents.com/teams/V5RC/36070X) FPTCanTho_Enterprise from STEAM for Vietnam Foundation - Tournament Champions 36070N again ... so who is going? It is 1599V! And with this skills event the updated scores at the [World Skills Standing](https://www.robotevents.com/robot-competitions/vex-robotics-competition/standings/skills) has 6229 teams with entries. 32 teams HS are from Vietnam, with team 50922T LSTS MAKO MANIACS having 109 points and rank 58 in the world. The Vietnamese list has also 5 teams from SSIS with their respective position: | #vn | #world | score | number | team name | |:---:|:------:|:-----:|:------:|--------------------------------| | 10 | 869 | 70 | 1599V | SSIS Vietnamese Banana Farmers | | 19 | 2584 | 39 | 1599N | SSIS Black Vulture | | 21 | 2963 | 34 | 1599C | SSIS CoCoa | | 26 | 4205 | 21 | 1599Z | SSIS Titans | | 30 | 5725 | 8 | 1599E | SSIS DinoSoap | The current list for Middle school contains 2827 teams with 11 teams from Vietnam. The only one from SSIS is Christopher Columbus on 6th place: | #vn | #world | score | number | team name | |:---:|:------:|:-----:|:------:|---------------------------| | 6 | 500 | 50 | 1599R | SSIS Christopher Columbus | ## VEX Robotics World Championship High School 2025/05/06 - 08 Here is [the link](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-8909.html#general-info). There should be 4 teams from Vietnam (out of 833): - [1599V](https://www.robotevents.com/teams/V5RC/1599V) SSIS Vietnamese Banana Farmers from Saigon South International School (SSIS), _Design Award_, rank 62 w 10/24/176 - [23457H](https://www.robotevents.com/teams/V5RC/23457H) BL SAI GON CHEETAH from BRICK lab robotics CLUB, _Tournament Champions_, rank 68 w 9/21/140 - [50922T](https://www.robotevents.com/teams/V5RC/50922T) LSTS MAKO MANIACS from Lawrence S.Ting School, _Robot Skills Champion_ and _Excellence Award_, rank 54 w 11/39/170 - [62024P](https://www.robotevents.com/teams/V5RC/62024P) Panda Robotics Platinum from Panda Robotics, _Tournament Champions_, rank 44 w 13/30/219 1599V got place 62/83 in their ""Design"" division. And 151/405 in the skills ranking. ### Two more teams from Vietnam with the [Online Challenges](https://challenges.robotevents.com/) In addition to the V5 National Championship events you can also qualify for VEX World with Online challenges. There are 3+3+3=9 challenges for middle school and 3+3+4=10 challenges for high school. Applying there two more teams from Vietnam entered the World Championship in 2025: - [36070M](https://www.robotevents.com/teams/V5RC/36070M) 11 from STEAM for Vietnam Foundation, rank 67 w 8/24/195 - [36070N](https://www.robotevents.com/teams/V5RC/36070N) Green Ams Robotics Team 1 from Hanoi Amsterdam High School for the Gifted, _Excellence Award_, rank 18 w 18/48/180 These challenges are: - Team Recruitment Poster Challenge โ Middle School Teams & High School Teams - Meme My Team Challenge โ Middle School Teams & High School Teams - Innovate to Elevate Challenge โ Middle School Teams & High School Teams - (Cycle 2) Create a Game Element Challenge: CAD Challenge - Middle School & High School - (Cycle 2) Game Design Challenge: The Upcycling Effect - Middle School & High School - (Cycle 2) Show Your Spark: Meme My Team Challenge - Middle School & High School - (Cycle 3) RECF Community Challenge - High School - (Cycle 3) Girl Powered Challenge: Leadership in STEM Challenge - Middle School & High School - (Cycle 3) VEXcode VR Virtual Skills Challenge - Middle School & High School - (Cycle 3) A3 Robot Safety Award โ Sponsored by the Association for Advancing Automation- Middle School & High School The winning contributions are: - 36070M as [Team 11](https://challenges.robotevents.com/user/144229) in 2025 Challenges > [STEM Advocacy Challenge - High School](https://challenges.robotevents.com/challenge/287/stem-advocacy-challenge/entry) > [Empowering Cao Bang through Robotics](https://challenges.robotevents.com/challenge/287/stem-advocacy-challenge/entry/14761) with a [PDF file](https://challenges.robotevents.com/uploads/0025238_original.pdf) (39 pages) or a [website](https://sites.google.com/view/team-11-36070m/home) ## VEX Robotics World Championship Middle School 2025/05/09 - 11 Here is [the link](https://www.robotevents.com/robot-competitions/vex-robotics-competition/RE-V5RC-24-8910.html#general-info). There should be 3 teams from Vietnam (out of 488): - [23457V](https://www.robotevents.com/teams/V5RC/23457V) BRICK LAB 01 from BRICK lab robotics CLUB, rank 42 w 11/15/244 - [27908V](https://www.robotevents.com/teams/V5RC/27908V) LSTS LOGICRIDERS from Lawrence S.Ting School, rank 51 w 10/9/178 - [62024N](https://www.robotevents.com/teams/V5RC/62024N) Panda Robot from Panda Robotics, rank 52 w 9/21/262 ## Virtual Standings [on robotevents](https://www.robotevents.com/robot-competitions/vex-robotics-competition/virtualSkillsStandings) - 2024/10/05 none of 128 - 2025/01/28 132 of 439 with 30 points and 31 seconds stop time for 1599V, #3 in Vietnam (4 teams total, best at rank 54 for 50922T with 46 points) - 2025/02/07 147 of 465 with 30 points and 31 seconds stop time for 1599V, #3 in Vietnam (50922T now rank 57 worldwide) - 2025/03/06 154 of 489 with 30 points, now 5 teams in Vietnam total, and 50922T at 61 worldwide ## Available spots at Worlds The year 2024 saw an increase in interest for VEX V5 in Vietnam, while the focus shifted away from VEX IQ. That's even more the case for 2025 and the available spots to compete at VEX Worlds in Dallas. Now there are [7 spots at V5RC](https://kb.roboticseducation.org/hc/en-us/articles/5474199602071-Qualifying-Criteria-for-VEX-Robotics-Competition-Events) for Vietnam! | Season | VIQRC (ES) | VIQRC (MS) | V5RC (MS) | V5RC (HS) | SSIS | |---------------------|:----------:|:----------:|:---------:|:---------:|:----:| | 2018 In The Zone | - | - | - | 1 | 1 - [76209G](https://www.robotevents.com/teams/V5RC/76209G) | | 2019 Turning Point | - | - | - | 1 | 1 - [76209X](https://www.robotevents.com/teams/V5RC/76209X) | | 2020 Tower Takeover | - | - | - | Covid19 | 1 - [76209G](https://www.robotevents.com/teams/V5RC/76209G) | | 2021 Change-Up | Covid19 | Covid19 | Covid19 | Covid19 | - | | 2022 Tipping Point | Covid19 | Covid19 | Covid19 | Covid19 | - | | 2023 Spin Up | [6](https://en.vietnamplus.vn/vietnam-to-send-20-teams-to-vex-robotics-world-championship-2023-post247574.vnp) | [13](https://baogialai.com.vn/hoc-sinh-gia-lai-tiec-nuoi-dung-buoc-o-vong-loai-giai-vo-dich-the-gioi-vex-robotics-2023-post236206.html) | 1 | 1 | [2](https://sites.google.com/ssis.edu.vn/vex) - [76209M](https://www.robotevents.com/teams/V5RC/76209M) & [76209R](https://www.robotevents.com/teams/V5RC/76209R) | | 2024 Over Under | 3 | 5 | 1 | 3 | 0 | | 2025 High Stakes | 3 | 5 | 3 | 4 + 2 | 1 - [1599V](https://www.robotevents.com/teams/V5RC/1599V) | And the Vietnam Banana Farmers 1599V (previous Vector as 76209R Racoons [Rookies] team) is returning to Dallas!"
https://github.com/kreier/language-families/blob/main/README.md,"# Language families and the connection to Noah's family Connect language families with the spread of Noah's family after the flood. The Wikipedia articles about language families in [German](https://de.wikipedia.org/wiki/Sprachfamilie) and [English](https://en.wikipedia.org/wiki/Language_family) contain some nice world maps already. ![Sprachfamilien 2020](images/Sprachfamilien2020.png) ![Language families 2005](images/language-families2005.png) ## Procedural generation It might be possible to create a SVG or PDF with python and the [GeoPandas](https://geopandas.org/en/stable/) package (on [Github](https://github.com/geopandas/geopandas)). Relevant maps in the SGX format might be available at Kaggle. - [Making colored country maps with real data using matplotlip and Geopandas](https://medium.com/analytics-vidhya/making-colored-country-maps-with-real-data-using-matplotlib-and-geopandas-2d10687ca7ac) - [How to make colored country maps in Python TLDR edition](https://medium.com/@protobioengineering/how-to-make-colored-country-maps-in-python-tldr-edition-d58147105a8d) - [Choropleth Map Tutorial on Github](https://github.com/aero-man/choropleth-map-tutorial) - https://koordinates.com/layer/3824-nz-police-district-boundaries/ - [Data model (GIS)](https://en.wikipedia.org/wiki/Data_model_(GIS)) - [Choropleth map](https://en.wikipedia.org/wiki/Choropleth_map) - [Shapefile](https://en.wikipedia.org/wiki/Shapefile) ## Editing a vector file Now that [Affinity is freely available](https://www.affinity.studio/), we could just start with a vector file to represent our current state. Over time we update, and document changes. ## Enduring constraints on grammar revealed by Bayesian spatiophylogenetic analyses In a [post on phys.org](https://phys.org/news/2025-11-patterns-world-languages-grammatical-universals.html) I found the structural connection between 23 languages and how patterns ([linguistic universal](https://en.wikipedia.org/wiki/Linguistic_universal)) appeared over time in most of them. The original article was [posted on nature.com](https://www.nature.com/articles/s41562-025-02325-z) on November 17th, 2025. ## History - 2025/08/27 This idea started on in August in Nha Trang during a conversation with Brandon from Spokane. He created a map in 2005 with Photoshop, and the idea of an updated vector edition was born. - 2025/10/10 In a conversation with Carlo this topic apeared again. He studied Geography in Rome, Italy and investigated the hypothesis of [Altaic languages](https://en.wikipedia.org/wiki/Altaic_languages). This will be a great addition to this project - 2025/11/17 An article on nature.com [Enduring constraints on grammar revealed by Bayesian spatiophylogenetic analyses](https://www.nature.com/articles/s41562-025-02325-z) talks about some [Linguistic universals](https://en.wikipedia.org/wiki/Linguistic_universal) in 23 language groups"
https://github.com/vex-ssis/.github/blob/main/README.md,# .github VEX at SSIS
https://github.com/kreier/study/blob/main/README.md,"# Study [![GitHub release](https://img.shields.io/github/release/kreier/study.svg)](https://GitHub.com/kreier/study/releases/) [![MIT license](https://img.shields.io/github/license/kreier/study)](https://kreier.mit-license.org/) ![example workflow](https://github.com/kreier/study/actions/workflows/jekyll-gh-pages.yml/badge.svg) A compilation and documentation of some highlights from study projects related to the bible. ## Reading project The digital documentation of the reading progress was reactivated on June 10th, 2023. Earlier projects date back to February 2009 and March 1999. Reading (or listening to a reading) of the whole bible started one day later, June 11th, 2023. It was finished by October 6th, 2023. **117 days** later. Here is [the documented progress](https://github.com/kreier/study/blob/main/markdown/progress.txt). [Genesis](docs/bible/genesis/), [Exodus](docs/bible/exodus/), [Leviticus](docs/bible/leviticus/), [Numbers](docs/bible/numbers/), [Deuteronomy](docs/bible/deuteronomy/), [Joshua](docs/bible/joshua/), [Judges](docs/bible/judges/), [Ruth](docs/bible/ruth/), [1 Samuel](docs/bible/1_samuel/), [2 Samuel](docs/bible/2_samuel/), [1 Kings](docs/bible/1_kings/), [2 Kings](docs/bible/2_kings/), [1 Chronicles](docs/bible/1_chronicles/), [2 Chronicles](docs/bible/2_chronicles/), [Ezra](docs/bible/ezra/), [Nehemiah](docs/bible/nehemiah/), [Esther](docs/bible/esther/), [Job](docs/bible/job/), [Psalms](docs/bible/psalms/), [Proverbs](docs/bible/proverbs/), [Ecclesiastes](docs/bible/ecclesiastes/), [Song of Solomon](docs/bible/song_of_solomon/), [Isaiah](docs/bible/isaiah/), [Jeremiah](docs/bible/jeremiah/), [Lamentations](docs/bible/lamentations/), [Ezekiel](docs/bible/ezekiel/), [Daniel](docs/bible/daniel/), [Hosea](docs/bible/hosea/), [Joel](docs/bible/joel/), [Amos](docs/bible/amos/), [Obadiah](docs/bible/obadiah/), [Jonah](docs/bible/jonah/), [Micah](docs/bible/micah/), [Nahum](docs/bible/nahum/), [Habakkuk](docs/bible/habakkuk/), [Zephaniah](docs/bible/zephaniah/), [Haggai](docs/bible/haggai/), [Zechariah](docs/bible/zechariah/), [Malachi](docs/bible/malachi/), [Matthew](docs/bible/matthew/), [Mark](docs/bible/mark/), [Luke](docs/bible/luke/), [John](docs/bible/john/), [Acts](docs/bible/acts/), [Romans](docs/bible/romans/), [1 Corinthians](docs/bible/1_corinthians/), [2 Corinthians](docs/bible/2_corinthians/), [Galatians](docs/bible/galatians/), [Ephesians](docs/bible/ephesians/), [Philippians](docs/bible/philippians/), [Colossians](docs/bible/colossians/), [1 Thessalonians](docs/bible/1_thessalonians/), [2 Thessalonians](docs/bible/2_thessalonians/), [1 Timothy](docs/bible/1_timothy/), [2 Timothy](docs/bible/2_timothy/), [Titus](docs/bible/titus/), [Philemon](docs/bible/philemon/), [Hebrews](docs/bible/hebrews/), [James](docs/bible/james/), [1 Peter](docs/bible/1_peter/), [2 Peter](docs/bible/2_peter/), [1 John](docs/bible/1_john/), [2 John](docs/bible/2_john/), [3 John](docs/bible/3_john/), [Jude](docs/bible/jude/), [Revelation](docs/bible/revelation/) ![image size distribution](data/size_kjv.png) Image above is taken from the project [https://kreier.github.io/tripitaka/](https://kreier.github.io/tripitaka/). ### Reading schedules Of course it is best to have a reading schedule. I tracked down our [organized schedules to the 70s](https://raw.githubusercontent.com/kreier/study/refs/heads/main/data/midweek2025.pdf). And the pace changed several times. The 2000s say a speed up to completely read the whole bible in 5 years. With the new cycle that started on January 6th, 2020 it is greatly reduced. In 2025, after 5 years, we finished Psalms on February 10th. Thats 628 chapters so far (52.8 % of 1189 chapters) that would have required 2870 minutes (51.7% of 5553 %) listening. With so many highlights in the Greek scriptures to expect I think we're looking at a 10 year reading cycle that finishes at the end of 2030. ## Miracles of Jesus in the Bible There should be some 30+ miracles. How many to you recall? 1. Water to wine (John 2:1-12) 2. Heals Simon's mother-in-law and others (Matthew 8:14-17, Mark 1:21-34, Luke 4:31-41) 3. Feeding 4000 4. Resurrecting the son in Nain 5. Resurrecting the daughter of Jairus 6. Healing the flow of blood 7. Resurrecting Lazarus (John 11:38-48) 8. Healing a leper 9. Healing 10 blind men 10. Walking on water (Matthew 14:24-33) 11. Healing ""every sort of diseas and every sort of infirmity."" (Matthew 4:23) 12. Feeding 5000 ## Manuscripts of the Bible While writing articles in the German Wikipedia in 2008 about ### Paleographie The style of writing letters changes over time and can be used to date a scripture rather precisely compared to C-14 dating. That is one thing I learnd when investigating the different types of scrolls An example of how this is done can be seen in the analysis of the En-Gedi scroll and the [prelimary article about the En-Gedi scroll on archive.org](https://f-origin.hypotheses.org/wp-content/blogs.dir/1052/files/2016/09/308.En-GediTextus-26..pdf) ![En Gedi scroll](https://raw.githubusercontent.com/kreier/study/main/manuscripts/EnGedi-Scroll.jpg) More about this scroll here: [https://archive.org/details/engedi-scroll](https://archive.org/details/engedi-scroll) ## [A Timeline of human history](https://github.com/kreier/timeline) Human history graph created in Jupyter Notebook, python and exported as pdf. It is a [different repository](https://github.com/kreier/timeline) on github. ![timeline](https://raw.githubusercontent.com/kreier/timeline/main/spreadsheet/timeline.png) last updated: 2025-02-28 00:17:27.664496"
https://github.com/kreier/notes/blob/main/README.md,
https://github.com/kreier/prime_gaps_line/blob/main/README.md,"# Prime Gaps Line ![GitHub License](https://img.shields.io/github/license/kreier/prime_gaps_line) ![GitHub Release](https://img.shields.io/github/v/release/kreier/prime_gaps_line) Create a logarithmic plot of the frequency of gaps between primes up to an arbitrary number. This was inspired by the the video of Stand-up Maths: https://youtu.be/SMsTXQYgbiQ For the log line he calculated the gaps for the first 150,000,000 primes (minute 18:40) This should be able to calcutate within 300 seconds in Python according to my graph https://github.com/kreier/prime Based on an article by Kerry D. Wong from 2009: http://www.kerrywong.com/2009/09/06/an-alternative-illustration-of-prime-number-distribution/ ## Graph up to 1 million ![graph to 1 million](docs/graph_1million.png) This was created in a Jupyter Notebook in 1.5 seconds with the following code: ``` py import matplotlib.pyplot as plt import math, time, cpuinfo import random last = 1000000 # 4294967295 is the limit for unsigned 32bit, 2147483647 found = 4 # we start from 11, know 2, 3, 5, 7 primes = [3, 5, 7] # exclude 2 since we only test odd numbers frequency = [0] * 100 # should be fine for 100 or gaps of 200 def is_prime(number): flag_prime = 1 for divider in range(3, int(math.sqrt(number)) + 1, 2): if number % divider == 0: flag_prime = 0 break return flag_prime def find_primes(largest): global primes, found for number in range(11, largest + 1, 2): if is_prime(number) > 0: found += 1 primes.append(number) def is_prime_fast(number): flag_prime = True largest_divider = int(math.sqrt(number)) + 1 for divider in primes: if number % divider == 0: flag_prime = False break if divider > largest_divider: break return flag_prime def elapsed_time(seconds): hours = int(seconds/3600) minutes = int(seconds/60 - hours*60) sec = int(seconds - minutes*60 - hours*3600) return(f""{hours}h {minutes}min {sec}s"") print(f""Calculating prime numbers to {last} in Python with algorithm v5.4.2024"") print(f""Running on a {cpuinfo.get_cpu_info()['brand_raw']}"") start = time.perf_counter_ns() dot = start column = 0 largest_divider = int(math.sqrt(last)) if largest_divider % 2 == 0: largest_divider += 1 print(f'First find prime divisors up to {largest_divider}.') find_primes(largest_divider) print(f'Found {found} primes, now use them als divisors.') frequency[0] = 1 # gap of 2 between 5 and 7 last_prime = 7 for number in range(9, last, 2): if is_prime_fast(number): gap = number - last_prime location = int(gap/2 - 1) frequency[location] += 1 found += 1 last_prime = number duration = (time.perf_counter_ns() - start)/1000000000 print(f""This took: {duration:.9f} seconds. {elapsed_time(duration)}"") print(f""I found {found} prime numbers. Should be 78498."") for i in range(len(frequency) - 1, 1, -1): if frequency[i] > 0: highest = i break frequency = frequency[0:highest] plt.plot(frequency) plt.show() gapsize = [] for i in range(highest): gapsize.append(int((i+1)*2)) plt.scatter(gapsize, frequency) plt.yscale('log') plt.show() ``` ## Compare graph to 1 million and 100 million ## And further to 4 billion - 2E32, the largest 32bit integer It took my i3-10100 some 20 hours to finish the calculation in python. ## Most common gap size - the jumping champion For one million the most common gap size is 6. And it has been since around 500. But until then the champion is jumping between 1, 2, 4 and 6 several times. I have to write a program to visualize it, and it will look like here: https://mathworld.wolfram.com/JumpingChampion.html https://math.berkeley.edu/~molsson/Goldston.pdf Graph on page 67 for the champions 2, 4 and 6 And on slide 92 a champion distribution for 2310. https://t5k.org/glossary/page.php?sort=JumpingChampion ## My old finding - not correct, just kept it here for documentation Until 367 the most common gapsize is 2, having appeared 20 times. With 373 and 379 the gapsize 6 appeared 21 times and is taking over the lead until $1.74 \times 10^{35}$ ![gapsize 2 distribution](docs/gapsize_2.png) The most common distance changes with larger prime numbers: - 2 until 373 (20x), with 379 it is 6 - 6 until $1.74 \times 10^{35}$ - 30 until $10^{425}$ - 210 much later, and is then taking over by - 2310 Which follows the pattern or sequence: With the sequence - $p_1 = 2 = 2$ - $p_2 = 6 = 2 \times 3$ - $p_3 = 30 = 2 \times 3 \times 5$ - $p_4 = 210 = 2 \times 3 \times 5 \times 7$ - $p_5 = 2310 = 2 \times 3 \times 5 \times 7 \times 11$ https://arxiv.org/abs/1408.4505 Kevin Ford, Ben Green, Sergei Konyagin, Terence Tao (20 Aug 2014) https://arxiv.org/abs/1408.5110 James Maynard (1 day later on 21 Aug 2014)"
https://github.com/kreier/128x64/blob/main/README.md,"# 128x64 displays small and large Projects for LED and OLED displays with this resolution Just ordered a few 1.14"" OLED displays with SH1105 or SSD1306 controller. And have seen that there are some 128x64 2.5mm LED displays with HUB75E connector available. Same resolution - let's use it for some Circuitpython and Arduino C projects and the Raspberry Pico or some ESP32-S3 boards. That's the pinout of the connector: ![Hub HUB75E](docs/HUB75E.png) ## Example on T-Display ![image](https://kreier.github.io/t-display/starfield.gif) ## Example on OLED ![display](https://kreier.github.io/T400/t400plus.jpg) ![robot](https://kreier.github.io/T400/T400lite.jpg)"
https://github.com/ssis-robotics/team426-2023/blob/main/README.md,# team426-2023 ![GitHub Release](https://img.shields.io/github/v/release/ssis-robotics/team426-2023) ![GitHub License](https://img.shields.io/github/license/ssis-robotics/team426-2023) Updated new codebase for 2023 WPIlib and FRC code.
https://github.com/ssis-unity/unity2022/blob/main/README.md,"# unity2022 ![GitHub Release](https://img.shields.io/github/v/release/ssis-unity/unity2022) ![GitHub License](https://img.shields.io/github/license/ssis-unity/unity2022) Documentation of progess at the Unity Impact Club 2022 at SSIS ## The club in social media You can find out more at the website [sites.google.com/ssis.edu.vn/unityimpact](https://sites.google.com/ssis.edu.vn/unityimpact) and on our [Instagram account](https://www.instagram.com/unity_impact/) or on our [Youtube Channel]() ### Media: - Website [https://sites.google.com/ssis.edu.vn/unityimpact](https://sites.google.com/ssis.edu.vn/unityimpact) - Instagram [https://www.instagram.com/unity_impact/](https://www.instagram.com/unity_impact/) - Youtube [Unity Impact](https://www.youtube.com/channel/UCYwXpmGJ3De0EM0Upb-92vg) - itch.io [https://unityimpact.itch.io/](https://unityimpact.itch.io/) ## History This will be documented in the [Documentation](Documentation) folder. ### Game Exibition March 3rd, 2023 After the first semester seven different games were developed. On the game exibition in MPR2 students had a chance to test their skills in these: ![Games March 2023](Documentation/2023-03-03_games.jpg) ### Direct links to the games to start in your browser - [Organize, My Friend in the Mirror](https://unityimpact.itch.io/organize-my-friend-in-the-mirror) by Nam - [Build Your Way Up](https://unityimpact.itch.io/build-your-way-up) by Nam Le (LonelyDevil) - [Pain](https://unityimpact.itch.io/pain) by Sean - [Breezy Mayday](https://unityimpact.itch.io/mayday) by Matthew - [Bowling Alley](https://unityimpact.itch.io/bowling-alley) by Yoyo - [Save the Chicken](https://unityimpact.itch.io/save-the-chicken) by Soleil - [Gun Platformer](https://unityimpact.itch.io/gun-platformer-demo) by Matthew - [Airplane Shooter Game](https://unityimpact.itch.io/airplane-shooter-game) by Soleil"
https://github.com/timeline25/timeline25.github.io/blob/main/README.md,"# timeline25.github.io Simply contain the latest PDFs for download, linked from the QR codes on the timelines itself. # Repository for latest PDF versions of the timeline project [![GitHub release](https://img.shields.io/github/release/timeline25/timeline25.github.io.svg)](https://GitHub.com/timeline25/timeline25.github.io/releases/) [![MIT license](https://img.shields.io/github/license/timeline25/timeline25.github.io)](https://kreier.mit-license.org/) [![pages-build-deployment](https://github.com/timeline25/timeline25.github.io/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/timeline25/timeline25.github.io/actions/workflows/pages/pages-build-deployment) This website contains the latest PDFs for download, linked from the QR codes on the [timelines](https://github.com/kreier/timeline) itself. ![timeline 5.10](https://raw.githubusercontent.com/timeline25/timeline25.github.io/refs/heads/main/test/timeline20251007_v5.10.png) | language | print | version | last updated | |-------------------------------------------------------------------------|:-----------------------------------------------------------:|:-------:|:------------:| | [German (Deutsch)](https://timeline25.github.io/timeline_de.pdf) | [link](https://timeline25.github.io/timeline_de_print.pdf) | 5.10 | 2025-10-10 | | [English](https://timeline25.github.io/timeline_en.pdf) | [link](https://timeline25.github.io/timeline_en_print.pdf) | 5.10 | 2025-10-10 | | [Vietnamese (Tiแบฟng Viแปt)](https://timeline25.github.io/timeline_vi.pdf) | [link](https://timeline25.github.io/timeline_vi_print.pdf) | 5.10 | 2025-10-10 | The print version has additional 5cm left and right for the print shop. It's easier to connect the end roll covers to the timeline. The standard dimensions for the print version are 1308x210mm. But it can be scaled to any size with a ratio 6.228:1. ## Project repository The work on the timeline is done and documented at the repository [https://github.com/kreier/timeline](https://github.com/kreier/timeline). The idea for this project started with spreadsheets in 2009. I moved to vector graphics in 2015. Then from 2023 on it was finally generated with a python program and the __reportlab package__ to make the creation, translation and editing much faster and easier. We stopped using reportlab with version 4.6 in summer 2024 and moved to [fpdf2](https://py-pdf.github.io/fpdf2/index.html) with 4.7 to support complicated glyph composition for languages like Khmer, Sinhala and Arabic that requires a specific shape engine like [harfbuzz](https://github.com/harfbuzz/harfbuzz). ## Improvement - report mistakes If you spot a mistake, please add an issue at [https://github.com/kreier/timeline/issues](https://github.com/kreier/timeline/issues) ## Create your own PDF in a browser To greate your own version just using a browser you can try out this [Jupyter Notebook at Google Colab](https://colab.research.google.com/drive/1G0z6jKIs_B_Md_y6Wen108Keo5WazalZ?usp=sharing). Simply press __Runtime - Run all__. It requires less than 60 seconds. Since June 2024 there is also [a version 4.7 with fpdf2](https://colab.research.google.com/drive/1WbLz2Gz775j0bSFPHdQihAkub3wltAof?usp=sharing) to support RTL scripts, Khmer and Sinhala. - Jupyter notebook [in Google Colab with reportlab](https://colab.research.google.com/drive/1G0z6jKIs_B_Md_y6Wen108Keo5WazalZ?usp=sharing) - Jupyter notebook [in Google Colab with fpdf2](https://colab.research.google.com/drive/1WbLz2Gz775j0bSFPHdQihAkub3wltAof?usp=sharing) ## Edit your own edition in a browser To edit the files in the browser its best to have your own Github account. Fork the [timeline](https://github.com/kreier/timeline) repository and create a Codespace within the fork. Install the needed 3 libraries (reportlab, svglib and googletranslate) and the CSV extention to Visual Studio Code. You're good to go! Change everything you want - just using the browser."
https://github.com/kreier/cru/blob/main/README.md,"# Custom Resolution Utility (CRU) [![GitHub Release](https://img.shields.io/github/v/release/kreier/cru)](https://GitHub.com/kreier/cru/releases/) ![GitHub License](https://img.shields.io/github/license/kreier/cru) [![pages-build-deployment](https://github.com/kreier/cru/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/cru/actions/workflows/pages/pages-build-deployment) This is just a fork of the work from [ToastyX](https://www.monitortests.com/forum/User-ToastyX). Since 2012 [his utility](https://www.monitortests.com/forum/Thread-Custom-Resolution-Utility-CRU) fixes several problems with graphic cards, monitors, drivers and their communication. Please download the latest version 1.5.3 from 2025-04-28 directly from [https://www.monitortests.com/forum/Thread-Custom-Resolution-Utility-CRU](https://www.monitortests.com/forum/Thread-Custom-Resolution-Utility-CRU) and consider supporting him [on Patreon](https://www.patreon.com/ToastyX). Custom Resolution Utility (CRU) is an **EDID editor** that focuses on custom resolutions. CRU shows you how the monitor defines resolutions and other capabilities and gives you the power to change it. Add custom resolutions, remove unwanted resolutions, edit FreeSync ranges, and more. CRU creates software EDID overrides in the registry and does not modify the hardware. [![Patreon support](docs/patreon.png)](https://www.patreon.com/ToastyX) ## Compatibility issues: ### NVIDIA and DSC - ToastyX Wrote: ``` NVIDIA's driver currently ignores EDID overrides if Display Stream Compression (DSC) is active and the maximum resolution @ refresh rate combination exceeds the GPU's single-head pixel clock limit: GTX 1600-series: 1330 MHz RTX 2000-series: 1330 MHz RTX 3000-series: 1335 MHz RTX 4000-series: 1350 MHz RTX 5000-series: 1620 MHz ``` Workarounds: 1. SRE can add custom GPU-scaled resolutions but not custom refresh rates: https://www.monitortests.com/forum/Threa...Editor-SRE 2. Use RegEdit to disable using multiple heads, but the pixel clock will be limited to the single-head limit:\ Key: HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Class\{4d36e968-e325-11ce-bfc1-08002be10318}\#### (usually 0000)\ Value: ""EnableTiledDisplay""=dword:00000000 ### NVIDIA and multiple displays - ToastyX Wrote: NVIDIA's driver currently has a bug that can cause Windows to hang during boot when an EDID override is present with multiple displays connected. Workaround using scripts: [https://www.monitortests.com/forum/Threa...wn-scripts](https://www.monitortests.com/forum/Thread-Workarounds-for-Nvidia-issues-using-CRU-and-a-couple-of-startup-shutdown-scripts) ### Windows 11 with non-PnP displays - ToastyX Wrote: Windows 11 ignores EDID overrides for displays that don't have a valid EDID. This can happen if the EDID is corrupted on the monitor. This will appear as ""PNP09FF - Generic Non-PnP Monitor"" in CRU with no resolutions or extension blocks listed. Workarounds: 1. Try another port on the monitor. Usually each type of port has a separate EDID, so only one might be corrupted. 2. Use an EDID emulator such as this: [https://www.amazon.com/dp/B07YMS18T7/?tag=mtests-20#ad](https://www.amazon.com/dp/B07YMS18T7/?tag=mtests-20#ad) 3. Use Windows 10 with CRU to add the resolutions you need. 4. Advanced: try to fix the EDID on the monitor using EDWriter with an AMD GPU: [https://www.monitortests.com/forum/Threa...yID-Writer](https://www.monitortests.com/forum/Thread-EDID-DisplayID-Writer) ## Example This is how this Windows program looks like: ![sample image](docs/example.png) ### Requirements: - Windows Vista or later (Windows XP does not support EDID overrides) - AMD/ATI or NVIDIA GPU with appropriate driver installed (Microsoft Basic Display Adapter driver does not support EDID overrides) - Intel GPUs and laptops with switchable graphics are supported with one of these drivers: - Newer Intel GPUs are supported with the latest drivers. - 6th generation (Skylake): [Intel Graphics Driver for Windows [15.45]](https://downloadcenter.intel.com/download/30195) - 4th/5th generation (Haswell/Broadwell): [Intel Graphics Driver for Windows [15.40]](https://downloadcenter.intel.com/download/30196) - 4th generation (Haswell) for Windows 7/8.1: [Intel Graphics Driver for Windows 7/8.1 [15.36]](https://downloadcenter.intel.com/download/29970) - Older Intel GPUs are supported for external displays only using the alternative method described below. Before making any changes, familiarize yourself with booting Windows in safe mode using a recovery drive in case you can't see the screen. If you don't have a recovery drive, press and hold the power button to shut off the computer while Windows is booting. Doing this twice should give you recovery options that you can use to get into safe mode: Troubleshoot > Advanced options > Startup Settings > Restart ### Getting started: 1. Run CRU.exe. A UAC prompt may appear because it needs permission to access the registry. 2. Choose a display from the drop-down list. - ""(active)"" means the display is connected and recognized by the graphics driver. - ""*"" means changes were made and an override was saved in the registry. 3. Edit the configuration as desired. __Please read the sections below for more information.__ 4. Repeat steps 2-3 for other displays if required. - The ""Copy"" and ""Paste"" buttons at the top can be used to copy all the resolutions, extension blocks, and range limits if included. It will not copy the name or serial number, but it will copy the inclusion of these items using the display's own information. Import follows the same logic unless ""Import complete EDID"" is selected. 5. Click ""OK"" to save the changes. 6. Run restart.exe to restart the graphics driver. - If the display does not return after 15 seconds, press F8 for recovery mode. This will temporarily unload all the EDID overrides without deleting them. Restart the driver again to reload any changes. - On some systems, the graphics driver might crash while restarting. If that happens, the driver might be disabled after rebooting. Simply run restart.exe again to enable the driver. 7. Set the resolution in the Windows display settings. To set the refresh rate: - Windows 10: right-click on the desktop > Display settings > Advanced display settings > Display adapter properties > Monitor tab - Windows Vista/7/8/8.1: right-click on the desktop > Screen resolution > Advanced settings > Monitor tab To reset a display back to the default configuration, use the ""Delete"" button at the top to delete the override from the registry and reboot. To reset all displays, run reset-all.exe and reboot. This can be done in safe mode if necessary. ### Alternative method for Intel GPUs: If you have an older Intel GPU, use the ""Export..."" button and choose ""EXE file"" for the file type to export a self-contained EDID override installer. Then run the .exe file and choose ""Install EDID"" to install the EDID override on all matching displays. ### Detailed resolutions: * Detailed resolutions are the preferred way to add custom resolutions. More detailed resolutions can be added using extension blocks. * The first detailed resolution is considered the preferred or native resolution. At least one detailed resolution should exist to define the native resolution. All other resolutions can be removed if they are not needed. The graphics driver will automatically add some common lower resolutions as scaled resolutions. To edit the list of scaled resolutions for AMD and NVIDIA GPUs, use [Scaled Resolution Editor](https://www.monitortests.com/forum/Thread-Scaled-Resolution-Editor-SRE). * CRU adds monitor resolutions, not scaled resolutions. Lower resolutions can be scaled up to the native resolution by enabling GPU scaling in the graphics driver's control panel, but higher resolutions won't be scaled down by the GPU. Higher resolutions will only work if the monitor can handle them. * Laptop displays usually don't have scalers and can't display non-native resolutions without GPU scaling. To add other refresh rates, add the refresh rate at the native resolution. The graphics driver will automatically add the refresh rate to lower scaled resolutions. * Monitors with NVIDIA's G-SYNC processor only support a limited set of resolutions with display scaling. To add non-native resolutions, make sure GPU scaling is enabled in the NVIDIA control panel, or use [Scaled Resolution Editor](https://www.monitortests.com/forum/Thread-Scaled-Resolution-Editor-SRE). * EDID detailed resolutions are limited to 4095x4095 and 655.35 MHz pixel clock. If a value turns **red** , that means it's invalid or out of limits. Use a DisplayID extension block to add resolutions with higher limits. * Use the timing options to help fill in the values: * Manual - Allows the timing parameters to be set manually. The dialog will always open in this mode. See also: [Timing parameters explained](https://www.monitortests.com/blog/timing-parameters-explained/) * Automatic PC - Uses standards common with PC monitors. Uses CTA-861 for 4:3/16:9 resolutions up to 1920x1080 @ 60 Hz, VESA DMT for 1360/1366x768 and 1600x900, CVT-RB otherwise. * Automatic HDTV - Uses standards common with HDTVs. Uses CTA-861 for all TV resolutions if possible, VESA DMT for 1360/1366x768 and 1600x900, CVT-RB otherwise. * Automatic CRT - Uses standards compatible with CRT monitors. Uses VESA DMT for 4:3/5:4 resolutions, CVT otherwise. * Native PC/HDTV - Uses the 60 Hz ""Automatic"" timing parameters for all refresh rates. This may help when trying other refresh rates. * Exact - Uses non-standard timing parameters to produce exact integer refresh rates. * Exact reduced - Adjusts the ""Exact"" timing parameters to reduce the pixel clock if possible. This may help when trying higher refresh rates. * Exact CRT - Uses timing parameters compatible with CRT monitors to produce exact integer refresh rates. * VESA standards: * CVT standard - Standard intended for CRT monitors. * CVT-RB standard - Standard intended for LCD monitors. Reduces the blanking compared with CVT. * CVT-RB2 standard - Newer standard intended for LCD monitors. Reduces the horizontal blanking compared with CVT-RB. * GTF standard - Old standard commonly used with CRT monitors. * Vertical total calculator - Calculates the vertical total required for the specified refresh rate and pixel clock. This can be used to implement [Quick Frame Transport (QFT)](https://forums.blurbusters.com/viewtopic.php?t=8946), which can help reduce crosstalk with backlight strobing at lower refresh rates. * __Pay attention to pixel clock limits:__ * Single-link DVI is limited to 165 MHz and dual-link DVI is limited to 330 MHz unless the graphics driver is patched: * [AMD/ATI Pixel Clock Patcher](https://www.monitortests.com/forum/Thread-AMD-ATI-Pixel-Clock-Patcher) * [NVIDIA Pixel Clock Patcher](https://www.monitortests.com/forum/Thread-NVIDIA-Pixel-Clock-Patcher) * HDMI is treated as single-link DVI unless an ""HDMI support"" data block is defined in a CTA-861 extension block. * HDMI 2.0 requires both an ""HDMI support"" data block and an ""HDMI 2.0 support"" data block. * HDMI limits depend on the GPU: * Newer GPUs with HDMI 2.0 support up to 600 MHz with HDMI 2.0 and up to 340 MHz with HDMI 1.x. * AMD HD 7000-series and newer GPUs without HDMI 2.0 support up to 297 MHz. Older GPUs are limited to 165 MHz unless the driver is patched. * Intel GPUs without HDMI 2.0 support up to 300.99 MHz. * AMD/ATI and Intel also listen to the maximum TMDS clock in the ""HDMI support"" data block. Make sure it's enabled and set to 340 MHz. * DisplayPort limits are listed here: [Common pixel clock limits](https://www.monitortests.com/blog/common-pixel-clock-limits/) * Passive DisplayPort to HDMI adapters are limited to 165 MHz unless the driver is patched. * These DisplayPort to HDMI 2.0 active adapters support up to 600 MHz pixel clock (Amazon affiliate links): * [Plugable DisplayPort 1.2 to HDMI 2.0 Active Adapter](https://www.amazon.com/dp/B00S0C7QO8/?tag=mtests-20#ad) * [Club 3D CAC-1080 DisplayPort 1.4 to HDMI 2.0b HDR Active Adapter](https://www.amazon.com/dp/B077JB28KM/?tag=mtests-20#ad) * [Club 3D CAC-1180 Mini DisplayPort 1.4 to HDMI 2.0b HDR Active Adapter](https://www.amazon.com/dp/B077J8655R/?tag=mtests-20#ad) ### Standard resolutions: * Standard resolutions are mostly useful for CRT monitors and for adding lower resolutions with LCD monitors. Do not add the native resolution as a standard resolution. * AMD/ATI only supports the resolutions in the drop-down list. Other resolutions will be ignored by the driver. These will be listed in gray. * NVIDIA does not support more than 8 standard resolutions. Additional resolutions will use up detailed resolution slots. * Standard resolutions are limited to certain aspect ratios: 4:3, 5:4, 16:9, 16:10. Use detailed resolutions for other aspect ratios. * The horizontal resolution is limited to 256-2288 and must be a multiple of 8. Use detailed resolutions for other resolutions. * The refresh rate is limited to 60-123 Hz. Use detailed resolutions for other refresh rates. ### Extension blocks: * GPU-specific limtations: * CRU can read extension blocks from displays connected to AMD and NVIDIA GPUs. * CRU can't read extension blocks with Intel GPUs or switchable graphics. * Older drivers or GPUs may only support up to 3 extension blocks. * Extension block types: * CTA-861 extension blocks can contain additional detailed resolutions and data blocks such as TV resolutions, audio formats, and HDMI support. Note: NVIDIA requires at least 2 bytes left for data blocks or the driver will ignore all changes. * Use VTB-EXT to add more standard resolutions. Note: AMD/ATI only supports one VTB-EXT block, and it must be the last block in the list. * Use DisplayID to add resolutions greater than 4095x4095 or 655.35 MHz pixel clock. DisplayID 2.0 supports pixel clocks with three decimal places, but the driver or hardware might not support such precision. * Default extension blocks are placeholders for the monitor's original extension blocks. Extension blocks that can't be read will appear as default extension blocks. Note: NVIDIA does not support default extension blocks and will ignore all changes if a default extension block exists. * If you need to add an extension block manually, importing one of these files will provide a starting point: * [hdmi.dat](https://www.monitortests.com/download/dat/hdmi.dat) - HDMI support only * [hdmi-audio.dat](https://www.monitortests.com/download/dat/hdmi-audio.dat) - HDMI support with audio * [hdmi-bitstream.dat](https://www.monitortests.com/download/dat/hdmi-bitstream.dat) - HDMI support with bitstreaming audio formats * [hdmi2.dat](https://www.monitortests.com/download/dat/hdmi2.dat) - HDMI 2.0 support only * [hdmi2-audio.dat](https://www.monitortests.com/download/dat/hdmi2-audio.dat) - HDMI 2.0 support with audio * [hdmi2-bitstream.dat](https://www.monitortests.com/download/dat/hdmi2-bitstream.dat) - HDMI 2.0 support with bitstreaming audio formats * [displayport-audio.dat](https://www.monitortests.com/download/dat/displayport-audio.dat) - DisplayPort audio ### Editing FreeSync/VRR ranges: * For DisplayPort, use the ""Edit..."" button at the top to edit the ""V rate"" under range limits, and make sure ""Include if slot available"" is enabled. Note: NVIDIA has ranges hard-coded for some monitors. To get around this, change the device ID at the top to anything else, such as ABC1234 (3 letters, 4 hex digits). * For HDMI FreeSync, edit the ""FreeSync range"" data block in the CTA-861 extension block. * For HDMI 2.1 VRR, edit the ""HDMI 2.1 support"" data block in the CTA-861 extension block. ### Export formats: * .bin - Raw binary EDID compatible with most EDID tools * .dat - Data file compatible with Phoenix EDID Designer and Advantiv EEditZ/EEditGold * .inf - Unsigned monitor driver compatible with Windows Vista and later * .txt - Text file containing whitespace-separated hexadecimal values (16 per line) * .csv - Text file containing comma-separated hexadecimal values (one block per line) * .exe - Self-contained EDID override installer (includes alternative method for Intel GPUs) CRU can import all of the above formats and any reasonably formatted text file with hexadecimal values. ### Command-line options: * Exported .exe files: * /i - Install EDID without prompting * /r - Reset EDID without prompting * reset-all.exe: * /q - Reset without prompting * restart.exe/restart64.exe: * /q - Restart without prompting (or rename the file to restart-only.exe) * /r - Activate recovery mode without prompting ### Memory clock issues: * The GPU will not reduce the memory clock when idle if the vertical blanking is too low because there won't be enough time between refreshes to retrain the memory without screen corruption. Horizontal values can still be reduced if necessary. * Older AMD/ATI GPUs require the ""Automatic PC/HDTV"" or ""CVT-RB standard"" vertical blanking to reduce the memory clock when idle. * NVIDIA and newer AMD cards can handle some lower values depending on the resolution and refresh rate. * Older AMD/ATI GPUs have a design limitation that causes video acceleration to scramble the screen if the vertical blanking is below standard with the GPU's memory overclocked or with multiple monitors connected. Skype is known to trigger this problem. Either don't overclock the GPU's memory, or use the ""Automatic PC/HDTV"" or ""CVT-RB standard"" vertical blanking. ## Changelog ### 2025-04-28 Changes in 1.5.3: * Added support for extension override data blocks (HF-EEODB). All extension blocks should now be readable with AMD and NVIDIA GPUs. * Added support for editing existing FreeSync version 3 data blocks with higher maximum range. * EDID detailed resolutions: preserve borders if present. ### 2022-09-01 Changes in 1.5.2: * Support up to 7 extension blocks * NVIDIA can now read all extension blocks * Detailed resolutions: * Added 480p/480i/525p/525i to ""Automatic CRT"" * Fixed ""Exact"" and ""Exact reduced"" for interlaced resolutions * Added ""Exact CRT"" timing option * Added ""Vertical total calculator"" timing option * Audio formats: added ""Auro-Cx"" and ""MPEG-D USAC"" from CTA-861.6 * Colorimetry: added ""sRGB"" and ""Default RGB"" from [CTA-861.6](https://shop.cta.tech/products/cta-861-6) ### 2021-01-18 Changes in 1.5.1: - Audio formats: added new formats from CTA-861-G/H - Colorimetry: added ICtCp from CTA-861-H - DisplayID 2.0 detailed resolutions: fix ""Reset"" button resetting to 6 Hz when adding a new resolution - Tiled display topology: split vendor and product IDs to accommodate OUIs (2.0) and non-letter IDs (1.3) - List boxes now retain scroll position after editing ### 2021-01-01 Changes in 1.5: - Added DisplayPort YCbCr color formats and maximum color depth (use the ""Edit..."" button at the top) - Added HDMI 2.1 features including maximum FRL rate, variable refresh rate, and display stream compression - New and improved timing options for detailed resolutions: - ""LCD standard"" has been split into ""Automatic (PC)"" and ""Automatic (HDTV)"" to better accommodate different display standards. - The main difference is how they handle resolutions greater than 1920x1080 @ 60 Hz and 21:9 resolutions. ""PC"" favors CVT-RB, while ""HDTV"" favors CTA-861. - ""LCD native"" has been split into ""Native (PC)"" and ""Native (HDTV)"" for the same reason. - ""LCD reduced"" has been eliminated because it was too arbitrary and only worked for certain resolutions. Try ""Exact reduced"" for an alternative. - ""CRT standard"" is now ""Automatic (CRT)"" and includes 4:3/5:4 VESA DMT resolutions. Use ""CVT standard"" for the old behavior. - Added ""Exact"" and ""Exact reduced"" to calculate exact integer refresh rates. - Added common display standards: CVT, CVT-RB, CVT-RB2, and GTF (previously ""Old standard"") - Detailed resolutions can now calculate frequencies for all possible pixel clocks (up to 167772.16 MHz for DisplayID 1.3) - CEA-861 extension blocks are now called CTA-861 to reflect the standard's new name - Added support for DisplayID 2.0 extension blocks - Export now saves the original unmodified EDID if no changes were made ### 2019-10-30 Changes in 1.4.2: - List inactive displays with overrides installed - Display properties: interpret ""0"" ID serial number as blank - Detailed resolutions: ""LCD reduced"" will no longer go below 56 horizontal blanking - DisplayID detailed resolutions: fixed interlaced calculations to match DisplayID standard - HDMI 2.0 support: enable ""SCDC present"" by default when adding new data blocks - Added `.csv` file export: outputs comma-separated hexadecimal values (one block per line) - Added `.exe` file export: outputs self-contained EDID override installers (includes alternative method for Intel GPUs) - `reset-all.exe`: Reset alternative method for Intel GPUs, added /q option - `restart.exe`/`restart64.exe`: Faster restarts, recovery mode includes alternative method for Intel GPUs, added /r option ### 2018-09-17 Changes in 1.4.1: - Speaker setup: added new speakers from CTA-861-G - HDMI support: fixed undefined latency data saving as 2 ms (since 1.3.99-p1) - HDMI 2.0 support: preserve additional fields for HDMI 2.1 - FreeSync range: added support for editing FreeSync 2 ranges - Added support for HDR static metadata blocks ### 2018-07-14 Changes in 1.4: - Added support for DisplayID extension blocks: - Added support for ""Type I"" detailed resolutions. - Added support for tiled display topology data blocks. - Display properties: added support for ID serial number in EDID header - Detailed resolutions: added ""Automatic - Old standard"" timing option for GTF - TV resolutions: added new resolutions from [CTA-861-G](https://web.archive.org/web/20171201033424/https://standards.cta.tech/kwspub/published_docs/CTA-861-G_FINAL_revised_2017.pdf) (requires driver support) - Colorimetry: added DCI-P3 standard from [CTA-861-G](https://archive.org/details/CTA-861-G/mode/2up) More about Display Technology Information at [https://glenwing.github.io/](https://glenwing.github.io/) with [Display Industry Standards](https://glenwing.github.io/docs/) like DP, HDMI, DVI, CTA-861, DCI and VESA ### 2018-01-24 Patch 1 v1.3.99-p1 Version v1.4 will be released later the year. Release notes for this patch version are later mostly transferred to v1.4. The source code for this version code is published. It can be found at https://github.com/radamar/Custom-Resolution-Utility-ToastyX where it was uploaded 2018-04-11. ### 2017-08-24 Changes in 1.3.1: - Fixed .inf export for Windows 10 Creators Update - Detailed resolutions: use CEA-861 timing parameters for `3840x2160 @ 60 Hz` with ""LCD standard"" (use ""LCD reduced"" for old values) - Detailed resolutions: allow 0 back porch - TV resolutions: disable ""Native format"" for resolutions that don't support this option - Do not add blank extension block if no extension blocks exist by default - Allow invalid but possible product IDs when editing display properties - Fixed '`&`' character in monitor name and serial number not displaying correctly in detailed resolutions list box - Improved row spacing between UI elements with higher DPI settings ### 2016-10-30 Changes in 1.3: * Added support for reading extension blocks from connected monitors with AMD/ATI and NVIDIA * Automatically add blank extension block in registry and exported .inf files to work around NVIDIA driver issues * Added support for multiple extension blocks * Added support for importing other types of extension blocks * Added support for VTB-EXT extension blocks (detailed/standard resolutions only) * Changed default TMDS clock to 340 MHz for new HDMI data blocks * Added support for HDMI 2.0 data blocks * Added support for HDMI FreeSync data blocks * Added BT.2020 formats in colorimetry data blocks * Added text file export (outputs hex values) * Improved UI scaling with higher DPI settings * `restart.exe`/`restart64.exe`: fix Start menu, search box, and Radeon Settings not responding after restarting ### 2016-09-28 Patch 2 for v1.2 in v1.2.99-p2 * Final patch for the old v1.2 a month before the new v1.3 is ready for release with many more features and extended support ### 2016-04-23 Patch 1 for v1.2 in v1.2.99-p1 * No major update yet, small patches for the 2015 version of `cru` until the release of v1.3 later the year ### 2015-12-22 Changes in 1.2.6: * Fixed a bug affecting non-PnP monitors since 1.2.3 (invalid EDID version with new overrides) ### 2015-12-04 Changes in 1.2.5: * Include range limits by default if min/max horizontal values match and certain conditions are met (for * * * FreeSync monitors) * `restart.exe`/`restart64.exe`: restart Radeon Settings (`cnext.exe`) ### 2015-11-20 Changes in 1.2.4: * Made range limits compatible with FreeSync monitors ### 2015-11-17 Changes in 1.2.3: * Added basic support for range limits and serial number descriptors (use the ""Edit..."" button at the top) * Show included descriptors in the detailed resolution list * Added ""Import complete EDID"" option ### 2015-09-05 Changes in 1.2.2: * Detailed resolutions: added ""LCD reduced"" timing parameters for 2560x1440 @ 144 Hz and higher resolutions * Extension block: added support for colorimetry and video capability data blocks * Redesigned icon to scale better with Windows 10's broken taskbar scaling * Fixed how disabled buttons appear with Windows 10 ### 2015-07-28 Changes in 1.2.1: * Detailed resolutions: added ""LCD native"" option * TV resolutions: added support for 4:2:0 resolutions * HDMI support: added support for HDMI resolutions, latency information, and supported content types * Fixed access violation in `comctl32.dll` message with higher DPI settings * Fixed layout issues with higher DPI settings and enabled DPI awareness * `restart.exe`/`restart64.exe`: implemented a better recovery mode ### 2015-02-14 Changes in 1.2: * Added custom extension block editing * Added support for more than 8 standard resolutions (AMD/ATI only) * Added support for other standard resolutions (NVIDIA only) * Updated `reset-all.exe` to reset Windows resolution settings * Include new version of `restart.exe`/`restart64.exe` ### 2014-04-05 Changes in 1.1.2: * Fixed HDMI audio not working with older ATI GPUs ### 2014-02-14 Changes in 1.1.1: * Fixed monitors with invalid signal type information not working with AMD/ATI GPUs * Added ""LCD standard"" timing parameters for 3840x2160 @ 30 Hz and 1366x768 @ 60 Hz (use ""LCD reduced"" for old values) * Automatically enable extension block when importing extension block files * Show number of slots left ### 2013-10-01 Changes in 1.1: * Import extension block from files (editing coming later) * Automatically fill in likely native resolution when adding a detailed resolution * Disable controls when deleting a monitor ### 2013-08-24 Changes in 1.0.1: * Fixed `.inf` export * Added support for non-PnP monitors * Changed monitor list sorting ## Software environment for this C++ project As posted 2020-12-20 in this forum https://www.monitortests.com/forum/Thread-What-is-the-development-enviroment-of-open-source-software-CRU this software is written with Borland Turbo C++ Builder 2006."
https://github.com/kreier/ESP32/blob/main/README.md,"# ESP32 projects [![GitHub release](https://img.shields.io/github/release/kreier/ESP32.svg)](https://GitHub.com/kreier/ESP32/releases/) [![MIT license](https://img.shields.io/github/license/kreier/ESP32)](https://kreier.mit-license.org/) After working with Arduino since 2015 I was more and more challenged by the limitations and needs of exernal modules to expand the capabilites. Since 2018 I started to first work with the [ESP8266](../ESP8266) thanks to the included WiFi and later to this ESP32 for faster speed, more storage and integrated Bluetooth. Thanks to advancements you can get now an TTGO T-Display with WiFi, LiPo battery charge controller, USB-C connector, two input buttons and 1.18"" color IPS display 135x240px for less than an original Arduino Uno (with just USB-B and nothing else). So let's list some repositories that build on the ESP32: ## [T-Display](../t-display) __2020/11/24__ A cost effective solution for students to enter the world of programming their own devices. With integrated display and battery connector their projects can be carried anywhere and the results shown to others. The integrated WiFi connects to the world. ## [Solarmeter](../solar/solarmeter) __2020/06/23__ Measures the created electric energy on our renewable energy station at AISVN including photovoltaic cells, wind generator, battery voltages and temperature ## [T200](../T200) __2019/04/08__ A robot car controlled by Bluetooth BLE . ## Further smaller projects The ESP32 are well suited for our data collection project at AISVN with many analog pins, deep sleep modes to work long on battery power and WiFi capabilities to transfer data to the internet. This is accompanied by sufficient fast processing power and large memory. Some projects that use the ESP32 are: - [TTGO T-Display ESP32 board](https://github.com/kreier/t-display) Small board with display, two buttons and battery connector 2020/11/24 - [solarmeter](https://github.com/kreier/solarmeter) Measures the created electric energy on our renewable energy station at AISVN including photovoltaic cells, wind generator, battery voltages and temperature 2020/06/23 - [T200](https://github.com/kreier/T200) robot car controlled by Bluetooth BLE 2019/04/08 - [Webserver in MicroPython](https://github.com/kreier/python2018/tree/master/micropython/webserver) with button control 2019/12/16 ![Webserver LED control](https://raw.githubusercontent.com/kreier/python2018/master/micropython/webserver/20191216.gif) This repository collects smaller [sniplets](sniplets) and projects that don't require its own repository. Some of these are: - [Blink2020](sniplets/Blink2020) only short flashing, HIGH/LOW easier to alter - [Blink2020sweep](sniplets/Blink2020sweep) find the pin the LED is attached to (different with every board ...) - [ESP32 power consumption](ESP32_power_consumtion) test script to place the ESP32 in different power modes to measure the energy consumption - [I2C scanner](sniplets/i2c_scan) scans the i2c bus for devices - [i2cdetect](sniplets/i2cdetect) replicates the output of the Raspberry Pi output. Here with rtc and flash on ZS-042: ``` i2cdetect Scanning address range 0x00-0x7F 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- 57 -- -- -- -- -- -- -- -- 60: -- -- -- -- -- -- -- -- 68 -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- ``` - [startup-post](startup-post) See a message at [https://sites.google.com/view/startup-post](https://sites.google.com/view/startup-post) after a succesfull boot and internet connection of your IoT project. ## Power Consumption The measurements were taken at 28/11/2020 and are documented in the Excel file in [ESP power consumption](https://github.com/kreier/ESP32/tree/master/sniplets/ESP32_power_consumption). All values are in mA: | | TTGO | TTGO | TTGO | WEMOS | DOIT | |---------------|:-------:|:---------:|:-------:|:------------:|:---------:| | USB | T18 3.0 | T-Display | T-Koala | LoLin32 lite | DEVKIT V1 | | on | 47 | 68 | 35,8 | 47 | 68 | | wifi | 70 | 83 | 100 | 83 | 100 | | wifi transmit | 85 | 108 | | 116 | 151 | | radio off | | | | 47 | 56 | | 80 MHz | 35 | | | 60 | 38 | | light sleep | 19 | 9 | 0,79 | 8 | 17 | | deep sleep | | 0,35 | | 4 | 16 | And now looking for prospect temp station candidates: | LiPo | T-Display | T-Koala | LoLin32 lite | |---------------|:---------:|:-------:|:------------:| | on | 68 | 50 | 43 | | wifi | 84 | 104 | 73 | | wifi transmit | 108 | 131 | 103 | | radio off | | 37 | 43 | | 80 MHz | | 21 | 24 | | light sleep | 9 | 2,5 | 1,6 | | deep sleep | 0,18 | 0,79 | 0,063 | ## History This repository started in March 2019. I was new to the ESP8266 and ESP32 and took the first steps with both, documentation on GitHub and using BLE. The [T200](https://github.com/kreier/T200) was a successful robot car project from this time, controlled by Bluetooth BLE. I wrote back then: > 2019/03/24 We had several Arduino Uno projects at our school. But soon you want to add some bluetooth or WiFi functionality to your project. You need another module, library, cable and so on. Why not use the ESP32 that has all that out of the box? And much more RAM and storage for data and all kinds of projects? That's why it's here. Let's start simple. ### [Visit the Wiki](https://github.com/kreier/ESP32/wiki)! ![ESP32](docs/IMG-5684.JPG) ## Blink Unlike the Arduino the build-in LED is not connected to pin 13, but pin 2. Everything else is the same. Once it blinks you know that the module works, you can upload stuff and you have a simple output signal for further experiments. If you use the board ""**DOIT ESP32 DEVKIT V1**"" you can use the ""**File > Examples > 01.Basics > Blink** out of the box. ## BLE with iPhone remote Bluetooth Low Energy BLE is a little more complicated than Bluetooth 2.0. The ESP can do both, and the serial connection with an ESP32 is pretty straight forward. Comparable with a HC-05. BLE is a little more complicated, because there are services, characteristics, descriptors, properties, values and several of them with their own UUID. Using nRF Connect, BLE Scanner and LightBlue it was easy to connect to the ESP with the build-in examples. But I wanted to use the remote app GoBLE. More in the [Wiki](https://github.com/kreier/ESP32/wiki)."
https://github.com/kreier/nam-electric/blob/main/README.md,# Nam's homework at the Tรดn ฤแปฉc Thแบฏng University ![GitHub Release](https://img.shields.io/github/v/release/kreier/nam-electric) ![GitHub License](https://img.shields.io/github/license/kreier/nam-electric) [![pages-build-deployment](https://github.com/kreier/nam-electric/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/nam-electric/actions/workflows/pages/pages-build-deployment) Solving homeworks with Nam Nguyแปn of the Tรดn ฤแปฉc Thแบฏng University in Saigon. ## 2025/09/27 Broken PEN conductor in a system with 3 devices ![part 1](images/2025-09-27_p1.jpg) ![part 2](images/2025-09-27_p2.jpg) ![part 3](images/2025-09-27_p3.jpg) ![part 4](images/2025-09-27_p4.jpg) Solution in a Jupyter notebook: > [File in Google Colaboratory](https://colab.research.google.com/drive/1uV5ceeU2U_ZtXH21PM6EcFd4qzqG1tay?usp=sharing)
https://github.com/kreier/movies/blob/main/README.md,"# Movies ![GitHub Release](https://img.shields.io/github/v/release/kreier/movies) ![GitHub License](https://img.shields.io/github/license/kreier/movies) [![pages-build-deployment](https://github.com/kreier/movies/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/movies/actions/workflows/pages/pages-build-deployment) **Evaluate your media consumption** This project started in 2013. From that year on I took notes which movie I watched in which year. I got a 2-dimensional graph for the last 6 years of an ever growing number of movies. This chart of 7 years already indicates that we probably mostly watch recent movies. ![10 year graph](docs/movies2020.png) Since I took a mark if I watched a movie, the database goes back to 1921 with more than 4500 movies. As of now I watched 1335 of them. But rarely a new movie from long ago makes it to the list. Or if it does, I've already seen it and it doesn't show up. We're just watching the classics ... ![45 year graph](docs/movies1975-2020.png) ## Purpose of this repository As with many data collections it started out as an excel worksheet. Over time the demand on the data extends the capabilties of a spreadsheet document. I want to convert it to a .csv data file and then start to analyse and extend in python on kaggle or colaboratory with a jupyter notebook. Goals: - Find the associated IMDB number for this movie for future reference. - Add a recent number of global revenue from boxofficemojo. - Indicate the original language of the movie. The last point came to my attention only in 2019 and 2020 when rather unknown movies made it into the top100 grossing movies of that year. Turns out that the movie market in China has grown in the years since I started this project in 2013 that their domestic market was strong enough to compete with Hollywood. BTW: I included some german movies that were not really recognized somewhere else in the world. ## Update 2025 By now my movie list has 5000 entries and I watched more than 1500 of them. ![released and watched](docs/movies2025.svg) And just how many movies I watch per year: ![movies per year](docs/movies2025per_year.svg) ## History This project started 2014 on hofkoh.de. Here are the two posts from that time (https://hofkoh.de/2014/10/filmliste/ and https://hofkoh.de/2015/06/medienkonsum-die-zweite/): ### Filmliste 2014/10/26 Immer wieder werden mir Filme empfohlen, die ich โunbedingt gesehen haben mussโ. Gleichzeitig kann ich selten auf gemeinsame Filmzitate zurรผckgreifen, weil der jeweils andere den Film nicht gesehen hat. So kam irgendwann die Idee auf, eine Filmliste zu erstellen. Hier ist die passende Datei im Excelformat und hier im ODS-Format (OpenOffice und LibreOffice). Die Liste umfasst mitlerweile 3800 Filme, die vornehmlich aus den TOP100 der vergangenen 34 Jahre auf Basis von boxofficemojo.com zusammengestellt ist. Natรผrlich fehlen einige wichtige Filme ๐ Hinterlasst mir dazu einfach einen Kommentar, dann gibtโs ein Update. Meine 904 gesehenen Filme habe ich nach Jahren sortiert noch weiter ausgewertet: ![Filmliste](https://raw.githubusercontent.com/kreier/movies/refs/heads/main/docs/history/Filmhistory.png) In den letzten Jahren haben ich wohl 30-40 Filme pro Jahr gesehen, ein Teil davon nicht unbedingt im Kino, sondern auf DVD oder im Fernsehen. Vor 1985 ist es allerdings recht dรผnn. Fernsehfilme sind natรผrlich ebensowenig enthalten wie Serien, Computerspiele, Handygames und Konsolenspiele. Listen dazu folgen spรคter. ![Filmliste 2](https://raw.githubusercontent.com/kreier/movies/refs/heads/main/docs/history/Filmhistory2.png) **Comment:** > Nadine: Ich sage nur โ ich Nummer 1, Du Nummer 2โฆ 2015/06/16 Macht man nix. Laut boxofficemojo.com gibt es Mitte 2016 insgesamt 645 Filme, die weltweit mehr als 200 Millionen Dollar eingespielt haben. In den Top 10 finden sich erstaunlich viele Filme der letzten Jahre oder gar des letzten Jahres. ### Medienkonsum die Zweite 2015/06/09 Natรผrlich kann man sehr viel Zeit mit Kinofilmen verbringen, aber das ist nichts im Vergleich zu Serien, Soaps, Dokus, Animes und Zeichentrickfilmen im Fernsehen. Passend zum alten Projekt habe ich also eine erste Liste mit 192 Serien der vergangenen Jahre aufgestellt. Solltet Ihr meinen, dass eine wichtige Serie fehlt, dann schreibt es einfach in den Kommentar, es wird aktualisiert. So sind aber schon mal 129139 Episoden enthalten, also 92462 Stunden Unterhaltung. Man brรคuchte 10 1/2 Jahre, um alle Episoden ohne Unterbrechung hintereinander zu schauen. Hier ist die Liste. Auch die alte Liste mit Kinofilmen habe ich aktualisiert, sie enthรคlt jetzt 4000 Filme bis 2015: Datei als XLSX. Ganz will ich die Listen aber nicht vervollstรคndigen. Das hat auch mit dem inflationรคren Anzahl von Serien zu tun, welches durch Eigenproduktionen von Netflix, Amazon und watchever noch beschleunigt wird. Dazu ein Detail aus Wikipedia zu Serien, die einen eigenen Artikeln haben: - 1940er โ 3 Serien - 1950er โ 67 Serien - 1960er โ 239 Serien - 1970er โ 402 Serien - 1980er โ 626 Serien - 1990er โ 931 Serien - 2000er โ 1671 Serien - 2010er โ erst 1422 Serien, aber es bleiben noch 5 Jahre โฆ Soweit zu Filmen und Serien. Jetzt fehlt noch eine Liste mit Computerspielen. Ob hier jemand noch einen ZX81, Atari 600XL oder KC 85/3 kennt? Und dann Konsolen, PS3, PS4, XBOX, iPod touch, Android und iPhone und Tablets โ es wird endlos! Nicht zu vergessen den PC und Prince of Persia auf einem 286er mit 20MHz. **Comment:** Wo ist denn Homeland, The Closer, Monk, Downton Abbey, Dexter, Gilmore Girls, McLeods Tรถchter, Chigago Fire, Fringe, CSI: Cyber, Crossing Jordan, Criminal Intent, die 7 Reihen des โEs war einmal โฆโ, Seinfeld und Die Sopranos? 2015/06/09"
https://github.com/kreier/T400/blob/main/README.md,"# T400 [![GitHub release](https://img.shields.io/github/release/kreier/T400.svg?color=brightgreen)](https://GitHub.com/kreier/T400/releases/) [![MIT license](https://img.shields.io/github/license/kreier/T400?color=brightgreen)](http://opensource.org/licenses/MIT) [![pages-build-deployment](https://github.com/kreier/T400/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/T400/actions/workflows/pages/pages-build-deployment) Robot car with WiFi, programmed and controlled by MicroPython. The OLED screen gives information about status, connection and WiFi network to connect to (AP mode). ![T400](docs/T400-robotarm.jpg) ![T400 lite](docs/T400lite.jpg) ## Project This car was build during ASA session III in 2019/2020 at the AISVN. In 11 weeks from February 24th to May 22nd we successfully created 8 robot cars. Here are some pictures of the finished products: ### Key features Over the time of 3 months the students will reach different stages of their project, but here are some key features: - Central unit is a ESP8266 with 32 kByte RAM and 4 GByte Flash memory, running at 160 MHz. - The programming language is [MicroPython](https://en.wikipedia.org/wiki/MicroPython) with an interactive prompt [REPL](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop). - The control unit is powered by a standard 5V powerbank. - The drive unit is a caterpillar base with two 12V motors. - The robot car can be controlled via WiFi. - An OLED display 128x64 (ssd1306) gives status updates. ## Materials The materials used for this project were ordered at [IC ฤรY RแปI](https://icdayroi.com/), [thegioiic.com](https://thegioiic.com/) and [lazada.vn](https://www.lazada.vn/#). Here is a list of materials: | Nr | Name | Amount | Unit Price | Sum | Supplier | |:--:|-------------|:------:|-----------:|--------:|:--------------:| | 1 |ESP8266 NodeMCU | 1 | 83000 VND| 83000 VND| [link thegioiic](https://thegioiic.com/products/lua-esp8266-cp2102-nodemcu-wifi-module) | | 2 |Motor Shield L293D | 1 | 30000 VND| 30000 VND| [link thegioiic](https://thegioiic.com/products/esp12e-lua-l293d-de-ra-chan-wifi-esp8266-nodemcu) | | 3 |OLED display 126x64 I2C | 1 | 79000 VND| 79000 VND| [link thegioiic](https://thegioiic.com/products/lcd-oled-0-96inch-128x64-iic-4pin-chu-trang) | | 4 |Wires DuPont MF and FF | 20 | 300 VND| 6000 VND| [link thegioiic](https://thegioiic.com/products/day-be-cai-cai-dai-15cm) | | 5 |Robot caterpillar 12V unit | 1 | 483000 VND| 483000 VND| [link lazada.vn](https://www.lazada.vn/products/smart-tank-car-chassis-tracked-caterpillar-crawler-robot-platform-with-dual-dc-12v-motor-for-diy-for-arduino-t101-ptp101-i402162026-s693860633.html?spm=a2o4n.searchlist.list.162.24b0381feoC1Mg&search=1) | | 6 |Powerbank 10000 mAh 2 USB | 1 | 249000 VND| 249000 VND| [link nguyenkim](https://www.nguyenkim.com/pin-sac-du-phong-mili-power-shine-ii-hb-m90bk.html) | | 7 |DC step-up converter 5V 12V | 1 | 23000 VND| 23000 VND| [link thegioiic](https://thegioiic.com/products/xl6009-mach-tang-ap-4a) | | 8 |Robot 4DOF kit | 1 | 246000 VND| 246000 VND| [link lazada.vn](https://www.lazada.vn/products/4-dof-acrylic-chua-lap-rap-diy-canh-tay-robot-diy-bo-cho-arduino-may-lam-ho-tro-hoc-tap-sg90-servo-i267650656-s391094259.html) | | 9 |Servo SG90 | 5 | 29000 VND| 145000 VND| [link icdayroi](https://icdayroi.com/servo-sg90) | | 10 |Ultrasonic Module US-100 3.3V | 1 | 59000 VND| 59000 VND| [link thegioiic](https://thegioiic.com/products/us-100-module-cam-bien-sieu-am) | | 11 |I2C servo controller PCA9685 | 1 | 49000 VND| 49000 VND| [link thegioiic](https://thegioiic.com/products/pca9685-dieu-khien-dong-co-servo-12bit-pwm-6-kenh) | | 12 |USB male connector Type A | 2 | 1800 VND| 3600 VND| [link thegioiic](https://thegioiic.com/products/cong-usb2-0-typea-4pin-dau-duc-han-day) | | 13 |Buzzer 3.3 Volt | 1 | 3000 VND| 3000 VND| [link thegioiic](https://thegioiic.com/products/module-coi-buzzer-3-3v-5v) | | 14 |Screw M3 8mm | 8 | 550 VND| 4400 VND| [link thegioiic](https://thegioiic.com/products/vit-pm-m3-x-8mm) | | 15 |HEX-M3 spacer 15mm | 4 | 1000 VND| 4000 VND| [link thegioiic](https://thegioiic.com/products/tru-dong-hex-m3-cai-cai-dai-15mm) | | | | | VND| 1467000 VND| | ## Pin layout ![Pin esp8266](docs/esp8266_pins.jpg) ## Code This is an example of the MicroPython code we are going to use: ``` py from machine import Pin, I2C import ssd1306 # ESP32 Pin assignment # i2c = I2C(1, scl=Pin(22), sda=Pin(21)) # ESP8266 Pin assignment i2c = I2C(scl=Pin(12), sda=Pin(14)) oled_width = 128 oled_height = 64 oled = ssd1306.SSD1306_I2C(oled_width, oled_height, i2c) # draw some boxes for x in range(0, 127): # horizontal lines oled.pixel(x, 0, 1) oled.pixel(x, 15, 1) oled.pixel(x, 16, 1) oled.pixel(x, 63, 1) for y in range(0, 63): # vertical lines oled.pixel(0, y, 1) oled.pixel(127, y, 1) oled.text('T400 Robot Car', 8, 4) oled.text('Programmed in', 4, 22) oled.text('MicroPython on', 4, 32) oled.text('a ESP8266.', 4, 42) oled.text('Used at AISVN.', 4, 52) oled.show() ``` ## I2C connector `2020/07/09` Following the inspiration of SparkFun with their [QWIIC](https://www.sparkfun.com/qwiic#products) connector I tried to replicate the pin order. But instead of SMD 1.0 mm connector I just use the regular 2.54mm raster with XH connector on the board and respective 4 pin connector wire. ![QWIIC system](docs/qwiic.png) Following the same order the pins are assigned: 1. black - GND 2. red - 3.3 V 3. blue - SDA 4. yellow - SCL ![XH 2.54 connector](docs/xh254.jpg) The order does not match several OLED displays, but the ZS-042 rtc clock, the 1602 display adapter and many more. `2020/11/27` With the new [T-Display](https://kreier.github.io/t-display/) project I included the I2C connector as well. The pins look like this: ![I2C on T-Display](docs/x254-i2c.jpg) At the ESP32 SCL (SCK) is on GPIO 22 and SDA (SDI) is on GPIO 21."
https://github.com/kreier/T300/blob/master/README.md,"# T300 robot 3.0 with BLE, ultrasonic, robot arm and display [![MIT license](https://img.shields.io/github/license/kreier/T300?color=brightgreen)](http://opensource.org/licenses/MIT) ![GitHub Release](https://img.shields.io/github/v/release/kreier/T300) [![pages-build-deployment](https://github.com/kreier/T300/actions/workflows/pages/pages-build-deployment/badge.svg?branch=master)](https://github.com/kreier/T300/actions/workflows/pages/pages-build-deployment) This is the third iteration of our robots at AISVN as described in [the history](#history) further down. It used the Arduino Leonardo and incorporates: - Motorshield L298 with buzzer on pin4 - 4 DoF robot arm with 4 servos on pin A0 to A3 - Bluetooth Low Energy connection with pin 0 and 1 (Serial1) - PWM motor control on pin 10 to 13 - 1602 LCD display over I2C on pin 2 and 3 SDA SCL - MPU6050 gyroscope for location control on I2C - Ultrasonic distance with pin 7 (trigger) and pin 8 (echo/response) - PS2X controller at pin 5 SC, 6 CLK, A4 DAT and A5 CMD ## Materials We ordered the following materials for all students among others at [CแปฌA HรNG IC ฤรY RแปI](https://icdayroi.com/). This gives a common ground for further experiments both in software and hardware: nr name amount unit price price link 1 Arduino Leonardo 1 125.000 VND 125.000 VND link icdayroi.com 2 Robot base 4 wheels 1 140.000 VND 140.000 VND link icdayroi.com 3 Motor Shield L298 1 120.000 VND 120.000 VND link icdayroi.com 4 Bluetooth AT-09 1 75.000 VND 75.000 VND link icdayroi.com 5 Battery 18650 3.7V 2 35.000 VND 70.000 VND link icdayroi.com 6 Battery holder 2C 18650 1 7.000 VND 7.000 VND link icdayroi.com 7 Power switch MTS 102 1 4.000 VND 4.000 VND link icdayroi.com 8 Battery voltage display 1 22.000 VND 22.000 VND link icdayroi.com 9 Servo SG90 5 29.000 VND 145.000 VND link icdayroi.com 10 Ultrasonic module HC-SR04 1 20.000 VND 20.000 VND link icdayroi.com 11 Robot 4DOF kit 1 246.000 VND 246.000 VND link lazada.vn 12 Wires DuPont MF and FF 20 300 VND 6.000 VND link thegioiic.com 13 Voltmeter for Battery 1 21.000 VND 21.000 VND link thegioiic.com 14 Display 1602 3.3V white on blue 1 32.000 VND 32.000 VND link thegioiic.com 15 I2C serial to parallel adapter 1 13.500 VND 13.500 VND link thegioiic.com 1.046.500 VND Apart from these materials for 1.046.500 VND or 45 USD we need some time to assemble all parts - and then to program the robot car! Over the months of development several changes and standardizations took place. We ended up with a standard as platform at AISVN, to be found in the [respective github project](https://github.com/kreier/aisvn). ## Building steps * Assemble the robot * Connect the motors to M1 and M4 on the L293D shield * Connect the bluetooth module pin TXD to pin 8 of the motorshield ## Remote how to control with 10 keys | Key | Character | Mode 1 | Mode 2 | Mode 3 | Mode 4 | |:------:|:---------:|:--------:|:--------:|:------------:|:----------------:| | โ | F | forward | forward | | | | โ | B | backward | backward | | | | โ | L | left | left | left | | | โ | R | right | right | right | | | Select | M | Menu+ | Menu+ | Menu+ | Menu+ | | Start | S | Start | Return | toggle sound | start autonomous | | โณ | T | turbo | up | | | | โ | C | faster | open | | | | X | X | Stop | down | | Stop | | โ | Q | slower | close | | | - 'F' forward - 'B' backward - 'L' turn left - 'R' turn right - 'M' select (menu) - 'S' start - 'T' triangle - 'C' circle - 'X' button X - 'Q' sQuare ## Pin assignment | pin | general | used for | note | |:---:|:-------:|:------------------:|:--------------------:| | 0 | RX | Bluetooth RX | | | 1 | TX | Bluetooth TX | has voltage divider 1kฮฉ/2kฮฉ for 3.3V | | 2 | SDA | I2C | Display 1602 and | | 3~ | SCL | I2C | MPU 6050 gyroscope | | 4 | | buzzer | acoustic feedback | | 5~ | | PS2X CS | Chip Select (SPI SS) | | 6~ | | PS2X CLK | Clock (SPI SCLK) | | 7 | | Ultrasonic trigger | | | 8 | | Ultrasonic echo | | | 9~ | | Servo ultrasonic | | | 10~ | | E1 | enable Moter 1 (PWM) | | 11~ | | E2 | enable Motor 2 (PWM) | | 12 | | M1 | forward/backward | | 13 | LED | M2 | forward/backward | | A0 | | Servo left-right | Robotarm 5-175 | | A1 | | Servo up-down | Robotarm 45-120 | | A2 | | Servo forward-back | Robotarm 65-140 | | A3 | | Servo open-close | Robotarm 90-125 | | A4 | | PS2X DAT | Data (SPI MISO) | | A5 | | PS2X CMD | Command (SPI MOSI) | ### Issues After some time of use almost all of the boards no longer support PWM for pin 11 on the motor shield. Any value below 255 is interpreted as a low and the motor is shut off. Not very usefull for a motor project. Same is true for pin 1. Even though a voltage divider with 1kฮฉ/2kฮฉ is reducing the output voltage of the Arduino to 3.3 V several boards don't submit any signal. The bluetooth module can therefore only receive information, but not send them back. ## History - 2019-12-17 [T300](https://kreier.github.io/T300) this robot with 4 wheels, robot arm, ultrasonic distance sensor is the enhanced asa robot. Winner of the first AISVN robot competition [ROBOT 2019](https://sites.google.com/ais.edu.vn/robot2019). - 2019-11-04 [asa](https://github.com/kreier/asa) robot from first ASA period 2019/2020, evolved to T300 in the second period. After 9 sessions 60% of the students successfully finished their remote controlled robot. - 2019-04-08 [T200](https://github.com/kreier/T200) updated 2-wheel robot, controlled by an ESP32 over BLE and the software []() reverse engineered for our purpose. - 2019-03-26 [T80](https://github.com/kreier/T80) simplified version for Viet for the [Sciencefair 2019](https://sites.google.com/ais.edu.vn/sciencefair2019/grade-9) Design project. Has a L298N motor driver and HC-05 bluetooth module. Power supply was upgraded to LiIon because the 4 AA batteries provided not enough voltage for the bluetooth module once the motors where started. - 2018-10-25 [T110](https://github.com/kreier/T110) updated robot with Bluetooth 4.0 remote to be used by iOS devices. - 2018-10-09 [T100](https://github.com/kreier/T100) first robot with Bluetooth remote control, 2 wheels, L293D motorshield. ### Gallery ## Materials 2019 - has been updated We ordered the following materials at [CแปฌA HรNG IC ฤรY RแปI](https://icdayroi.com/) for all students to have a common ground for further experiments both in software and hardware: 1. [Arduino Leonardo](https://icdayroi.com/arduino-leonardo-r3) (because of the Micro-USB interface) 125.000โซ 2. [Khung xe robot 4 bรกnh](https://icdayroi.com/khung-xe-robot-4-banh) (4 wheels - stable driving) 140.000โซ 3. [Arduino Motor Shield L298](https://icdayroi.com/arduino-motor-shield-l298) 120.000โซ 4. [Module thu phรกt bluetooth HC-05](https://icdayroi.com/module-thu-phat-bluetooth-hc-05) 80.000โซ 5. [Pin Cell 18650 4200mAh 3.7V](https://icdayroi.com/pin-cell-18650-4200mah-3-7v) (4 AA batteries are not enough for motor and bluetooth, and not rechargable) 35.000โซ 6. [Hแปp ฤแบฟ pin 18650 loแบกi 2 cell](https://icdayroi.com/hop-de-pin-18650-loai-2-cell) battery holder for two 18650 batteries 7.000โซ 7. [Cรดng tแบฏc gแบกt MTS-103 3 trแบกng thรกi](https://icdayroi.com/cong-tac-gat-mts-103-3-trang-thai) power switch for the robot 5.500โซ 8. [ฤแปng hแป ฤo Vรดn (Volt) 3.5-30V](https://icdayroi.com/dong-ho-do-von-volt-3-5-30v) Voltage display to check the charge level of the battery 22.000โซ 9. Four 10 cm cable 0.25 mmยฒ to connect the motors to the shield โซ 10. Three female-male jumper wire to connect the bluetooth module to the Arduino (+3.3V, GND, RX) 11. So in general: some [jumper wires](https://icdayroi.com/bo-day-cam-test-board-65-soi) 19.000โซ 12. Maybe [a breadboard](https://icdayroi.com/testboard-mini-syb-170) to connect 5.000โซ All in all some 550.000โซ are already spend on these simple materials. Further steps include the collaborative project of a self driving robot ([Khung xe robot omni ฤa hฦฐแปng](https://icdayroi.com/khung-xe-robot-omni-da-huong) 2.250.000โซ), controlled by an [Raspberry Pi](https://thegioiic.com/products/raspberry-pi-4-model-b-2gb) 1.580.000 VND with [Camera](https://thegioiic.com/products/camera-8mp-imx219-160-degree-fov) 305.000 VND for object detection and obstacle avoidance. ### Future updates The above program consumes 91% of the available RAM of the Arduino Leonardo. For future projects we need more. Some contenstants: | Model | RAM instructions | RAM data | Flash | Clock | Pins | |:------------------:|-----------------:|:---------:|--------------:|---------:|:----:| | Arduino Leonardo | 2.5 KB | - | 32 KB | 16 MHz | 20 | | ESP8266 (NodeMCU) | 32 KB | 80 KB | 4000 KB | 160 MHz | 12 | | ESP32 (WROVER-32) | 520 KB | 4000 KB | 4000 KB | 240 MHz | 20 | | Raspberry Pi 1 | 512,000 KB | - | 16,000,000 KB | 700 MHz | 26 | | Raspberry Pi 4 | 4,000,000 KB | - | 64,000,000 KB | 1500 MHz | 40 | | Nvidia Jetson Nano | 4,000,000 KB | 473 GFLOP | 16,000,000 KB | 918 MHz | 40 |"
https://github.com/LiBeKra/KLZ/blob/main/README.md,"# KLZ - Klassenzeitung der Klasse 8a32 [![GitHub release](https://img.shields.io/github/release/LiBeKra/KLZ.svg)](https://GitHub.com/LiBeKra/KLZ/releases/) ![GitHub License](https://img.shields.io/github/license/LiBeKra/KLZ) [![pages-build-deployment](https://github.com/LiBeKra/KLZ/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/LiBeKra/KLZ/actions/workflows/pages/pages-build-deployment) Ein Schรผlerprojekt der 8a32 von der KGS Sittensen oder Ostetalschule. Mit viel Zusammenarbeit! ## Archiv - [2024-08-09](docs/Archiv/2024-08-09_Klassenskandal.pdf) Der Zรผndfunke fรผr unsere Klassenzeitung war jene Hausaufgabe in Deutsch. - [2024-08-12](docs/Archiv/2024-08-12.pdf) Erste Ausgabe fรผr die Woche vom 12. bis 16. August, verรถffentlicht am 18. August - [2024-08-19](docs/Archiv/2024-08-19.pdf) Zweite Ausgabe 19. - 23. August mit Geschichten von Dr. Pepper und Dr. med Rasen - [2024-08-26](docs/Archiv/2024-08-26.pdf) Dritte Ausgabe รผber die letzte Augustwoche, jetzt mit neuem Logo und QR code! - [2024-09-09](docs/Archiv/2024-09-09.pdf) Ausgabe 4: Mit Pseudonymen und Vertrag fรผr die Bilder, der Geschichtslehrer der Sigma - [2024-09-16](docs/Archiv/2024-09-16.pdf) Ausgabe 5: Die Schรผlerdiktatur. Und die explodierende Flasche. - [2024-09-25](docs/Archiv/2024-09-25.pdf) Ausgabe 6: Er kann reden, schreiben und sich versprechen. - [2024-12-16](docs/Archiv/2024-12-16.pdf) Die Winterausgabe zum Ende des Jahres 2024! Es ist Winter und Zeit fรผr Klassencomedy! - [2025-06-27](docs/Archiv/2025-06-27.pdf) Ausgabe 8: Die letzte ihrer Art? Oder ein Neuanfang? ![QR code](docs/Bilder/qr.png)"
https://github.com/LiBeKra/Probability-calculus/blob/main/README.md,"# Probability-calculus ![GitHub Release](https://img.shields.io/github/v/release/LiBeKra/Probability-calculus) ![GitHub License](https://img.shields.io/github/license/LiBeKra/Probability-calculus) [![pages-build-deployment](https://github.com/LiBeKra/Probability-calculus/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/LiBeKra/Probability-calculus/actions/workflows/pages/pages-build-deployment) Leider erst in Klasse 9 kam die 9a32 dazu, das alte Thema der 7. Klasse zur Wahrscheinlichkeitsberechnung im Matheunterricht durchzunehmen. Dabei macht es so viel Spass! Hier ein paar Hausaufgaben als Beispiele: ## 6 aus 49 > Schreibe ein Pythonprogramm um die Wahrscheinlichkeiten fรผr 6 aus 49 auszurechnen. ``` py import math def comb(n, k): return math.comb(n, k) # ab Python 3.8 verfรผgbar def lotto_probabilities(): total = comb(49, 6) # alle mรถglichen Tipps probs = {} for k in range(7): # 0 bis 6 Richtige # Anzahl der gรผnstigen Fรคlle: # k Richtige aus den 6 gezogenen Zahlen, und (6-k) Falsche aus den 43 รผbrigen favorable = comb(6, k) * comb(49 - 6, 6 - k) probs[k] = favorable / total return probs # Ausgabe probs = lotto_probabilities() print(""Wahrscheinlichkeiten fรผr 6 aus 49:\n"") for k, p in probs.items(): print(f""{k} Richtige: {p:.10f} ({p*100:.8f}%)"") ``` Und das Ergebnis ist: ``` Wahrscheinlichkeiten fรผr 6 aus 49: 0 Richtige: 0.4359649755 (43.59649755%) 1 Richtige: 0.4130194505 (41.30194505%) 2 Richtige: 0.1323780290 (13.23780290%) 3 Richtige: 0.0176504039 (1.76504039%) 4 Richtige: 0.0009686197 (0.09686197%) 5 Richtige: 0.0000184499 (0.00184499%) 6 Richtige: 0.0000000715 (0.00000715%) ``` ![graph visualizing the probability distribution](./docs/image/lotto.png) ## Drei Wรผrfel Die minimale Augenzahl fรผr drei Wรผrfel ist 3, die maximale ist 18. Fรผr beide Werte gibt es nur eine Mรถglichkeit. Wie sind aber die Wahrscheinlichkeiten der anderen Augenzahlen verteilt? ``` py # Erzeugt mit ChatGPT 5 # # Prompt: Create a column graph in text for the probability # of the outcome of 3 dices in python from collections import Counter import itertools # Calculate probabilities for 3 dice dice = [1, 2, 3, 4, 5, 6] sums = [sum(roll) for roll in itertools.product(dice, repeat=3)] counts = Counter(sums) # Normalize to probabilities total = len(sums) probs = {s: counts[s]/total for s in range(3, 19)} # possible sums from 3 to 18 # Scale probabilities to fit column graph height max_height = 20 scale = max_height / max(probs.values()) # Draw the column graph print(""Probability distribution of 3 dice (text column graph)\n"") for level in range(max_height, 0, -1): # top to bottom line = """" for s in range(3, 19): if round(probs[s] * scale) >= level: line += ""โโ "" # block character for column else: line += "" "" print(line) # Print labels at the bottom print("" "".join(f""{s:2}"" for s in range(3, 19))) ``` Das Ergebnis: ``` sh (v13) PS D:\github\LiBeKra\Probability-calculus\python> python .\zufall.py Probability distribution of 3 dice (text column graph) โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ โโ 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ``` Und das wird in Jupyter Notebook mit mathplotlib erzeugt: ![graph visualizing the probability distribution](./docs/image/three_dices.png)"
https://github.com/kreier/rp2040/blob/main/README.md,"# rp2040 ![GitHub Release](https://img.shields.io/github/v/release/kreier/rp2040) ![GitHub License](https://img.shields.io/github/license/kreier/rp2040) Example programs in CircuitPython and C for the Raspberry Pico 2040. We use it with 3 different external displays as more detailed optical output than just the led. ## 320x240 ili9341 3.2 inch tft ![ini9341](docs/ili9341.jpg) [3.2 inch display at thegioiic.com](https://www.thegioiic.com/lcd-3-2inch-320x240-tft-ili9341-giao-tiep-spi-v2-0) ## 240x240 st7789 1.3 inch waveshare tft ![st7789](docs/st7789.jpg) [1.3 tft display documentation at waveshare](https://www.waveshare.com/wiki/Pico-LCD-1.3) | TFT | Pico | Description | |-------|------|-----------------------------------------------------------| | VCC | VSYS | Power Input | | GND | GND | GND | | DIN | GP11 | MOSI pin of SPI, slave device data input | | CLK | GP10 | SCK pin of SPI, clock pin | | CS | GP9 | Chip selection of SPI, low active | | DC | GP8 | Data/Command control pin (High for data; Low for command) | | RST | GP12 | Reset pin, low active | | BL | GP13 | Backlight control | | A | GP15 | User button A ----- left button | | B | GP17 | User button B ----- right button | | X | GP19 | User button X | | Y | GP21 | User buttonY | | UP | GP2 | Joystick-up | | DOWN | GP18 | Joystick-down | | LEFT | GP16 | Joystick-left | | RIGHT | GP20 | Joystick-right | | CTRL | GP3 | Joystick-center | | SDA | GP0 | i2c data line for OLED and external sensors | | SCL | GP1 | i2c clock for OLED and external sensors | ## 128x64 sh1106 1.3 inch oled ![sh1106](docs/sh1106.jpg) [1.3 inch oled at thegioiic.com](https://www.thegioiic.com/lcd-oled-1-3inch-128x64-chu-xanh-duong-4-chan-giao-tiep-iic) ## 128x32 ssd1306 oled adafruit ![adafruit oled](docs/ssd1306.jpg) [Adafruit documentation circuitpython]() # rp2040 and i2c sensors We would like to just solder a 4-pin JST XH 2.54 mm pitch (0.1 "") connector to any of these boards and then use a standard XH-4 cable to connect to our ssis:bit without worrying about polarity or correct pin order: ![connector](docs/i2c_connector.jpg) The order of pins in the 1mm QUIIC connector is different from the order of the 4 pins found in virtually every hobby board with 2.54mm pins: ![sensors](docs/i2c_order.jpg) Hopefully we soon have a little shelf with all these different sensors for 'plug and play' and a software library on our boards."
https://github.com/kreier/ESP8266/blob/main/README.md,"# Projects with the ESP8266 ![GitHub Release](https://img.shields.io/github/v/release/kreier/ESP8266) ![GitHub commit activity](https://img.shields.io/github/commit-activity/t/kreier/ESP8266) ![GitHub License](https://img.shields.io/github/license/kreier/ESP8266) You can get a variety of different ESP8266 boards here in HCM, for less than $3. One resource is [CแปฌA HรNG IC ฤรY RแปI](https://icdayroi.com/). Another one is [Cรดng Ty thegioiic](https://www.thegioiic.com/). Here are some boards I got and used in 2018: ![ESP8266 boards](pic/esp8266.jpg) ## [Arduino C projects](arduino_c) ### [OLED Display driver sh1106 and ssd1306](./arduino_c/oled_animation_demo_sh1106) After some search I found the great libraries [u8glib](https://github.com/olikraus/u8glib) and [u8g2](https://github.com/olikraus/u8g2) from [Oli Kraus](https://github.com/olikraus). Just uncomment the correct line, connnect the 4 needed wires for the I2C connection of the display and you get the first output. The main libraries are - [u8glib](https://github.com/olikraus/u8glib) no longer active developed - [u8g2](https://github.com/olikraus/u8g2) for monochrome displays, includes __U8x8__ as well ### [I2C scanner](arduino_c/SH1106_SPI_I2C_scanner) Using SCL (D1 or GPIO5) and SDA (D2 or GPIO4) we get the hardware I2C of the ESP8266 and can scan for connected devices like RTC, 1Kbyte EEPROM, BME280 or 1602 displays. The 256bit ID is displayed on the 128x64 SH1106 SPI 1.13"" OLED display and the serial bus: The above image shows that both the RTC DS3231 on 0x57 as well as the 1k EEPROM AT24C32 on 0x68 have been found. Both are on the ZS-042 module. With A0, A1 and A2 the I2C address of the DS3231 could be altered. ### [Analog pin reader](arduino_c/read_analog) From zero to 3.1 Volt its a linear reading: ![linear input](arduino_c/read_analog/graph3.png) ### [Blink 2020](arduino_c/Blink2020) Different blink sequence and placeholder for various LED pins and HIGH/LOW combination: ```c /* Blink */ // T-Koala: 5 // Wemos lite: 4 // LORA915: 2 and ESP8266 NodeMCU, D1 R32 (Arduino size) // T8 V1.7: 21 // T-Dislay: // ATMega2560: 13 and Arduino Uno, Leonardo // int ledPin = LED_BUILTIN; int ledPin = 2; //bool light = HIGH; // LORA915, T-Koala, T8, Arduino //bool dark = LOW; bool light = LOW; // WEMOS Lite, ESP8266 NODEMCU bool dark = HIGH; ``` ## [ESP IDF](RTOS_SDK) Directly program to the board on the terminal with `~/ make flash monitor`. For example [CoreMark](../benchmark/CoreMark). ## IoTman In the window of our makerspace ... follows, with servo and LED, can be remotely controlled. Database on own webseite https://mypdesign.org or https://stemfair.org. Mal sehen. Das war ein Plan in 2018 - never happened, like the Makerspace."
https://github.com/kreier/rp2350/blob/main/README.md,"# rp2350 ![GitHub Release](https://img.shields.io/github/v/release/kreier/rp2350) ![GitHub License](https://img.shields.io/github/license/kreier/rp2350) Example programs in CircuitPython and C for the Raspberry Pico 2350. ## Benchmark prime ``` py import math import time last = 1000 found = 4 start = time.monotonic() print('Prime numbers to {}'.format(last)) for number in range(11, last, 2): prime = 1 if number % 3 == 0: prime = 0 elif number % 5 == 0: prime = 0 elif number % 7 == 0: prime = 0 if prime == 1: for divider in range(11, int(math.sqrt(number))+1, 2): if number % divider == 0: prime = 0 break if prime == 1: found += 1 end = time.monotonic() print('\nThis took:', (end - start), 'seconds.') print('Found: ',found) ``` ## CoreMark This has do be adjusted. And test the two RISC cores! ## CPU Frequency Easy tested with Circuitpython, has only 150 MHz instead of 200. Why? ``` py import microcontroller print(microcontroller.cpu.frequency) ```"
https://github.com/kreier/jetson/blob/main/README.md,"# Jetson Nano Developer Kit A02 4GB ![GitHub Release](https://img.shields.io/github/v/release/kreier/jetson) ![GitHub commit activity](https://img.shields.io/github/commit-activity/y/kreier/jetson) ![GitHub License](https://img.shields.io/github/license/kreier/jetson) I got the [Developer Kit A02](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit) (only one CSI camera interface, the B01 has two) of the [Jetson Nano](https://developer.nvidia.com/embedded/jetson-nano) in early 2020. In 2021 I added the case, proper power supply and Wifi Card. Early 2024 I started to use it again, but run into limitations very early. Here is part of the documentation. ## Structure - [Ubuntu Distribution limited to 18.04](#ubuntu-distribution-limited-to-1804) - [First start](#first-start) - 8 minutes - [Hardware limitations](#hardware-limitations) - [Memory bandwidth](#memory-bandwidth) - [Running Ollama on the Jetson - CPU only?](#running-ollama-on-the-jetson---cpu-only) - [Use of GPU not possible - 2024-07-25](#use-of-gpu-not-possible---2024-07-25) - [llama.cpp as an alternative?](#llamacpp-as-an-alternative) - [Probably CPU only 2024-04-11](#probably-cpu-only-2024-04-11) - [GPU accelerated b1618 2023-11-03](#gpu-accelerated-b1618-2023-11-03) - [GPU accelerated b2268 2024-04-11](#gpu-accelerated-b2268-2024-04-11) - [GPU accelerated b5050 2025-04-05](#gpu-accelerated-b5050-2025-04-05) - [OpenCL with POCL - Portable CL on the Jetson?](#opencl-with-pocl---portable-cl-on-the-jetson) - [Install LLVM](#install-llvm) - [Compile and install PoCL](#compile-and-install-pocl) - [Some tips](#some-tips) ## Ubuntu Distribution limited to 18.04 While some updated images with 20.04 exist, officially Nvidia only supports [18.04 LTS](https://en.wikipedia.org/wiki/Ubuntu_version_history#1804) from the [official website](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write). This version is 7 years old in 2025 and ended support in May 2023. This adds severe software limitations to the already existing hardware limitations: - Kernel GNU/Linux 4.9.201-tegra - GNU Compiler Collection 7.5.0 (G++ 7.5.0) from 2019 - NVIDIA Cuda Compiler nvcc 10.3.200 - Jetpack 4.6.1-b110 `sudo apt-cache show nvidia-jetpack` - Python 3.6.9 - No [OpenCL](https://en.wikipedia.org/wiki/OpenCL) (try fix with PoCL) ## First start The first system start (after having written the latest image from Nvidia to the SD card - 43 to 52 minutes) with some setup, useful software features and ssh login needs **less than 8 minutes**: - 2 minutes - First boot, a few clicks, setting timezone, username and other settings - 2 minutes - A new login screen, enter your password and click a few welcome messages - The system is now running after 48 minutes, and the OpenSSH server has already started, you can ssh into your machine - 4 minutes - A few changes, `apt update` (not upgrade), few packages and a reboot A few things you might want to do. Disable the graphical login. Update your apt repository (348 packages, 38 seconds). Install `jtop`. This will take another 3 minutes, followed by a reboot. ``` sh sudo systemctl set-default multi-user.target sudo apt update sudo apt install nano curl libcurl4-openssl-dev python3-pip sudo -H pip3 install -U jetson-stats sudo reboot ``` After this the system uses `df` some **12,615,632 Bytes** of the SD card. `jtop` reports `Jetpack 4.6.1 [L4T 32.7.1]`. A run of `sudo apt autoremove` will take 45 seconds and save 114 MBytes. The compiler `/usr/local/cuda/bin/nvcc --version` returns: ``` nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2021 NVIDIA Corporation Built on Sun_Feb_28_22:34:44_PST_2021 Cuda compilation tools, release 10.2, V10.2.300 Build cuda_10.2_r440.TC440_70.29663091_0 ``` The kernel is `uname -a`: Linux nano 4.9.253-tegra #1 SMP PREEMPT Sat Feb 19 08:59:22 PST 2022. Without the GUI its 383M/3.87G Mem used. Compiler `gcc --version` is: ``` gcc (Ubuntu/Linaro 7.5.0-3ubuntu1~18.04) 7.5.0 Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ``` ![Jetson nano with 7"" screen](https://kreier.github.io/jetson-car/pic/2024_jetson_nano.jpg) ## Hardware limitations The hardware was released 2019, based on the [Maxwell architecture](https://en.wikipedia.org/wiki/Maxwell_(microarchitecture)) of Nvidia from 2014. That's 11 years by 2025. - Quadcore [Cortex-A57](https://en.wikipedia.org/wiki/ARM_Cortex-A57) at 1428 MHz in [Tegra X1](https://en.wikipedia.org/wiki/Tegra#Tegra_X1) like Nintendo Switch and Nvidia Shield Pro - 4GB LPDDR4 with 25.60 GB/s bandwidth - 128 core Maxwell ([CUDA Compute Capabilty 5.3](https://www.techpowerup.com/gpu-specs/jetson-nano.c3643)) GPU with 472 GFLOPS at 921 MHz ### Memory bandwidth I checked the actual memory bandwidth with `sysbench`: ``` sh mk@jetson:~$ sysbench memory --memory-block-size=1m run sysbench 1.0.11 (using system LuaJIT 2.1.0-beta3) 68903.00 MiB transferred (6887.13 MiB/sec) ``` It looks like only 6.8 GB/s are usable with LPDDR4, not 25.60. This will limit the speed in token generation (TG) later. ## Running Ollama on the Jetson - CPU only? See [Nvidia Jetson AI Lab](https://www.jetson-ai-lab.com/index.html), it generally starts with the Jetson Orin Nano. The orignal Jetson is only there for comparison. For example the [Ollama tutorial](https://www.jetson-ai-lab.com/tutorial_ollama.html) not even mention the 4GB Orin model, and lists [JetPack 5](https://developer.nvidia.com/embedded/jetpack-sdk-514) (L4T r35.x) and [JetPack 6](https://developer.nvidia.com/embedded/jetpack-sdk-62) (L4T r36.x) as requirements. The [latest JetPack](https://developer.nvidia.com/embedded/jetpack) for the original Jetson Nano is [JetPack 4.6.6](https://developer.nvidia.com/jetpack-sdk-466) - see [the archive](https://developer.nvidia.com/embedded/jetpack-archive). You can install [ollama](https://ollama.com/) on this machine. The simple instruction is `curl -fsSL https://ollama.com/install.sh | sh`. And it does run llama3.2:1b with __3.77 token/s__ at 100% CPU. Gemma3 is faster with more than __5 t/s__. Is it possible to get GPU acceleration? The hardware should be able to, since Cuda CC >= 5.0 is required, and the Jetson has CC 5.3. ### Use of GPU not possible - 2024-07-25 As per this [ollama issue 4140](https://github.com/ollama/ollama/issues/4140) on Github it should not be possible to run ollama on the Jetson Nano. The challenge is the version of `gcc`. ``` sh mk@jetson:~$ nvcc --version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2021 NVIDIA Corporation Built on Sun_Feb_28_22:34:44_PST_2021 Cuda compilation tools, release 10.2, V10.2.300 Build cuda_10.2_r440.TC440_70.29663091_0 ``` - Ollma a requires gcc-11. CUDA 10.2 is not supported past gcc-8 - Nvidia provies for the Jetson Nano only JetPack 4.6, based on Ubuntu 18.04, with build-in CUDA 10.2. It includes gcc-7.5 As tested by dtischler in May 4, 2024 an upgrade to gcc-11 is relatively easy done, but CUDA and the GPU are not usable, and it falls back to CPU inference. Technically the Maxwell GPU with Cuda CC 5.3 should be supported by Cuda 12. But it would be privided by Nvidia with their [JetPack SDK](https://developer.nvidia.com/embedded/jetpack). And as the [list of old versions](https://developer.nvidia.com/embedded/jetpack-archive) indicate, the latest supported version for the Jetson Nano is 4.6.6. Since 5.1.1 the Jetson Orin Nano is supported. ## llama.cpp as an alternative? ### Probably CPU only 2024-04-11 You can compile and run llama.cpp on the Jetson Nano with a decent speed with the following commands: ``` git clone https://github.com/ggml-org/llama.cpp cd llama.cpp cmake -B build -DLLAMA_CURL=ON sudo cmake --build build --config Release ``` More in these repositories: - [https://github.com/kreier/llama.cpp-jetson](https://github.com/kreier/llama.cpp-jetson) Compile a new llama.cpp for CPU and also with CUDA for GPU acceleration - [https://github.com/kreier/llama.cpp-jetson.nano](https://github.com/kreier/llama.cpp-jetson.nano) Install precompiled binaries in minutes and start testing ![speed comparison](https://raw.githubusercontent.com/kreier/llama.cpp-jetson/main/docs/TinyLlama.png) ### GPU accelerated b1618 2023-11-03 Look [here](https://github.com/kreier/llama.cpp-jetson/tree/main/patch/b1618) and on medium. ### GPU accelerated b2268 2024-04-11 The following procedure seems to be obsolete, now that specific entries for the Jetson Nano are included in the Makefile for llama.cpp and even ollama runs out-of-the-box. The gist does not mention the use of the GPU with CUDA for acceleration. An gist [article by Flor Sanders](https://gist.github.com/FlorSanders/2cf043f7161f52aa4b18fb3a1ab6022f) from April 2024 describes the process of running llama.cpp on a 2GB Jetson Nano. With 4GB it should be possible to run a complete llama3.2:1b model file. But you can't use the provided gcc 7.5 compiler, you need at least 8.5 - so you compile it yourself over night. It needs around 3 hours to complete. Since I have a 32GB SDcard and 11 GB free it should be possible to compile GCC 8.5 overnight. But first we have to [add the link to nvcc](https://forums.developer.nvidia.com/t/cuda-nvcc-not-found/118068) the path. in `~/.bashrc` I have to add (with `nano`, that has to be installed too): ``` $ export PATH=/usr/local/cuda/bin${PATH:+:${PATH}} $ export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} ``` The recommended version of llama.cpp to check out is [a33e6a0](https://github.com/ggerganov/llama.cpp/commit/a33e6a0d2a66104ea9a906bdbf8a94d050189d91) from February 26, 2024. The current version of the Makefile has entries for the Jetson [in line 476](https://github.com/ggerganov/llama.cpp/blob/2e2f8f093cd4fb6bbb87ba84f6b9684fa082f3fa/Makefile#L476). It could well be that this only refers to run on the CPU (as with the mentioned Raspberry Pi's) and not using the GPU with CUDA. This aligns with the [error message by VViliams123](https://gist.github.com/FlorSanders/2cf043f7161f52aa4b18fb3a1ab6022f?permalink_comment_id=5219170#gistcomment-5219170) on October 4, 2024. ### GPU accelerated b5050 2025-04-05 Install a CUDA version of `llama.cpp`, `llama-server` and `llama-bench` on the Jetson Nano in one minute, compiled with `gcc 8.5`. Just type: ``` curl -fsSL https://kreier.github.io/llama.cpp-jetson.nano/install.sh | sh ``` If the path is not automatically adjusted, run `export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH` or add this line permanently with `nano ~/.bashrc` to the end. ## OpenCL with PoCL - Portable CL on the Jetson? An [article on Medium](https://yunusmuhammad007.medium.com/build-and-install-opencl-on-jetson-nano-10bf4a7f0e65) from September 2021 describes the installation of [PoCL](https://github.com/pocl/pocl) 1.7 on the Jetson Nano. By 2024 version 6.0 is the latest one, but it's not supported by PoCL. The reason [is described here](https://largo.lip6.fr/monolithe/admin_pocl/), and related to the old Ubuntu 18.04. That's why the latest version that can be installed is PoCL 3.0. This has been done successfully in October 2022. On ""old"" Jetson boards (TX2, Xavier NX, AGX Xavier & Nano), it is not possible to install recent PoCL version 5 because the OS is too old (Ubuntu 18.04) and it is complicated to install a recent version of the required Clang compiler (version 17). This is why on these specific boards we will install PoCL version 3. One of the main drawback is that there is no GPU 16-bit float support in this version ๐. Before we compile and install PoCL we need LLVM 11.1.0, the target-independent optimizer and code generator initially named *Low Level Virtual Machine* in 2003. ### Install LLVM Install the LLVM for ARM64 and Jetson Nano on Ubuntu 18.04 ([source](https://largo.lip6.fr/monolithe/admin_pocl/)): ``` bash export LLVM_VERSION=10 sudo apt install -y build-essential ocl-icd-libopencl1 cmake git pkg-config libclang-${LLVM_VERSION}-dev clang-${LLVM_VERSION} llvm-${LLVM_VERSION} make ninja-build ocl-icd-libopencl1 ocl-icd-dev ocl-icd-opencl-dev libhwloc-dev zlib1g zlib1g-dev clinfo dialog apt-utils libxml2-dev libclang-cpp${LLVM_VERSION}-dev libclang-cpp${LLVM_VERSION} llvm-${LLVM_VERSION}-dev libncurses5 cd /opt sudo wget https://github.com/llvm/llvm-project/releases/download/llvmorg-11.1.0/clang+llvm-11.1.0-aarch64-linux-gnu.tar.xz sudo tar -xvvf clang+llvm-11.1.0-aarch64-linux-gnu.tar.xz sudo mv clang+llvm-11.1.0-aarch64-linux-gnu llvm-11.1.0 sudo rm clang+llvm-11.1.0-aarch64-linux-gnu.tar.xz ``` ### Compile and Install PoCL ``` sh cd ~/ mkdir softwares cd softwares git clone -b release_3_0 https://github.com/pocl/pocl.git pocl_3.0 cd pocl_3.0 mkdir build cd build cmake -DCMAKE_INSTALL_PREFIX=/opt/pocl-3.0 -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=""-funroll-loops -march=native"" -DCMAKE_C_FLAGS=""-funroll-loops -march=native"" -DWITH_LLVM_CONFIG=/opt/llvm-11.1.0/bin/llvm-config -DSTATIC_LLVM=ON -DENABLE_CUDA=ON .. make -j4 sudo make install sudo mkdir -p /etc/OpenCL/vendors/ sudo touch /etc/OpenCL/vendors/pocl.icd echo ""/opt/pocl-3.0/lib/libpocl.so"" | sudo tee --append /etc/OpenCL/vendors/pocl.icd ``` Now OpenCL should be successfully installed on the system. You can check if it works with the following command: ``` sh mk@jetson:~$ clinfo ``` My result: ``` Number of platforms 1 Platform Name Portable Computing Language Platform Vendor The pocl project Platform Version OpenCL 3.0 PoCL 3.0-rc2 Linux, RELOC, LLVM 11.1.0, SLEEF, FP16, CUDA, POCL_DEBUG Platform Profile FULL_PROFILE Platform Extensions cl_khr_icd cl_pocl_content_size Platform Host timer resolution 0ns Platform Extensions function suffix POCL Platform Name Portable Computing Language Number of devices 2 Device Name pthread-cortex-a57 Device Vendor ARM Device Vendor ID 0x13b5 Device Version OpenCL 1.2 PoCL HSTR: pthread-aarch64-unknown-linux-gnu-cortex-a57 Driver Version 3.0-rc2 Device OpenCL C Version OpenCL C 1.2 PoCL Device Type CPU Device Name NVIDIA Tegra X1 Device Vendor NVIDIA Corporation Device Vendor ID 0x10de Device Version OpenCL 1.2 PoCL HSTR: CUDA-sm_53 Driver Version 3.0-rc2 Device OpenCL C Version OpenCL C 1.2 PoCL Device Type GPU Device Topology (NV) PCI-E, 00:00.0 Device Profile FULL_PROFILE Device Available Yes Compiler Available Yes Linker Available Yes Max compute units 1 Max clock frequency 921MHz Compute Capability (NV) 5.3 ``` #### Run `clpeak` Benchmark ``` cd ~/ && mkdir workspace && cd workspace git clone https://github.com/krrishnarraj/clpeak.git cd clpeak git submodule update --init --recursive --remote mkdir build && cd build cmake .. make -j4 ./clpeak ``` Result (also here in a [Google Sheet](https://docs.google.com/spreadsheets/d/14fJGbcIS7na7uuQzY_1g86mMyZHrhrN-U7P0sVHSopg/edit?usp=sharing)): ``` Platform: Portable Computing Language Device: pthread-cortex-a57 Driver version : 3.0-rc2 (Linux ARM64) Compute units : 4 Clock frequency : 1479 MHz Single-precision compute (GFLOPS) float : 1.04 float2 : 2.09 float4 : 4.14 float8 : 8.20 float16 : 15.94 Integer compute (GIOPS) int : 3.80 int2 : 3.28 int4 : 5.69 int8 : 11.14 int16 : 21.34 Device: NVIDIA Tegra X1 Driver version : 3.0-rc2 (Linux ARM64) Compute units : 1 Clock frequency : 921 MHz Single-precision compute (GFLOPS) float : 220.29 float2 : 228.37 float4 : 229.89 float8 : 228.30 float16 : 228.25 Integer compute (GIOPS) int : 62.01 int2 : 77.55 int4 : 77.35 int8 : 57.64 int16 : 63.62 ``` The GPU is slightly faster, but provides only **228 GFLOPS** and **0.06 TOPS** with 25 GB/s theoretical memory bandwidth. In theory it should achieve 472 GFLOPS in FP16. For comparison: the [Jetson Nano Orin Super](https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/nano-super-developer-kit/) has [2560 GFLOPS](https://www.techpowerup.com/gpu-specs/jetson-orin-nano-8-gb.c4082) and 67 TOPS with 102 GB/s theoretical memory bandwidth. ## Some tips Deactivate the GUI with `sudo systemctl set-default multi-user.target`. To apply, do a reboot with `sudo reboot`. Reactivate with `sudo systemctl set-default graphical.target` and `sudo reboot`."
https://github.com/kreier/cuda/blob/main/README.md,# cuda Example projects to learn parallized CUDA programming.
https://github.com/kreier/llama.cpp-jetson.nano/blob/main/README.md,"# llama.cpp-jetson.nano ![GitHub Release](https://img.shields.io/github/v/release/kreier/llama.cpp-jetson.nano) ![GitHub License](https://img.shields.io/github/license/kreier/llama.cpp-jetson.nano) Install a CUDA version of [llama.cpp](https://github.com/ggml-org/llama.cpp) with `llama-cli`, `llama-server` and `llama-bench` on the Jetson Nano, compiled with gcc 8.5. Just copy, paste and execute: ``` sh curl -fsSL https://kreier.github.io/llama.cpp-jetson.nano/install.sh | bash && source ~/.bashrc ``` ## CLI and Webinterface Now you can start Gemma3. The *first startup* takes almost **7 minutes**, later its just **10 seconds**. To start enter ``` sh llama-cli -hf ggml-org/gemma-3-1b-it-GGUF --n-gpu-layers 99 ``` The download might be 30 seconds. Then `main: load model the model and apply lora adapter, if any` stops for 6min30 during the first start. The next time the cli is available after **10 seconds**. If you `ssh` into your Jetson Nano with `ssh 192.168.37.37` you can also start the little `llama-server`. It renders the created markdown much nicer: ``` sh llama-server -m ~/.cache/llama.cpp/ggml-org_gemma-3-1b-it-GGUF_gemma-3-1b-it-Q4_K_M.gguf --host 0.0.0.0 --n-gpu-layers 99 ``` Then open port 8080 on your Jetson with [http://192.168.37.37:8080](http://192.168.37.37:8080) and enjoy the GUI! ![llama-server](docs/llama-server5050.png) Maybe let it compare *Snow White* to *Cinderella*. There is also a variant compiled with gcc 9.4 that works. Details are [described here](#running-with-gcc-94). Try it with: ``` sh curl -fsSL https://kreier.github.io/llama.cpp-jetson.nano/install9.sh | bash && source ~/.bashrc ``` ## Source The binaries were compiled with `gcc 8.5` and some changes, described in the repository [https://github.com/kreier/llama.cpp-jetson](https://github.com/kreier/llama.cpp-jetson). The compiled 71 binaries and libraries of the `/build/bin` folder can be found in the `/bin` folder of this repository. ## Description The script copies three binaries to `/usr/local/bin` and five libraries to `/usr/local/lib`. They should be included an $PATH and autmatically work. List of binaries to copy: - llama.cpp - llama-server - llama-bench And the 5 required libraries copied to `/usr/local/lib`: - libllama.so - libggml.so - libggml-base.so - libggml-cpu.so - libggml-cuda.so This is the content of the script: ``` bash #!/bin/bash set -eu red=""$( (/usr/bin/tput bold || :; /usr/bin/tput setaf 1 || :) 2>&-)"" plain=""$( (/usr/bin/tput sgr0 || :) 2>&-)"" status() { echo "">>> $*"" >&2; } error() { echo ""${red}ERROR:${plain} $*""; exit 1; } warning() { echo ""${red}WARNING:${plain} $*""; } TEMP_DIR=$(mktemp -d) cleanup() { rm -rf $TEMP_DIR; } trap cleanup EXIT available() { command -v $1 >/dev/null; } require() { local MISSING='' for TOOL in $*; do if ! available $TOOL; then MISSING=""$MISSING $TOOL"" fi done echo $MISSING } SUDO= if [ ""$(id -u)"" -ne 0 ]; then # Running as root, no need for sudo if ! available sudo; then error ""This script requires superuser permissions. Please re-run as root."" fi SUDO=""sudo"" fi NEEDS=$(require curl awk grep sed tee xargs) if [ -n ""$NEEDS"" ]; then status ""ERROR: The following tools are required but missing:"" for NEED in $NEEDS; do echo "" - $NEED"" done exit 1 fi status ""Downloading binaries to temporary directory"" FILES=""llama-cli llama-server llama-bench llama-run llama-simple llama-simple-chat libllama.so libggml.so libggml-base.so libggml-cpu.so libggml-cuda.so"" for FILE in $FILES; do status ""Downloading $FILE"" curl -fsSL -o ""$TEMP_DIR/$FILE"" ""https://kreier.github.io/llama.cpp-jetson.nano/bin/$FILE"" done status ""Installing llama.cpp with CUDA support on the Jetson Nano to /usr/local/bin"" $SUDO install -o0 -g0 -m755 -d ""/usr/local/bin"" $SUDO install -o0 -g0 -m755 -d ""/usr/local/lib"" # Copy binaries BINARIES=""llama-cli llama-server llama-bench llama-run llama-simple llama-simple-chat"" for FILE in $BINARIES; do $SUDO cp -v ""$TEMP_DIR/$FILE"" /usr/local/bin/ $SUDO chmod +x /usr/local/bin/$FILE done # Copy libraries LIBRARIES=""libllama.so libggml.so libggml-base.so libggml-cpu.so libggml-cuda.so"" for FILE in $LIBRARIES; do $SUDO cp -v ""$TEMP_DIR/$FILE"" /usr/local/lib/ done # Define the library path LIB_PATH=""/usr/local/lib"" # Check if the LD_LIBRARY_PATH line already exists in ~/.bashrc - if not, append it to ~/.bashrc if grep -q ""export LD_LIBRARY_PATH=$LIB_PATH:\$LD_LIBRARY_PATH"" ~/.bashrc; then echo ""Library path is already set in ~/.bashrc."" else echo ""Adding library path to ~/.bashrc..."" echo ""export LD_LIBRARY_PATH=$LIB_PATH:\$LD_LIBRARY_PATH"" >> ~/.bashrc fi # Reload ~/.bashrc to apply the changes echo ""Reloading ~/.bashrc..."" source ~/.bashrc echo ""Done! The library path has been updated."" ``` ## Running with GCC 9.4 Both the original gcc 7.5 and the last supported gcc for nvcc, 8.5, come with the library `libstdc++ 6.0.25` in `/usr/lib/aarch64-linux-gnu/libstdc++.so.6.0.25` For gcc 9 this is updated to version `6.0.32`. This is the reason the compiled binary from gcc 9.4 does not work on the unpatched system. Just copying the newer library to the library folder causes a system crash. But you can install gcc 9.4 from a reference repository in 4 minutes: ``` sh sudo apt install build-essential software-properties-common manpages-dev -y sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y sudo apt update sudo apt install gcc-9 g++-9 -y sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 9 sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 9 ``` After that you can use `llama.cpp` binaries compiled with gcc 9.4."
https://github.com/kreier/hacks/blob/main/README.md,"# Hacks ![GitHub Release](https://img.shields.io/github/v/release/kreier/hacks) ![GitHub License](https://img.shields.io/github/license/kreier/hacks) A few hacks I keep search the web way too often. - [Write protected disks and diskpart](#write-protected-disks-and-diskpart) - [Lower power consumption](#lower-power-consumption) - [Run ollama on RX 6600 and RX 470](#run-ollama-on-rx-6600-and-rx-470) - [Markdown](#markdown) - [Deactivate GUI](#deactivate-gui-on-ubuntu) ## Write protected disks and diskpart List disks, partitions and volumes. And select them once diskpart is started. ``` sh list disk list partition list volume select volume 4 delete volume override ``` Remove write protection ``` sh attributes disk clear readonly ``` Format in fat32 quick ``` select partition 3 format fs=fat32 label=""test"" quick ``` ## Lower power consumption Check your package C-states. If you're only on C2 this might be the reason your power consumption is rather high. Check with a Linux distribution in superuser mode and `powertop`. You might get better results after executing ``` sh powertop --auto-tune ``` But for me this affects the interrupts from the keyboard and mouse, the system seems to be very unresponsive. And usually the improvement in powerconsumption is not very large. ## Run ollama on RX 6600 and RX 470 As described in [this blog post](https://major.io/p/ollama-with-amd-radeon-6600xt/) it is possible to run ollama even on AMD graphics cards, even if the specific hardware does not yet have the [HIP SDK support](https://rocm.docs.amd.com/projects/install-on-windows/en/latest/reference/system-requirements.html). Usually the GPU should be found with `> lspci | grep -i VGA`. At first glance with `sudo journalctl --boot -u ollama` it looks like the GPU is not supported. But you can override that with the `HSA_OVERRIDE_GFX_VERSION` setting as explained in detail in this [documentation of ollama](https://github.com/ollama/ollama/blob/main/docs/gpu.md#overrides). Let's do that: ``` bash > sudo systemctl edit ollama.service ``` And enter ``` sh ### Editing /etc/systemd/system/ollama.service.d/override.conf ### Anything between here and the comment below will become the contents of the drop-in file [Service] Environment=""HSA_OVERRIDE_GFX_VERSION=10.3.0"" Environment=""ROCM_PATH=/opt/rocm"" ### Edits below this comment will be discarded ``` With systemd we can reload the unit and restart ollama: ``` sh > sudo systemctl daemon-reload > sudo systemctl stop ollama > sudo systemctl start ollama ``` After that I can use the RX6600 without problems, since its LLVM target is `gfx1032` and close to the overwritten `gfx1030`. Even the older `gfx900` of the Vega 56 would work. But my RX 470 is `gfx803`. Accordingly in ollama it is reported `amd_linux.go:305 msg=""amdgpu too old gfx803"" gpu=0`. I need to upgrade. ## Markdown To create a table use this online tool: [https://www.tablesgenerator.com/markdown_tables](https://www.tablesgenerator.com/markdown_tables) Other hacks: [https://github.com/im-luka/markdown-cheatsheet](https://github.com/im-luka/markdown-cheatsheet) ## Deactivate GUI on Ubuntu ``` sh sudo systemctl set-default multi-user.target ``` And revert with ``` sh sudo systemctl set-default graphical.target ```"
https://github.com/kreier/aa/blob/main/README.md,"# Advanced Automation ![GitHub Release](https://img.shields.io/github/v/release/kreier/aa) ![GitHub License](https://img.shields.io/github/license/kreier/aa) [![pages-build-deployment](https://github.com/kreier/aa/actions/workflows/pages/pages-build-deployment/badge.svg)](https://github.com/kreier/aa/actions/workflows/pages/pages-build-deployment) Reference documents are hosted at [https://github.com/ssis-aa](https://github.com/ssis-aa). This course at SSIS was created by Evan Weinberg [@emwdx](https://github.com/emwdx). ## Unit 1: [Functions and Modular Code](./unit1) 1. [Welcome to Advanced Automation](https://github.com/kreier/aa/tree/main/unit1#1-welcome-to-advanced-automation) 2. [Introduction to Functions](https://github.com/kreier/aa/tree/main/unit1#2-introduction-to-functions) 3. [Shock Detector Case Study](https://github.com/kreier/aa/tree/main/unit1#3-shock-detector-case-study) 4. [Mastery Check - Sketch of Functions](https://github.com/kreier/aa/tree/main/unit1#4-mastery-check---sketch-of-functions) 5. [Making Code Modular](https://github.com/kreier/aa/tree/main/unit1#5-making-code-modular) 6. [Module Maker - Creating modular code yourself!](https://github.com/kreier/aa/tree/main/unit1#6-module-maker---creating-modular-code-yourself) 7. [Drink Machine Part I](https://github.com/kreier/aa/tree/main/unit1#7-drink-machine-part-i) 8. [Drink Machine Part II](https://github.com/kreier/aa/tree/main/unit1#8-drink-machine-part-ii) 9. [Drink Machine Testing Software](https://github.com/kreier/aa/tree/main/unit1#9-drink-machine-testing-software) ## Unit 2: [Managing State](./unit2) 1. Binary Secret Code - Introduction to Abstraction 2. Three Boards, Three Flavors 3. Introduction to State Machine Programming - Escape to Summer Case Study 4. Drink Dispenser State Machine 5. Building a Physical Drink Dispenser State Machine 6. Iterative Design 7. Choosing your system 8. Microwave State Program 9. Inputs, Outputs, Hardware 10. Levels of Abstraction I 11. Levels of Abstraction II ## Unit 3: [Collaborative Code and Generative Art](./unit3) 1. Generative Art and the Circle K Project 2. Design Project 3. Branches, Forks, and Pull Requests 4. Circular Art 5. Idea Sharing for the Generative Art Project 6. Project Check-In 7. Design Project Submission 8. Singular Collaborative Art Project 9. Work on Collaborative Art Project 10. Work on Collaborative Art Project 11. Design Project Submission 12. Singular Collaborative Art Project 13. Singular Collaborative Art Project 14. Singular Collaborative Art Project 15. Singular Collaborative Art Project 16. Explanation of Winter Break Assignment ## Unit 4: [Control Algorithms and APIs](./unit4) 1. Introduction Control Systems Board 2. Carrier board rp2040 - physical and electrical connection 3. The I2C Bus 4. Activate the OLED display 5. Control Algorithms 6. Digital states and Pulldown Resistors 7. Repositories for Control Systems 8. The PID controller 9. VEX VR Control Systems Task 10. Water Flow Controller and Landing a Rocket 11. APIs and Libraries 12. Sphero RVR API 13. Control Challenge 2022-2023 14. Documentation on Design Decisions 15. On the Field: Control Systems and API Challenge 16. Final test for the Sphero RVR challenge on the field ## Unit 5: [Machine Learning and Modifying Code](./unit5) 1. Sketch Classifier 2. Improving the Classifier 3. Self Driving Car Activity 4. Iterative Design 5. Evaluating Algorithms and Standards 6. Machine Learning Project - Objective and Dataset 7. Machine Learning Project - Algorithm and Training Data 8. Machine Learning Project - Training the Model 9. Work on Project Unit 5: Standard 2, 11 and 12 10. Project Unit 5 completion 11. Presentation of Unit 5 projects 12. Refine presentations for art party โRESETโ ## Unit 6: [Measurement and Data Processing](./unit6) 1. Collecting Data 2. The Color Wheel 3. Fan Tachometer Revisited 4. Thresholded data and Pulse Width 5. From csv to continuous read 6. Morse Code Project 7. Individual project 8. Semester 2 Iterative Design 9. Continuous Read with the Circuit Playground Express 10. Project refinement for Unit 6 11. Presentation of Unit 6 projects 12. Reflection on achievements ## Standards The first **two standards** are a separate category with 33% weighting each. The remaining 12 standards fall into the third category, CSE Power Standards (Computer Science and Engineering) and the respective Advanced Automation standard rubrics. 1. **Document** design decisions using text, graphics, presentations, and/or demonstrations in the development of complex programs. 2. **Design** and **iteratively develop** computational artifacts for practical intent, personal expression, or to address a societal issue by using events to initiate instructions. 3. Decompose problems into smaller components through systematic analysis, using constructs such as procedures, modules, and/or objects. 4. Construct solutions to problems using student-created components, such as procedures, modules and/or objects. 5. Illustrate ways computing systems implement logic, input, and output through hardware components. 6. Compare levels of abstraction and interactions between application software, system software, and hardware layers. 7. Justify the selection of specific control structures when tradeoffs involve implementation, readability, and program performance, and explain the benefits and drawbacks of choices made. 8. Design and develop computational artifacts working in team roles using collaborative tools. 9. Create prototypes that use algorithms to solve computational problems by leveraging prior student knowledge and personal interests. 10. Demonstrate code reuse by creating programming solutions using libraries and APIs. 11. Modify an existing program to add additional functionality and discuss intended and unintended implications (e.g., breaking other functionality) 12. Implement an artificial intelligence algorithm to play a game against a human opponent or solve a problem. 13. Use lists to simplify solutions, generalizing computational problems instead of repeatedly using simple variables. 14. Create artifacts by using procedures within a program, combinations of data and procedures, or independent but interrelated programs. Create procedures with parameters to organize code and make it easier to reuse. 15. Develop guidelines that convey systematic troubleshooting strategies that others can use to identify and fix errors. 16. Evaluate and refine computational artifacts to make them more usable and accessible."
